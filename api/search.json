[{"id":"11c0f2fa5655c019aeb2222b34a90ab0","title":"数据结构与算法","content":"# 数据结构与算法# 数据结构# 了解哪些数据结构？\n数组：数组的内存空间是连续的，随机访问的时间复杂度是O1，适用于需要按索引访问元素的场景，但是插入和删除元素较慢，时间复杂度是On\n链表：链表是由节点组成，节点之间是分散存储的，内存不连续，每个节点存储数据和指向下一个节点的指针。适用于频繁插入和删除元素的场景，随机访问元素较慢。\n栈：栈是一种后进先出的数据结构，只允许在栈顶进行插入和删除操作。\n队列：队列是一种先进先出（FIFO）的数据结构，允许在队尾插入元素，在队首删除元素。\n树：树是一种非线性数据结构，由节点和边组成，每个节点可以有多个子节点。树适用于表示层次关系的场景，例如文件系统、组织结构等。\n\n# 数组和链表区别是什么？\n访问效率：数组可以通过索引直接访问任何位置的元素，访问效率高，时间复杂度为O(1)，而链表需要从头节点开始遍历到目标位置，访问效率较低，时间复杂度为O(n)。\n插入和删除操作效率：数组插入和删除操作可能需要移动其他元素，时间复杂度为O(n)，而链表只需要修改指针指向，时间复杂度为O(1)。\n**缓存命中率：**由于数组元素在内存中连续存储，可以提高CPU缓存的命中率，而链表节点不连续存储，可能导致CPU缓存的命中率较低，频繁的缓存失效会影响性能。\n应用场景：数组适合静态大小、频繁访问元素的场景，而链表适合动态大小、频繁插入、删除操作的场景\n\n# 为什么数组查询的复杂度为O(1)？数组必须要内存中一块连续的空间，并且数组中必须存放相同的数据类型。\n比如我们创建一个长度为 10，数据类型为整型的数组，在内存中的地址是从 1000 开始，那么它在内存中的存储格式如下。\n\n由于每个整型数据占据 4 个字节的内存空间，因此整个数组的内存空间地址是 1000～1039，根据这个，我们就可以轻易算出数组中每个数据的内存下标地址。\n利用这个特性，我们只要知道了数组下标，也就是数据在数组中的位置，比如下标 2，就可以计算得到这个数据在内存中的位置 1008，从而对这个位置的数据 241 进行快速读写访问，时间复杂度为 O(1)。\n# 说一下队列和栈的区别主要区别在于元素的插入和删除方式以及元素的访问顺序。\n插入和删除方式：\n\n队列：队列采用先进先出（FIFO）的方式，即新元素插入队尾，删除操作发生在队首。\n栈：栈采用后进先出（LIFO）的方式，即新元素插入栈顶，删除操作也发生在栈顶。\n\n元素的访问顺序：\n\n队列：队列的元素按照插入的顺序进行访问，先插入的元素先被访问到。\n栈：栈的元素按照插入的顺序进行访问，但是最后插入的元素先被访问到。\n\n队列适用于需要按照插入顺序进行处理的场景，例如任务调度；\n\n而栈适用于需要维护最近操作状态的场景，例如函数调用。\n\n# 如何使用两个栈实现队列？使用两个栈实现队列的方法如下：\n\n准备两个栈，分别称为stackPush和stackPop。\n当需要入队时，将元素压入stackPush栈。\n当需要出队时，先判断stackPop是否为空，如果不为空，则直接弹出栈顶元素；如果为空，则将stackPush中的所有元素依次弹出并压入stackPop中，然后再从stackPop中弹出栈顶元素作为出队元素。\n当需要查询队首元素时，同样需要先将stackPush中的元素转移到stackPop中，然后取出stackPop的栈顶元素但不弹出。\n通过上述方法，可以实现用两个栈来模拟队列的先进先出（FIFO）特性。\n\n这种方法的时间复杂度为O(1)的入队操作，均摊时间复杂度为O(1)的出队和查询队首元素操作。\n以下是使用两个栈实现队列的Java代码示例：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.util.Stack;class MyQueue &#123;    private Stack&lt;Integer&gt; stackPush;    private Stack&lt;Integer&gt; stackPop;    public MyQueue() &#123;        stackPush = new Stack&lt;&gt;();        stackPop = new Stack&lt;&gt;();    &#125;    public void push(int x) &#123;        stackPush.push(x);    &#125;    public int pop() &#123;        if (stackPop.isEmpty()) &#123;            while (!stackPush.isEmpty()) &#123;                stackPop.push(stackPush.pop());            &#125;        &#125;        return stackPop.pop();    &#125;    public int peek() &#123;        if (stackPop.isEmpty()) &#123;            while (!stackPush.isEmpty()) &#123;                stackPop.push(stackPush.pop());            &#125;        &#125;        return stackPop.peek();    &#125;    public boolean empty() &#123;        return stackPush.isEmpty() &amp;&amp; stackPop.isEmpty();    &#125;&#125;// 测试代码public class Main &#123;    public static void main(String[] args) &#123;        MyQueue queue = new MyQueue();        queue.push(1);        queue.push(2);        System.out.println(queue.peek());  // 输出 1        System.out.println(queue.pop());   // 输出 1        System.out.println(queue.empty()); // 输出 false    &#125;&#125;\n\n# 平衡二叉树结构是怎么样的？使用二叉树搜索树的目的之一是缩短插入、删除、修改和查找（插入、删除、修改都包括查找操作）节点的时间。\n关于查找效率，如果一棵树的高度为h，在最坏的情况，查找一个关键字需要对比 h 次，查找时间复杂度不超过 O(h)。一棵理想的二叉搜索树所有操作的时间可以缩短到 O(logn)（n 是节点总数)。\n然而 O(h) 的时间复杂度仅为理想情况。在最坏情况下，搜索树有可能退化为链表。想象一棵每个结点只有右孩子的二叉搜索树，那么它的性质就和链表一样，所有操作（增删改查）的时间是O(n)。\n可以发现操作的复杂度与树的高度 h 有关。由此引出了平衡树，通过一定操作维持树的高度（平衡性）来降低操作的复杂度。\n所谓的平衡树是指一种改进的二叉查找树，顾名思义平衡树就是将二叉查找树平衡均匀地分布，这样的好处就是可以减少二叉查找树的深度。\n一般情况下二叉查找树的查询复杂度取决于目标节点到树根的距离（即深度），当节点的深度普遍较大时，查询的平均复杂度就会上升，因此为了实现更高效的查询就有了平衡树。\n平衡二叉树平衡的特性：\n\n左右两个子树的高度差（平衡因子）的绝对值不超过1\n左右两个子树都是一棵平衡二叉树\n\n非平衡二叉树(左)和平衡二叉树(右)如下图所示：\n\n通过平衡的特性，可以有效的减少二叉树的深度，从而提高了查询的效率。\n再来看看下图：\n\n分析：\n\n图一是一个平衡二叉树，它满足平衡二叉树的定义。\n图二不是平衡二叉树，其原因并不是不满足平衡因子的条件，而是因为它不满足二叉搜索树的构成条件，这提醒我们平衡二叉树首先要是一棵二叉搜索树。\n图三满足平衡二叉树的构成条件。\n图 4 中的节点 (8) 平衡因子为 3，不满足平衡二叉树的要求。\n\n# 红黑树说一下，跳表说一下？红黑树（Red-Black Tree）是一种自平衡的二叉搜索树，它在插入和删除操作后能够通过旋转和重新着色来保持树的平衡。红黑树的特点如下：\n\n每个节点都有一个颜色，红色或黑色。\n根节点是黑色的。\n每个叶子节点（NIL节点）都是黑色的。\n如果一个节点是红色的，则它的两个子节点都是黑色的。\n从根节点到叶子节点或空子节点的每条路径上，黑色节点的数量是相同的。\n\n红黑树通过这些特性来保持树的平衡，确保最长路径不超过最短路径的两倍，从而保证了在最坏情况下的搜索、插入和删除操作的时间复杂度都为O(logN)。\n\n跳表（Skip List）是一种基于链表的数据结构，它通过添加多层索引来加速搜索操作。\n\n跳表的特点如下：\n\n跳表中的数据是有序的。\n跳表中的每个节点都包含一个指向下一层和右侧节点的指针。\n\n跳表通过多层索引的方式来加速搜索操作。最底层是一个普通的有序链表，而上面的每一层都是前一层的子集，每个节点在上一层都有一个指针指向它在下一层的对应节点。这样，在搜索时可以通过跳过一些节点，直接进入目标区域，从而减少搜索的时间复杂度。\n跳表的平均搜索、插入和删除操作的时间复杂度都为O(logN)，与红黑树相比，跳表的实现更加简单，但空间复杂度稍高。跳表常用于需要高效搜索和插入操作的场景，如数据库、缓存等。\n# 你知道什么地方用了红黑树和跳表吗？\nepoll 用了红黑树来保存监听的 socket\nredis 用了跳表来实现 zset\n\n# 跳表时间复杂度？\n\n搜索操作的时间复杂度：O(log n)，其中n是跳表中元素的数量。这是因为跳表中使用多级索引，可以通过跳跃的方式快速定位到目标元素所在的位置，从而将搜索的时间复杂度降低到对数级别。\n插入和删除操作的时间复杂度：O(log n)，其中n是跳表中元素的数量。与搜索操作类似，插入和删除操作也可以通过跳跃的方式快速定位到需要插入或删除的位置，并进行相应的操作。因此，插入和删除的时间复杂度也是对数级别的。\n\n# 红黑树的数据结构介绍一下？红黑树是一种自平衡的二叉查找树，\n\n具有以下特点：\n\n每个节点要么是红色，要么是黑色。\n根节点是黑色。\n每个叶子节点（NIL节点）是黑色。\n如果一个节点是红色，则其子节点必须是黑色。\n从任一节点到其每个叶子节点的所有路径都包含相同数目的黑色节点。\n\n红黑树的自平衡性质可以保证在进行插入、删除等操作后，树的高度保持在O(log n)内，从而保持了较高的查找、插入和删除效率。下面是红黑树插入节点的过程，这左旋右旋的操作，就是为了自平衡。\n\n# 二叉树搜索最坏的时间复杂度，为什么会这样？以及用什么结果解决？**当每次插入的元素都是二叉查找树中最大的元素，二叉查找树就会退化成了一条链表，查找数据的时间复杂度变成了 O(n)**，如下动图演示：\n\n二叉查找树由于存在退化成链表的可能性，会使得查询操作的时间复杂度从 O(logn) 升为 O(n)。\n为了解决二叉查找树会在极端情况下退化成链表的问题，后面就有人提出平衡二叉查找树（AVL 树）。\n主要是在二叉查找树的基础上增加了一些条件约束：每个节点的左子树和右子树的高度差不能超过 1。也就是说节点的左子树和右子树仍然为平衡二叉树，这样查询操作的时间复杂度就会一直维持在 O(logn) 。\n下图是每次插入的元素都是平衡二叉查找树中最大的元素，可以看到，它会维持自平衡：\n\n除了平衡二叉查找树，还有很多自平衡的二叉树，比如红黑树，它也是通过一些约束条件来达到自平衡，不过红黑树的约束条件比较复杂。下面是红黑树插入节点的过程，这左旋右旋的操作，就是为了自平衡。\n\n# B+树的特点是什么？\nB+树是一种自平衡的多路查找树，所有叶节点都位于同一层，保证了树的平衡，使得搜索、插入和删除操作的时间复杂度为对数级别的。\n非叶节点仅包含索引信息，不存储具体的数据记录，它们只用来引导搜索到正确的叶节点。非叶节点的子树指针与关键字数量相同，每个子树指针指向一个子树，子树中的所有键值都在某个区间内。\n所有数据记录都存储在叶节点中，且叶节点中的数据是按关键字排序的。叶节点包含实际的数据和关键字，它们是数据存储和检索的实体单元。叶节点之间通过指针相互链接，形成一个链表，便于范围查询和顺序遍历。\n\n# B+树和B树有什么不一样，B+树的叶子节点和非叶子节点有什么不一样，非叶子节点会不会存数据？\n检索路径：B树在查找数据时，可能在非叶子节点找到目标数据，路径长度不固定。即查找时可以在任意一个节点终止。B+树中所有数据都在叶子节点，查找数据时必须走到叶子节点，路径长度固定（均等）。即查找总是要到叶子节点结束。\n叶子节点结构：B树中叶子节点之间没有特别的链接，彼此独立。B+树中叶子节点通过指针连接，形成一个有序链表，便于范围查询和顺序访问。\n非叶子节点内容：B树中非叶子节点存储数据和索引。B+树中非叶子节点只存储索引，不存储实际数据。因此，当数据量比较大时，相对于B树，B+树的层高更少，查找效率也就更高。\n**高效地范围查询：**B+树叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树在进行范围查询时需要进行中序遍历，性能较差。\n\n# 堆是什么？堆是一颗完全二叉树，这样实现的堆也被称为二叉堆。堆中节点的值都大于等于（或小于等于）其子节点的值，堆中如果节点的值都大于等于其子节点的值，我们把它称为大顶堆，如果都小于等于其子节点的值，我们将其称为小顶堆。\n下图中，1，2 是大顶堆，3 是小顶堆， 4 不是堆（不是完全二叉树）\n\n# LRU是什么？如何实现？LRU 是一种缓存淘汰算法，当缓存空间已满时，优先淘汰最长时间未被访问的数据。\n实现的方式是哈希表+双向链表结合。\n\n具体实现步骤如下：\n\n使用哈希表存储数据的键值对，键为缓存的键，值为对应的节点。\n使用双向链表存储数据节点，链表头部为最近访问的节点，链表尾部为最久未访问的节点。\n当数据被访问时，如果数据存在于缓存中，则将对应节点移动到链表头部；如果数据不存在于缓存中，则将数据添加到缓存中，同时创建一个新节点并插入到链表头部。\n当缓存空间已满时，需要淘汰最久未访问的节点，即链表尾部的节点。\n\n上面这种思想方式，LRU 算法可以在 O(1) 的时间复杂度内实现数据的插入、查找和删除操作。每次访问数据时，都会将对应的节点移动到链表头部，保证链表头部的节点是最近访问的数据，而链表尾部的节点是最久未访问的数据。当缓存空间不足时，淘汰链表尾部的节点即可。\n# 布隆过滤器怎么设计？时间复杂度？在开发过程中，经常要判断一个元素是否在一个集合中。假设你现在要给项目添加IP黑名单功能，此时你手上有大约 1亿个恶意IP的数据集，有一个IP发起请求，你如何判断这个IP在不在你的黑名单中？\n类似这种问题用Java自己的Collection和Map很难处理，因为它们存储元素本身，会造成内存不足，而我们只关心元素存不存在，对于元素的值我们并不关心，具体值是什么并不重要。\n「布隆过滤器」可以用来解决类似的问题，具有运行快速，内存占用小的特点，它是一个保存了很长的二级制向量，同时结合 Hash 函数实现的。而高效插入和查询的代价就是，它是一个基于概率的数据结构，只能告诉我们一个元素绝对不在集合内，对于存在集合内的元素有一定的误判率。\n布隆过滤器中总是会存在误判率，因为哈希碰撞是不可能百分百避免的。布隆过滤器对这种误判率称之为「假阳性概率」，即：False Positive Probability，简称为 fpp。在实践中使用布隆过滤器时可以自己定义一个 fpp，然后就可以根据布隆过滤器的理论计算出需要多少个哈希函数和多大的位数组空间。需要注意的是这个 fpp 不能定义为 100%，因为无法百分保证不发生哈希碰撞。\n下图表示向布隆过滤器中添加元素 www.123.com 和 www.456.com 的过程，它使用了 func1 和 func2 两个简单的哈希函数。\n\n其基本原理如下：\n\n初始化：当我们创建一个布隆过滤器时，我们首先创建一个全由0组成的位数组（bit array)。同时，我们还需选择几个独立的哈希函数，每个函数都可以将集合中的元素映射到这个位数组的某个位置。\n添加元素：在布隆过滤器中添加一个元素时，我们会将此元素通过所有的哈希函数进行映射，得到在位数组中的几个位置，然后将这些位置标记为1。\n查询元素：如果我们要检查一个元素是否在集合中，我们同样使用这些哈希函数将元素映射到位数组中的几个位置，如果所有的位置都被标记为1，那么我们就可以说该元素可能在集合中。如果有任何一个位置不为1，那么该元素肯定不在集合中。\n\n通过其原理可以知道，我们可以提高数组长度以及 hash 计算次数来降低误报率，但是相应的 CPU、内存的消耗也会相应地提高，会增加存储和计算的开销。因此，布隆过滤器的使用需要在误判率和性能之间进行权衡。布隆过滤器有以下两个特点：\n\n只要返回数据不存在，则肯定不存在。\n返回数据存在，不一定存在。\n\n布隆过滤器的误判率主要来源于「哈希碰撞」。因为位数组的大小有限，不同的元素可能会被哈希到相同的位置，导致即使某个元素并未真正被加入过滤器，也可能因为其他已经存在的元素而让所有哈希函数映射的位都变为了1，从而误判为存在。这就是布隆过滤器的“假阳性”错误。在有限的数组长度中存放大量的数据，即便是再完美的 Hash 算法也会有冲突，所以有可能两个完全不同的 A、B 两个数据最后定位到的位置是一模一样的。这时拿 B 进行查询时那自然就是误报了。\n**布隆过滤器的时间复杂度和空间复杂度：**对于一个 m（比特位个数）和 k（哈希函数个数）值确定的布隆过滤器，添加和判断操作的时间复杂度都是 O(k)，这意味着每次你想要插入一个元素或者查询一个元素是否在集合中，只需要使用 k 个哈希函数对该元素求值，然后将对应的比特位标记或者检查对应的比特位即可。\n# 排序算法# 说几个你懂的排序算法，并说明其时间空间复杂度\n\n冒泡排序：通过相邻元素的比较和交换，每次将最大（或最小）的元素逐步“冒泡”到最后（或最前）。时间复杂度：最好情况下O(n)，最坏情况下O(n^2)，平均情况下O(n^2)。，空间复杂度：O(1)。\n插入排序：将待排序元素逐个插入到已排序序列的合适位置，形成有序序列。时间复杂度：最好情况下O(n)，最坏情况下O(n^2)，平均情况下O(n^2)，空间复杂度：O(1)。\n选择排序（Selection Sort）：通过不断选择未排序部分的最小（或最大）元素，并将其放置在已排序部分的末尾（或开头）。时间复杂度：最好情况下O(n^2)，最坏情况下O(n^2)，平均情况下O(n^2)，空间复杂度：O(1)。\n快速排序（Quick Sort）：通过选择一个基准元素，将数组划分为两个子数组，使得左子数组的元素都小于（或等于）基准元素，右子数组的元素都大于（或等于）基准元素，然后对子数组进行递归排序。时间复杂度：最好情况下O(nlogn)，最坏情况下O(n^2)，平均情况下O(nlogn)，空间复杂度：最好情况下O(logn)，最坏情况下O(n)。\n归并排序（Merge Sort）：将数组不断分割为更小的子数组，然后将子数组进行合并，合并过程中进行排序。时间复杂度：最好情况下O(nlogn)，最坏情况下O(nlogn)，平均情况下O(nlogn)。空间复杂度：O(n)。\n堆排序（Heap Sort）：通过将待排序元素构建成一个最大堆（或最小堆），然后将堆顶元素与末尾元素交*换，再重新调整堆，重复该过程直到排序完成。时间复杂度：最好情况下O(nlogn)，最坏情况下O(nlogn)，平均情况下O(nlogn)。空间复杂度：O(1)。\n\n# 讲一下冒泡排序算法冒泡排序：通过相邻元素的比较和交换，每次将最大（或最小）的元素逐步“冒泡”到最后（或最前）\n\n冒泡排序的最好时间复杂度出现在以下情况：当待排序数组已经有序时，即每个元素都比其前面的元素小，那么在第一次遍历数组时就可以确定排序已经完成，因此时间复杂度为O(n)。\n冒泡排序的时间复杂度为O(n^2)。因为在排序过程中，需要进行多次遍历和元素交换，而每次遍历都需要比较相邻的元素并决定是否进行交换，这种操作需要花费O(n)的时间。因此，冒泡排序的时间复杂度通常为O(n^2)。\n\n1234567891011121314151617181920212223242526272829public class BubbleSort &#123;    // 冒泡排序算法    public void bubbleSort(int[] arr) &#123;        int n = arr.length;        // 外层循环控制比较轮数        for (int i = 0; i &lt; n - 1; i++) &#123;            // 内层循环进行两两比较并交换            for (int j = 0; j &lt; n - i - 1; j++) &#123;                if (arr[j] &gt; arr[j + 1]) &#123;                    // 交换两个元素                    int temp = arr[j];                    arr[j] = arr[j + 1];                    arr[j + 1] = temp;                &#125;            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        int[] arr = &#123;64, 34, 25, 12, 22, 11, 90&#125;;        BubbleSort bubbleSort = new BubbleSort();        bubbleSort.bubbleSort(arr);        System.out.println(&quot;Sorted array:&quot;);        for (int value : arr) &#123;            System.out.print(value + &quot; &quot;);        &#125;    &#125;&#125;\n\n# 讲一下快排原理快排使用了分治策略的思想，所谓分治，顾名思义，就是分而治之，将一个复杂的问题，分成两个或多个相似的子问题，在把子问题分成更小的子问题，直到更小的子问题可以简单求解，求解子问题，则原问题的解则为子问题解的合并。\n快排的过程简单的说只有三步：\n\n首先从序列中选取一个数作为基准数\n将比这个数大的数全部放到它的右边，把小于或者等于它的数全部放到它的左边 （一次快排 partition）\n然后分别对基准的左右两边重复以上的操作，直到数组完全排序\n\n具体按以下步骤实现：\n\n1，创建两个指针分别指向数组的最左端以及最右端\n2，在数组中任意取出一个元素作为基准\n3，左指针开始向右移动，遇到比基准大的停止\n4，右指针开始向左移动，遇到比基准小的元素停止，交换左右指针所指向的元素\n5，重复3，4，直到左指针超过右指针，此时，比基准小的值就都会放在基准的左边，比基准大的值会出现在基准的右边\n6，然后分别对基准的左右两边重复以上的操作，直到数组完全排序\n\n注意这里的基准该如何选择？最简单的一种做法是每次都是选择最左边的元素作为基准，但这对几乎已经有序的序列来说，并不是最好的选择，它将会导致算法的最坏表现。还有一种做法，就是选择中间的数或通过 Math.random() 来随机选取一个数作为基准。\n\n代码实现：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class QuickSort &#123;    // 快速排序算法    public void quickSort(int[] arr, int low, int high) &#123;        if (low &lt; high) &#123;            int pi = partition(arr, low, high);            // 递归排序左半部分            quickSort(arr, low, pi - 1);            // 递归排序右半部分            quickSort(arr, pi + 1, high);        &#125;    &#125;    // 划分函数，用于找到基准元素的正确位置    int partition(int[] arr, int low, int high) &#123;        int pivot = arr[high]; // 选择最后一个元素作为基准        int i = low - 1; // 初始化较小元素的索引        for (int j = low; j &lt; high; j++) &#123;            if (arr[j] &lt; pivot) &#123;                i++;                // 交换元素                int temp = arr[i];                arr[i] = arr[j];                arr[j] = temp;            &#125;        &#125;        // 将基准元素放到正确的位置        int temp = arr[i + 1];        arr[i + 1] = arr[high];        arr[high] = temp;        return i + 1; // 返回基准元素的位置    &#125;    public static void main(String[] args) &#123;        int[] arr = &#123;10, 7, 8, 9, 1, 5&#125;;        QuickSort quickSort = new QuickSort();        quickSort.quickSort(arr, 0, arr.length - 1);        System.out.println(&quot;Sorted array:&quot;);        for (int value : arr) &#123;            System.out.print(value + &quot; &quot;);        &#125;    &#125;&#125;\n\n# 堆排序算法原理，稳定吗？如果每个节点大于等于子树中的每个节点，我们称之为大顶堆，小于等于子树中的每个节点，我们则称之为小顶堆。\n\n堆的要求：\n\n必须是完全二叉树\n堆中的每一个节点，都必须大于等于（或小于等于）其子树中每个节点的值。\n\n堆通常是使用一维数组进行保存，节省空间，不需要存左右子节点的指针，通过下标就可定位左右节点和父节点。在起始位置为0的数组中：\n\n父节点 i 的左子节点在(2i+1)的位置\n父节点 i 的右子节点在(2i+2)的位置\n子节点 i 的父节点在(i-1)&#x2F;2向下取整的位置\n\n\n我们可以把堆排序的过程大致分为两大步骤，分别是建堆和排序。\n\n建堆：建堆操作就是将一个无序的数组转化为最大堆的操作，首先将数组原地建一个堆。“原地”的含义就是不借助另一个数组，就在原数组上操作。我们的实现思路是从后往前处理数据，并且每个数据都是从上向下调整。\n排序：建堆结束后，数组中的数据已经按照大顶堆的特性进行组织了，数组中的第一个元素就是堆顶，也就是最大的元素。我们把它和最后一个元素交换，那最大的元素就放到了下标为n的位置，时末尾元素就是最大值，将剩余元素重新堆化成一个大顶堆。继续重复这些步骤，直至数组有序排列\n\n假设我们有一个数组 [4, 10, 3, 5, 1]，堆排序的过程如下：\n\n构建最大堆：[10, 5, 3, 4, 1]\n交换堆顶元素与最后一个元素：[1, 5, 3, 4, 10]\n调整剩余元素为堆：[5, 4, 3, 1]\n再次交换堆顶元素与最后一个元素：[1, 4, 3, 5]\n调整剩余元素为堆：[4, 3, 1]\n继续上述过程直到排序完成：[1, 3, 4, 5, 10]\n\n算法实现：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class HeapSort &#123;    // 堆排序方法    public static void heapSort(int[] arr) &#123;        int n = arr.length;        // 构建堆（重新排列数组）        for (int i = n / 2 - 1; i &gt;= 0; i--) &#123;            heapify(arr, n, i);        &#125;        // 依次从堆中提取元素        for (int i = n - 1; i &gt; 0; i--) &#123;            // 将当前根节点移动到末尾            int temp = arr[0];            arr[0] = arr[i];            arr[i] = temp;            // 在堆中调整            heapify(arr, i, 0);        &#125;    &#125;    // 通过索引i对数组arr的前n个元素进行堆调整    private static void heapify(int[] arr, int n, int i) &#123;        int largest = i; // 初始化最大值索引        int left = 2 * i + 1; // 左孩子节点        int right = 2 * i + 2; // 右孩子节点        // 如果左孩子大于根节点        if (left &lt; n &amp;&amp; arr[left] &gt; arr[largest]) &#123;            largest = left;        &#125;        // 如果右孩子大于当前最大值        if (right &lt; n &amp;&amp; arr[right] &gt; arr[largest]) &#123;            largest = right;        &#125;        // 如果最大值不是根节点        if (largest != i) &#123;            int swap = arr[i];            arr[i] = arr[largest];            arr[largest] = swap;            // 递归调整受影响的子树            heapify(arr, n, largest);        &#125;    &#125;    public static void main(String[] args) &#123;        int[] arr = &#123;4, 10, 3, 5, 1&#125;;        heapSort(arr);                System.out.println(&quot;排序后的数组:&quot;);        for (int i : arr) &#123;            System.out.print(i + &quot; &quot;);        &#125;    &#125;&#125;\n\n现在我们来分析一下堆排序的时间复杂度、空间复杂度以及稳定性。\n\n整个堆排序的过程中，只需要个别的临时存储空间，所以堆排序是原地排序算法。\n\n堆排序包括建堆和排序两个操作，建堆的时间复杂度是O(n)，排序过程时间复杂度是O(nlogN)。所以，**堆排序的整个时间复杂度是O(nlogN)**。\n\n因为在排序的过程中，存在将堆的最后一个节点跟堆顶互换的操作，所以有可能会改变值相同数据的原始相对顺序，所以堆排序不是稳定的排序算法。例如，假设我们有两个相同的元素A和B，且A在B前面。在构建和调整堆的过程中，B可能被移动到A的前面，从而破坏了它们原来的相对顺序。\n\n\n# 归并排序和快速排序的使用场景\n归并排序是稳定排序算法，适合排序稳定的场景；\n快速排序是不稳定排序算法，不适合排序稳定的场景，快速排序是目前基于比较的内部排序中被认为是最好的方法，当待排序的关键字是随机分布时，快速排序的平均时间最短；\n\n# 什么是排序稳定性？排序算法的稳定性是指在排序过程中，当有多个具有相同关键字的元素时，这些元素在排序后的序列中保持它们原有的相对顺序。\n换句话说，如果两个元素有相同的键值，那么在排序前，如果第一个元素在第二个元素之前，排序后第一个元素也应该在第二个元素之前。\n具体来说，对于一个序列中的两个元素A和B，如果A和B的键值相同，且在排序前A在B之前，那么在排序后A仍然应该在B之前，算法才能被称为是稳定的。\n例如，考虑一个包含姓名和年龄的列表：\n1[(&quot;Alice&quot;, 25), (&quot;Bob&quot;, 25), (&quot;Charlie&quot;, 20)]\n\n如果排序算法是稳定的，那么在按年龄排序后，”Alice”和”Bob”的相对顺序不会改变：\n1[(&quot;Charlie&quot;, 20), (&quot;Alice&quot;, 25), (&quot;Bob&quot;, 25)]\n\n但如果排序算法不稳定，”Alice”和”Bob”的相对顺序可能会在排序后改变：\n1[(&quot;Charlie&quot;, 20), (&quot;Bob&quot;, 25), (&quot;Alice&quot;, 25)]\n\n在这种情况下，排序算法就被认为是不稳定的。\n# 稳定和不稳定排序算法有什么特点？稳定排序算法的特点：\n\n相同元素的相对位置不会改变，排序后仍然保持原始顺序。\n适用于需要保持元素间相对顺序关系的场景，如按照年龄排序后按姓名排序。\n\n不稳定排序算法的特点：\n\n相同元素的相对位置可能会改变，排序后不保证原始顺序。\n可能会更快，但不适用于需要保持元素间相对顺序关系的场景。\n\n# 说说快排流程，时间复杂度快速排序的流程如下：\n\n从数组中选择一个基准元素（通常是数组中间位置的元素）。\n将数组分成两部分，小于基准元素的放在左边，大于基准元素的放在右边。\n递归地对左右两部分进行快速排序。\n\n快速排序的时间复杂度为O(n log n)，其中n为数组的长度。最坏情况下时间复杂度为O(n^2)，发生在每次选择的基准元素都是最大或最小值时。平均情况下时间复杂度为O(n log n)，效率较高。\n# 快排为什么时间复杂度最差是O（n^2）主要是因为在每次划分时选择的基准元素不合适导致的。当每次选择的基准元素都是当前子数组中的最大或最小元素时，就会导致每次划分只能减少一个元素，而不是均匀地分成两部分，从而造成时间复杂度达到O(n^2)。\n这种情况通常发生在数组已经有序或基本有序的情况下。为了避免最坏情况发生，可以通过随机选择基准元素或者使用三数取中法等策略来提高快速排序的性能。\n# 快排这么强，那冒泡排序还有必要吗？冒泡排序在一些特定场景下仍然有其优势，比如：\n\n对于小规模数据或基本有序的数据，冒泡排序可能比快速排序更简单、更直观。\n冒泡排序是稳定排序算法，相对于快速排序的不稳定性，在某些情况下可能更适合要求稳定性的场景。\n冒泡排序是原地排序算法，不需要额外的空间，适合空间复杂度要求严格的场景。\n\n# 如果要对一个很大的数据集，进行排序，而没办法一次性在内存排序，这时候怎么办？可以使用外部排序来解决，基本思路分为两个阶段。\n\n\n\n\n\n\n\n\n\n部分排序阶段。\n我们根据内存大小，将待排序的文件拆成多个部分，使得每个部分都是足以存入内存中的。然后选择合适的内排序算法，将多个文件部分排序，并输出到容量可以更大的外存临时文件中，每个临时文件都是有序排列的，我们将其称之为一个“顺段”。\n在第一个阶段部分排序中，由于内存可以装下每个顺段的所有元素，可以使用快速排序，时间复杂度是O(nlogn)。\n\n\n\n\n\n\n\n\n\n归并阶段\n我们对前面的多个“顺段”进行合并，思想和归并排序其实是一样的。以 2 路归并为例，每次都将两个连续的顺段合并成一个更大的顺段。\n因为内存限制，每次可能只能读入两个顺段的部分内容，所以我们需要一部分一部分读入，在内存里将可以确定顺序的部分排列，并输出到外存里的文件中，不断重复这个过程，直至两个顺段被完整遍历。这样经过多层的归并之后，最终会得到一个完整的顺序文件。\n\n归并阶段有个非常大的时间消耗就是 IO，也就是输入输出。最好就是让归并的层数越低越好，为了降低降低归并层数，可以使用败者树。\n败者树中的非终端结点中存储的是胜利（左右孩子相比较，谁最小即为胜者）的一方；而败者树中的非终端结点存储的是失败的一方。而在比较过程中，都是拿胜者去比较。\n\n现在有了败者树的加持，多路归并排序就可以比较高效地解决外部排序的问题了。\n大致思路就是：\n\n先用内排序算法（比如快速排序），尽可能多的加载源文件，将其变成 n 个有序顺段。\n在内存有限的前提下每 k 个文件为一组，每次流式地从各个文件中读取一个单词，借助败者树选出字典序最低的一个，输出到文件中，这样就可以将 k 个顺段合并到一个顺段中了；反复执行这样的操作，直至所有顺段被归并到同一个顺段。\n\n\n","slug":"数据结构与算法","date":"2024-12-04T04:38:03.000Z","categories_index":"数据结构与算法","tags_index":"数据结构与算法,精选","author_index":"Ivan"},{"id":"8c6c59136f9c0c8c29b87ea646eed9d1","title":"操作系统","content":"# 操作系统# 用户态和内核态# 用户态和内核态的区别？内核态和用户态是操作系统中的两种运行模式。它们的主要区别在于权限和可执行的操作：\n\n内核态（Kernel Mode）：在内核态下，CPU可以执行所有的指令和访问所有的硬件资源。这种模式下的操作具有更高的权限，主要用于操作系统内核的运行。\n用户态（User Mode）：在用户态下，CPU只能执行部分指令集，无法直接访问硬件资源。这种模式下的操作权限较低，主要用于运行用户程序。\n\n内核态的底层操作主要包括：内存管理、进程管理、设备驱动程序控制、系统调用等。这些操作涉及到操作系统的核心功能，需要较高的权限来执行。\n分为内核态和用户态的原因主要有以下几点：\n\n安全性：通过对权限的划分，用户程序无法直接访问硬件资源，从而避免了恶意程序对系统资源的破坏。\n稳定性：用户态程序出现问题时，不会影响到整个系统，避免了程序故障导致系统崩溃的风险。\n隔离性：内核态和用户态的划分使得操作系统内核与用户程序之间有了明确的边界，有利于系统的模块化和维护。\n\n内核态和用户态的划分有助于保证操作系统的安全性、稳定性和易维护性。\n# 进程管理# 线程和进程的区别是什么？\n\n本质区别：进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位\n在开销方面：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小\n稳定性方面：进程中某个线程如果崩溃了，可能会导致整个进程都崩溃。而进程中的子进程崩溃，并不会影响其他进程。\n内存分配方面：系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言，除了CPU外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源\n包含关系：没有线程的进程可以看做是单线程的，如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线\n\n# 进程，线程，协程的区别是什么？\n首先，我们来谈谈进程。进程是操作系统中进行资源分配和调度的基本单位，它拥有自己的独立内存空间和系统资源。每个进程都有独立的堆和栈，不与其他进程共享。进程间通信需要通过特定的机制，如管道、消息队列、信号量等。由于进程拥有独立的内存空间，因此其稳定性和安全性相对较高，但同时上下文切换的开销也较大，因为需要保存和恢复整个进程的状态。\n接下来是线程。线程是进程内的一个执行单元，也是CPU调度和分派的基本单位。与进程不同，线程共享进程的内存空间，包括堆和全局变量。线程之间通信更加高效，因为它们可以直接读写共享内存。线程的上下文切换开销较小，因为只需要保存和恢复线程的上下文，而不是整个进程的状态。然而，由于多个线程共享内存空间，因此存在数据竞争和线程安全的问题，需要通过同步和互斥机制来解决。\n最后是协程。协程是一种用户态的轻量级线程，其调度完全由用户程序控制，而不需要内核的参与。协程拥有自己的寄存器上下文和栈，但与其他协程共享堆内存。协程的切换开销非常小，因为只需要保存和恢复协程的上下文，而无需进行内核级的上下文切换。这使得协程在处理大量并发任务时具有非常高的效率。然而，协程需要程序员显式地进行调度和管理，相对于线程和进程来说，其编程模型更为复杂。\n\n# 为什么进程崩溃不会对其他进程产生很大影响主要是因为：\n\n进程隔离性：每个进程都有自己独立的内存空间，当一个进程崩溃时，其内存空间会被操作系统回收，不会影响其他进程的内存空间。这种进程间的隔离性保证了一个进程崩溃不会直接影响其他进程的执行。\n进程独立性：每个进程都是独立运行的，它们之间不会共享资源，如文件、网络连接等。因此，一个进程的崩溃通常不会对其他进程的资源产生影响。\n\n# 你说到进程是分配资源的基本单位，那么这个资源指的是什么？虚拟内存、文件句柄、信号量等资源。\n# 讲下为什么进程之下还要设计线程？我们举个例子，假设你要编写一个视频播放器软件，那么该软件功能的核心模块有三个：\n\n从视频文件当中读取数据；\n对读取的数据进行解压缩；\n把解压缩后的视频数据播放出来；\n\n对于单进程的实现方式，我想大家都会是以下这个方式：\n\n对于单进程的这种方式，存在以下问题：\n\n播放出来的画面和声音会不连贯，因为当 CPU 能力不够强的时候，Read 的时候可能进程就等在这了，这样就会导致等半天才进行数据解压和播放；\n各个函数之间不是并发执行，影响资源的使用效率；\n\n那改进成多进程的方式：\n\n对于多进程的这种方式，依然会存在问题：\n\n进程之间如何通信，共享数据？\n维护进程的系统开销较大，如创建进程时，分配资源、建立 PCB；终止进程时，回收资源、撤销 PCB；进程切换时，保存当前进程的状态信息；\n\n那到底如何解决呢？需要有一种新的实体，满足以下特性：\n\n实体之间可以并发运行；\n实体之间共享相同的地址空间；\n\n这个新的实体，就是线程( Thread **)**，线程之间可以并发运行且共享相同的地址空间。\n# 多线程比单线程的优势，劣势？\n多线程比单线程的优势：提高程序的运行效率，可以充分利用多核处理器的资源，同时处理多个任务，加快程序的执行速度。\n多线程比单线程的劣势：存在多线程数据竞争访问的问题，需要通过锁机制来保证线程安全，增加了加锁的开销，并且还会有死锁的风险。多线程会消耗更多系统资源，如CPU和内存，因为每个线程都需要占用一定的内存和处理时间。\n\n# 多线程是不是越多越好，太多会有什么问题？多线程不一定越多越好，过多的线程可能会导致一些问题。\n\n切换开销：线程的创建和切换会消耗系统资源，包括内存和CPU。如果创建太多线程，会占用大量的系统资源，导致系统负载过高，某个线程崩溃后，可能会导致进程崩溃。\n死锁的问题：过多的线程可能会导致竞争条件和死锁。竞争条件指的是多个线程同时访问和修改共享资源，如果没有合适的同步机制，可能会导致数据不一致或错误的结果。而死锁则是指多个线程相互等待对方释放资源，导致程序无法继续执行。\n\n# 进程切换和线程切换的区别？\n进程切换：进程切换涉及到更多的内容，包括整个进程的地址空间、全局变量、文件描述符等。因此，进程切换的开销通常比线程切换大。\n线程切换：线程切换只涉及到线程的堆栈、寄存器和程序计数器等，不涉及进程级别的资源，因此线程切换的开销较小。\n\n# 线程切换为什么比进程切换快，节省了什么资源？线程切换比进程切换快是因为线程共享同一进程的地址空间和资源，线程切换时只需切换堆栈和程序计数器等少量信息，而不需要切换地址空间，避免了进程切换时需要切换内存映射表等大量资源的开销，从而节省了时间和系统资源。\n# 线程切换详细过程是怎么样的？上下文保存在哪里？\n线程切换的详细过程可以分为以下几个步骤：\n\n上下文保存：当操作系统决定切换到另一个线程时，它首先会保存当前线程的上下文信息。上下文信息包括寄存器状态、程序计数器、堆栈指针等，用于保存线程的执行状态。\n切换到调度器：操作系统将执行权切换到调度器（Scheduler）。调度器负责选择下一个要执行的线程，并根据调度算法做出决策。\n上下文恢复：调度器选择了下一个要执行的线程后，它会从该线程保存的上下文信息中恢复线程的执行状态。\n切换到新线程：调度器将执行权切换到新线程，使其开始执行。\n\n上下文信息的保存通常由操作系统负责管理，具体保存在哪里取决于操作系统的实现方式。一般情况下，上下文信息会保存在线程的控制块（Thread Control Block，TCB）中。\nTCB是操作系统用于管理线程的数据结构，包含了线程的状态、寄存器的值、堆栈信息等。当发生线程切换时，操作系统会通过切换TCB来保存和恢复线程的上下文信息。\n# 进程的状态（五种状态），如何切换？一个完整的进程状态的变迁如下图：\n\n进程五种状态的变迁\n再来详细说明一下进程的状态变迁：\n\nNULL -&gt; 创建状态：一个新进程被创建时的第一个状态；\n创建状态 -&gt; 就绪状态：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；\n就绪态 -&gt; 运行状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；\n运行状态 -&gt; 结束状态：当进程已经运行完成或出错时，会被操作系统作结束状态处理；\n运行状态 -&gt; 就绪状态：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；\n运行状态 -&gt; 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I&#x2F;O 事件；\n阻塞状态 -&gt; 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；\n\n# 进程上下文有哪些？各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。\n在详细说进程上下文切换前，我们先来看看 CPU 上下文切换\n大多数操作系统都是多任务，通常支持大于 CPU 数量的任务同时运行。实际上，这些任务并不是同时运行的，只是因为系统在很短的时间内，让各个任务分别在 CPU 运行，于是就造成同时运行的错觉。\n任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。\n所以，操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器。\nCPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存（缓存）。我举个例子，寄存器像是你的口袋，内存像你的书包，硬盘则是你家里的柜子，如果你的东西存放到口袋，那肯定是比你从书包或家里柜子取出来要快的多。\n再来，程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。\n所以说，CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 CPU 上下文。\n既然知道了什么是 CPU 上下文，那理解 CPU 上下文切换就不难了。\nCPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。\n系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行.\n上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：进程上下文切换、线程上下文切换和中断上下文切换。\n\n\n\n\n\n\n\n\n\n进程的上下文切换到底是切换什么呢？\n进程是由内核管理和调度的，所以进程的切换只能发生在内核态。\n所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。\n通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：\n\n大家需要注意，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。\n# 进程间通讯有哪些方式？Linux 内核提供了不少进程间通信的方式：\n\n管道\n消息队列\n共享内存\n信号\n信号量\nsocket\n\n\nLinux 内核提供了不少进程间通信的方式，其中最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。\n匿名管道顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「|」竖线就是匿名管道，通信的数据是无格式的流并且大小受限，通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来匿名管道是只能用于存在父子关系的进程间通信，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。\n命名管道突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。\n消息队列克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。\n共享内存可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，它直接分配一个共享空间，每个进程都可以直接访问，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有最快的进程间通信方式之名。但是便捷高效的共享内存通信，带来新的问题，多进程竞争同个共享资源会造成数据的错乱。\n那么，就需要信号量来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。信号量不仅可以实现访问的互斥性，还可以实现进程间的同步，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作。\n与信号量名字很相似的叫信号，它俩名字虽然相似，但功能一点儿都不一样。信号是异步通信机制，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SIGSTOP，这是为了方便我们能在任何时候结束或停止某个进程。\n前面说到的通信机制，都是工作于同一台主机，如果要与不同主机的进程间通信，那么就需要 Socket 通信了。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。\n# 管道有几种方式？管道在Linux中有两种方式：匿名管道和命名管道。\n\n匿名管道：是一种在父子进程或者兄弟进程之间进行通信的机制，只能用于具有亲缘关系的进程间通信，通常通过pipe系统调用创建。\n命名管道：是一种允许无关的进程间进行通信的机制，基于文件系统，可以在不相关的进程之间进行通信。\n\n# 信号和信号量有什么区别？\n信号：一种处理异步事件的方式。信号是比较复杂的通信方式，用于通知接收进程有某种事件发生，除了用于进程外，还可以发送信号给进程本身。\n信号量：进程间通信处理同步互斥的机制。是在多线程环境下使用的一种设施，它负责协调各个线程，以保证它们能够正确，合理的使用公共资源。\n\n# 共享内存怎么实现的？共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。\n\n# 线程间通讯有什么方式？Linux系统提供了五种用于线程通信的方式：互斥锁、读写锁、条件变量、自旋锁和信号量。\n\n互斥锁（Mutex）：互斥量(mutex)从本质上说是一把锁，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量上的锁。对互斥量进行加锁以后，任何其他试图再次对互斥锁加锁的线程将会阻塞直到当前线程释放该互斥锁。如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可运行状态，第一个变为运行状态的线程可以对互斥锁加锁，其他线程将会看到互斥锁依然被锁住，只能回去再次等待它重新变为可用。\n条件变量（Condition Variables）：条件变量(cond)是在多线程程序中用来实现”等待–》唤醒”逻辑常用的方法。条件变量利用线程间共享的全局变量进行同步的一种机制，主要包括两个动作：一个线程等待”条件变量的条件成立”而挂起；另一个线程使“条件成立”。为了防止竞争，条件变量的使用总是和一个互斥锁结合在一起。线程在改变条件状态前必须首先锁住互斥量，函数pthread_cond_wait把自己放到等待条件的线程列表上，然后对互斥锁解锁(这两个操作是原子操作)。在函数返回时，互斥量再次被锁住。\n自旋锁（Spinlock）：自旋锁通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。一般加锁的过程，包含两个步骤：第一步，查看锁的状态，如果锁是空闲的，则执行第二步；第二步，将锁设置为当前线程持有；使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。CAS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。这里的「忙等待」可以用 while 循环等待实现，不过最好是使用 CPU 提供的 PAUSE 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。\n信号量（Semaphores）：信号量可以是命名的（有名信号量）或无名的（仅限于当前进程内的线程），用于控制对资源的访问次数。通常信号量表示资源的数量，对应的变量是一个整型（sem）变量。另外，还有两个原子操作的系统调用函数来控制信号量的，分别是：P 操作：将 sem 减 1，相减后，如果 sem &lt; 0，则进程&#x2F;线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；V 操作：将 sem 加 1，相加后，如果 sem &lt;&#x3D; 0，唤醒一个等待中的进程&#x2F;线程，表明 V 操作不会阻塞；\n读写锁（Read-Write Locks）：读写锁从字面意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。所以，读写锁适用于能明确区分读操作和写操作的场景。读写锁的工作原理是：当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。知道了读写锁的工作原理后，我们可以发现，读写锁在读多写少的场景，能发挥出优势。\n\n# 除了互斥锁你还知道什么锁？分别应用于什么场景？还有读写锁、自旋锁、条件变量、信号量。\n\n读写锁：读写锁允许多个线程同时读取共享资源，但只允许一个线程进行写操作。适用于读操作频繁、写操作较少的场景，可以提高并发性能。\n自旋锁：自旋锁是一种忙等待锁，线程在获取锁时不会进入阻塞状态，而是循环忙等待直到获取到锁。适用于临界区很小且锁的持有时间很短的场景，避免线程频繁切换带来的开销。\n条件变量：条件变量用于线程间的同步和通信。它通常与互斥锁一起使用，线程可以通过条件变量等待某个条件满足，当条件满足时，其他线程可以通过条件变量发送信号通知等待线程。\n信号量：信号量是一种计数器，用于控制对共享资源的访问。它可以用来限制同时访问资源的线程数量，或者用于线程间的同步。\n\n# 进程调度算法有哪些？\n\n\n\n\n\n\n\n\n先来先服务调度算法\n最简单的一个调度算法，就是非抢占式的先来先服务（First Come First Severd, FCFS）算法了。\n 顾名思义，先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。\n这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。 FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I&#x2F;O 繁忙型作业的系统。\n\n\n\n\n\n\n\n\n\n最短作业优先调度算法\n最短作业优先（Shortest Job First, SJF）调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。\n\n这显然对长作业不利，很容易造成一种极端现象。\n比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。\n\n\n\n\n\n\n\n\n\n高响应比优先调度算法\n前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。\n那么，高响应比优先 （Highest Response Ratio Next, HRRN）调度算法主要是权衡了短作业和长作业。\n每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：\n\n从上面的公式，可以发现：\n\n如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；\n如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；\n\n\n\n\n\n\n\n\n\n\n时间片轮转调度算法\n最古老、最简单、最公平且使用最广的算法就是时间片轮转（Round Robin, RR）调度算法。\n 每个进程被分配一个时间段，称为时间片（Quantum)，即允许该进程在该时间段中运行。\n\n如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；\n如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；\n\n另外，时间片的长度就是一个很关键的点：\n\n如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；\n如果设得太长又可能引起对短作业进程的响应时间变长。将\n\n通常时间片设为 20ms~50ms 通常是一个比较合理的折中值。\n\n\n\n\n\n\n\n\n\n最高优先级调度算法\n前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。\n但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法。 进程的优先级可以分为，静态优先级或动态优先级：\n\n静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；\n动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。\n\n该算法也有两种处理优先级高的方法，非抢占式和抢占式：\n\n非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。\n抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。\n\n但是依然有缺点，可能会导致低优先级的进程永远不会运行。\n\n\n\n\n\n\n\n\n\n多级反馈队列调度算法\n多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。\n顾名思义：\n\n「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。\n「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；\n\n 来看看，它是如何工作的：\n\n设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短；\n新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；\n当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；\n\n可以发现，对于短作业可能可以在第一级队列很快被处理完。\n对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。\n# 锁# 为什么并发执行线程要加锁？并发执行线程需要加锁主要是为了保护共享数据，防止出现”竞态条件”。\n“竞态条件”是指当多个线程同时访问和操作同一块数据时，最终结果依赖于线程的执行顺序，这可能导致数据的不一致性。\n通过加锁，我们可以确保在任何时刻只有一个线程能够访问共享数据，从而避免”竞态条件”，确保数据的一致性和完整性。\n# 自旋锁是什么？应用在哪些场景？自旋锁加锁失败后，线程会忙等待，直到它拿到锁。\n自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。\n一般加锁的过程，包含两个步骤：\n\n第一步，查看锁的状态，如果锁是空闲的，则执行第二步；\n第二步，将锁设置为当前线程持有；\n\nCAS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。\n比如，设锁为变量 lock，整数 0 表示锁是空闲状态，整数 pid 表示线程 ID，那么 CAS(lock, 0, pid) 就表示自旋锁的加锁操作，CAS(lock, pid, 0) 则表示解锁操作。\n使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 while 循环等待实现，不过最好是使用 CPU 提供的 PAUSE 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。\n自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。\n自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。\n自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对。\n如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。\n# 死锁发生条件是什么？死锁只有同时满足以下四个条件才会发生：\n\n互斥条件：互斥条件是指多个线程不能同时使用同一个资源。\n持有并等待条件：持有并等待条件是指，当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1。\n不可剥夺条件：不可剥夺条件是指，当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。\n环路等待条件：环路等待条件指的是，在死锁发生的时候，两个线程获取资源的顺序构成了环形链。\n\n# 如何避免死锁？避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是使用资源有序分配法，来破环环路等待条件。\n那什么是资源有序分配法呢？线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。\n\n# 讲一下银行家算法系统发生死锁是很正常的，我们需要主动去预防死锁，即进行有序的资源分配，使用银行家算法。\n银行家算法是最有代表性的避免死锁的算法。\n为什么叫银行家算法呢？就是这个算法的逻辑很像银行放贷的逻辑，也就是尽可能避免坏账的出现。\n银行家算法的业务逻辑如下。\n\n不负荷执行：一个进程的最大需求量不超过系统拥有的总资源数，才会被接纳执行。\n可分期：一个进程可以分期请求资源，但总请求书不可超过最大需求量。\n推迟分配：当系统现有资源数小于进程需求时，对进程的需求可以延迟分配，但总让进程在有限时间内获取资源。\n\n听起来有点绕，我们还是举个例子来说明。\n假如系统中有三类互斥资源 R1、R2、R3，可用资源数分别是 9、8、5，在指定时刻有 P1、P2、P3、P4 和 P5 这五个进程，这些进程的对三类互斥资源的最大需求量和已分配资源数如下表所示，那么系统如何先后运行这五个进程，不会发生死锁问题？\n\n\n\n进程\n最大需求量（分别为R1 R2 R3）\n已分配资源数（分别为R1 R2 R3）\n\n\n\nP1\n6 5 2\n1 2 1\n\n\nP2\n2 2 1\n2 1 1\n\n\nP3\n8 1 1\n2 1 0\n\n\nP4\n1 2 1\n1 2 0\n\n\nP5\n3 4 4\n1 1 3\n\n\n\n第一步：分析\n首先分析首次需求的资源，系统剩余可用资源数分别是 2、1、0，各进程需要的资源数如下表所示。\n资源 R1 的剩余可用资源数 &#x3D; 9 - 1 - 2 - 2 - 1 - 1 &#x3D; 2。\n资源 R2 的剩余可用资源数 &#x3D; 8 - 2 - 1 - 1 - 2 - 1 &#x3D; 1。\n资源 R3 的剩余可用资源数 &#x3D; 5 - 1 - 1 - 0 - 0 - 3 &#x3D; 0。\n\n\n\n进程\n最大需求量\n已分配资源数\n首次分配需要的资源数\n\n\n\nP1\n6 5 2\n1 2 1\n5 3 1\n\n\nP2\n2 2 1\n2 1 1\n0 1 0\n\n\nP3\n8 1 1\n2 1 0\n6 0 1\n\n\nP4\n1 2 1\n1 2 0\n0 0 1\n\n\nP5\n3 4 4\n1 1 3\n2 3 1\n\n\n根据银行家算法不负荷原则【一个进程的最大需求量不超过系统拥有的总资源数，才会被接纳执行】，优先给进程 P2 执行，因为剩余的 0 1 0 资源够让 P2 执行。\n第二步：执行 P2\nP2 执行之后，释放了刚刚放入的 2 1 0 资源，而且可以释放已分配的 2 1 1 资源，所以此时的资源剩余量。\n资源 R1 的剩余可用资源数 &#x3D; 原资源数 - 执行 P2 消耗数 + P2 执行完释放的资源数 &#x3D; 2 - 0 +（2 + 0） &#x3D; 4。\n资源 R2 的剩余可用资源数 &#x3D; 原资源数 - 执行 P2 消耗数 + P2 执行完释放的资源数 &#x3D; 1 - 1 + （1 + 1） &#x3D; 2。\n资源 R3 的剩余可用资源数 &#x3D; 原资源数 - 执行 P2 消耗数 + P2 执行完释放的资源数 &#x3D; 0 - 0 +（0 + 1） &#x3D; 1。\n执行完成 P2 后，操作系统剩余可用资源数为 4 2 1。\n\n\n\n进程\n最大需求量\n已分配资源数\n第二次分配需要的资源数\n\n\n\nP1\n6 5 2\n1 2 1\n5 3 1\n\n\nP2\n完成\n完成\n完成\n\n\nP3\n8 1 1\n2 1 0\n6 0 1\n\n\nP4\n1 2 1\n1 2 0\n0 0 1\n\n\nP5\n3 4 4\n1 1 3\n2 3 1\n\n\n\n第三步：执行 P4\n此时操作系统剩余可用资源数为 4 2 1，只能执行进程 P4，因为其他进程资源不够。\nP4 执行之后，释放了刚刚放入的 0 0 1 资源，而且可以释放已分配的 1 2 1 资源，所以此时的资源剩余量。\n资源 R1 的剩余可用资源数 &#x3D; 原资源数 - 执行 P4 消耗数 + P4 执行完释放的资源数 &#x3D; 4 - 0 +（1 + 0） &#x3D; 5。\n资源 R2 的剩余可用资源数 &#x3D; 原资源数 - 执行 P4 消耗数 + P4 执行完释放的资源数 &#x3D; 2 - 0 + （2 + 0） &#x3D; 4。\n资源 R3 的剩余可用资源数 &#x3D; 原资源数 - 执行 P4 消耗数 + P4 执行完释放的资源数 &#x3D; 1 - 1 +（1 + 1） &#x3D; 2。\n执行完成 P4 后，操作系统剩余可用资源数为 5 4 2。\n\n\n\n进程\n最大需求量\n已分配资源数\n第三次分配需要的资源数\n\n\n\nP1\n6 5 2\n1 2 1\n5 3 1\n\n\nP2\n完成\n完成\n完成\n\n\nP3\n8 1 1\n2 1 0\n6 0 1\n\n\nP4\n完成\n完成\n完成\n\n\nP5\n3 4 4\n1 1 3\n2 3 1\n\n\n\n第四步：执行 P5\n此时操作系统剩余可用资源数为 5 4 2，只能执行进程 P5，因为其他进程资源不够。\nP5 执行之后，释放了刚刚放入的 2 3 1 资源，而且可以释放已分配的 1 1 3 资源，所以此时的资源剩余量。\n资源 R1 的剩余可用资源数 &#x3D; 原资源数 - 执行 P5 消耗数 + P5 执行完释放的资源数 &#x3D; 5 - 2 +（1 + 2） &#x3D; 6。\n资源 R2 的剩余可用资源数 &#x3D; 原资源数 - 执行 P5 消耗数 + P5 执行完释放的资源数 &#x3D; 4 - 3 + （1 + 3） &#x3D; 5。\n资源 R3 的剩余可用资源数 &#x3D; 原资源数 - 执行 P5 消耗数 + P5 执行完释放的资源数 &#x3D; 2 - 1 +（3 + 1） &#x3D; 5。\n执行完成 P5 后，操作系统剩余可用资源数为 6 5 5。\n\n\n\n进程\n最大需求量\n已分配资源数\n第三次分配需要的资源数\n\n\n\nP1\n6 5 2\n1 2 1\n5 3 1\n\n\nP2\n完成\n完成\n完成\n\n\nP3\n8 1 1\n2 1 0\n6 0 1\n\n\nP4\n完成\n完成\n完成\n\n\nP5\n完成\n完成\n完成\n\n\n\n第五步：执行 P1 或者 P3\n此时操作系统剩余可用资源数为 6 5 5，可以执行 P1 或 P3。\n所以安全执行顺序为 p2 &#x3D;&gt; p4 &#x3D;&gt; p5 &#x3D;&gt; p1 &#x3D;&gt; p3 或 p2 &#x3D;&gt; p4 &#x3D;&gt; p5 &#x3D;&gt; p3 &#x3D;&gt; p1。\n\n或\n\n银行家算法总结\n银行家算法的核心思想，就是在分配给进程资源前，首先判断这个进程的安全性，也就是预执行，判断分配后是否产生死锁现象。如果系统当前资源能满足其执行，则尝试分配，如果不满足则让该进程等待。\n**通过不断检查剩余可用资源是否满足某个进程的最大需求，如果可以则加入安全序列，并把该进程当前持有的资源回收；不断重复这个过程，看最后能否实现让所有进程都加入安全序列。**安全序列一定不会发生死锁，但没有死锁不一定是安全序列。\n# 乐观锁和悲观锁有什么区别？乐观锁：\n\n基本思想：乐观锁假设多个事务之间很少发生冲突，因此在读取数据时不会加锁，而是在更新数据时检查数据的版本（如使用版本号或时间戳），如果版本匹配则执行更新操作，否则认为发生了冲突。\n使用场景：乐观锁适用于读多写少的场景，可以减少锁的竞争，提高并发性能。例如，数据库中的乐观锁机制可以用于处理并发更新同一行数据的情况。\n\n悲观锁：\n\n基本思想：悲观锁假设多个事务之间会频繁发生冲突，因此在读取数据时会加锁，防止其他事务对数据进行修改，直到当前事务完成操作后才释放锁。\n使用场景：悲观锁适用于写多的场景，通过加锁保证数据的一致性。例如，数据库中的行级锁机制可以用于处理并发更新同一行数据的情况。\n\n乐观锁适用于读多写少的场景，通过版本控制来处理冲突；而悲观锁适用于写多的场景，通过加锁来避免冲突。\n# 内存管理# 介绍一下操作系统内存管理操作系统设计了虚拟内存，每个进程都有自己的独立的虚拟内存，我们所写的程序不会直接与物理内打交道。\n\n有了虚拟内存之后，它带来了这些好处：\n\n第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。\n第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。\n第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。\n\nLinux 是通过对内存分页的方式来管理内存，分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。\n虚拟地址与物理地址之间通过页表来映射，如下图：\n\n页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。\n而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。\n# 什么是虚拟内存和物理内存？\n虚拟内存：是操作系统提供给每个运行中程序的一种地址空间，每个程序在运行时认为自己拥有的内存空间就是虚拟内存，其大小可以远远大于物理内存的大小。虚拟内存通过将程序的地址空间划分成若干个固定大小的页或段，并将这些页或者段映射到物理内存中的不同位置，从而使得程序在运行时可以更高效地利用物理内存。\n物理内存：物理内存是计算机实际存在的内存，是计算机中的实际硬件部件。\n\n# 讲一下页表？分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。\n虚拟地址与物理地址之间通过页表来映射，如下图：\n\n页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。\n而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。\n内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。\n但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有内部内存碎片的现象。\n在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。\n\n总结一下，对于一个内存地址转换，其实就是这样三个步骤：\n\n把虚拟内存地址，切分成页号和偏移量；\n根据页号，从页表里面，查询对应的物理页号；\n直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。\n\n下面举个例子，虚拟内存中的页通过页表映射为了物理内存中的页，如下图：\n\n# 讲一下段表？虚拟地址也可以通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：\n\n如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 &#x3D; 7500。\n# 虚拟地址是怎么转化到物理地址的？虚拟地址转化为物理地址是通过内存管理单元（Memory Management Unit，MMU）来完成的。MMU是计算机系统中的硬件组件，负责虚拟地址和物理地址之间的转换。\n在虚拟地址转换的过程中，通常会使用页表（Page Table）来进行映射。页表是一种数据结构，它将虚拟地址空间划分为固定大小的页（Page），对应于物理内存中的页框（Page Frame）。每个页表项（Page Table Entry）记录了虚拟页和物理页的对应关系。\n当程序访问一个虚拟地址时，MMU会将虚拟地址分解为页号和页内偏移量。然后，MMU会查找页表，根据页号找到对应的页表项。页表项中包含了物理页的地址或页框号。最后，MMU将物理页的地址与页内偏移量组合，得到对应的物理地址。\n虚拟地址转化为物理地址的过程中，还可能涉及到多级页表、TLB（Translation Lookaside Buffer）缓存等机制，以提高地址转换的效率。\n\n# 程序的内存布局是怎么样的？\n通过这张图你可以看到，用户空间内存，从低到高分别是 6 种不同的内存段：\n\n代码段，包括二进制可执行代码；\n数据段，包括已初始化的静态常量和全局变量；\nBSS 段，包括未初始化的静态变量和全局变量；\n堆段，包括动态分配的内存，从低地址开始向上增长；\n文件映射段，包括动态库、共享内存等；\n栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；\n\n上图中的内存布局可以看到，代码段下面还有一段内存空间的（灰色部分），这一块区域是「保留区」，之所以要有保留区这是因为在大多数的系统里，我们认为比较小数值的地址不是一个合法地址，例如，我们通常在 C 的代码里会将无效的指针赋值为 NULL。因此，这里会出现一段不可访问的内存保留区，防止程序因为出现 bug，导致读或写了一些小内存地址的数据，而使得程序跑飞。\n在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存。\n# 堆和栈的区别？\n分配方式：堆是动态分配内存，由程序员手动申请和释放内存，通常用于存储动态数据结构和对象。栈是静态分配内存，由编译器自动分配和释放内存，用于存储函数的局部变量和函数调用信息。\n内存管理：堆需要程序员手动管理内存的分配和释放，如果管理不当可能会导致内存泄漏或内存溢出。栈由编译器自动管理内存，遵循后进先出的原则，变量的生命周期由其作用域决定，函数调用时分配内存，函数返回时释放内存。\n大小和速度：堆通常比栈大，内存空间较大，动态分配和释放内存需要时间开销。栈大小有限，通常比较小，内存分配和释放速度较快，因为是编译器自动管理。\n\n# fork()会复制哪些东西？\nfork 阶段会复制父进程的页表（虚拟内存）\nfork 之后，如果发生了写时复制，就会复制物理内存\n\n# 介绍copy on write(写时复制)主进程在执行 fork 的时候，操作系统会把主进程的「页表」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。\n\n这样一来，子进程就共享了父进程的物理内存数据了，这样能够节约物理内存资源，页表对应的页表项的属性会标记该物理内存的权限为只读。\n不过，当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发写保护中断，这个写保护中断是由于违反权限导致的，然后操作系统会在「写保护中断处理函数」里进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写，最后才会对内存进行写操作，这个过程被称为「**写时复制(Copy On Write)**」。\n写时复制顾名思义，在发生写操作的时候，操作系统才会去复制物理内存，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。\n# copy on write节省了什么资源？节省了物理内存的资源，因为 fork 的时候，子进程不需要复制父进程的物理内存，避免了不必要的内存复制开销，子进程只需要复制父进程的页表，这时候父子进程的页表指向的都是共享的物理内存。\n只有当父子进程任何有一方对这片共享的物理内存发生了修改操作，才会触发写时复制机制，这时候才会复制发生修改操作的物理内存。\n# malloc 1KB和1MB 有什么区别？malloc() 源码里默认定义了一个阈值：\n\n如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；\n如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；\n\n注意，不同的 glibc 版本定义的阈值也是不同的。\n# 介绍一下brk，mmap实际上，malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。\nmalloc 申请内存的时候，会有两种方式向操作系统申请堆内存。\n\n方式一：通过 brk() 系统调用从堆分配内存\n方式二：通过 mmap() 系统调用在文件映射区域分配内存；\n\n方式一实现的方式很简单，就是通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间。如下图：\n\n方式二通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。如下图：\n\n# 操作系统内存不足的时候会发生什么？应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。\n当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生缺页中断，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。\n缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。\n如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。\n\n后台内存回收（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。\n直接内存回收（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。\n\n如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——触发 OOM （Out of Memory）机制。\nOOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。\n申请物理内存的过程如下图：\n\n系统内存紧张的时候，就会进行回收内存的工作，那具体哪些内存是可以被回收的呢？\n主要有两类内存可以被回收，而且它们的回收方式也不同。\n\n文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存。\n匿名页（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。\n\n文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中：\n\nactive_list 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；\ninactive_list 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；\n\n越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。\n# 页面置换有哪些算法？页面置换算法的功能是，当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。\n那其算法目标则是，尽可能减少页面的换入换出的次数，常见的页面置换算法有如下几种：\n\n最佳页面置换算法（OPT）\n先进先出置换算法（FIFO）\n最近最久未使用的置换算法（LRU）\n时钟页面置换算法（Lock）\n最不常用置换算法（LFU）\n\n\n\n\n\n\n\n\n\n\n最佳页面置换算法\n最佳页面置换算法基本思路是，置换在「未来」最长时间不访问的页面。\n所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。\n我们举个例子，假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图：\n\n在这个请求的页面序列中，缺页共发生了 7 次（空闲页换入 3 次 + 最优页面置换 4 次），页面置换共发生了 4 次。\n这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。\n所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。\n\n\n\n\n\n\n\n\n\n先进先出置换算法\n既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以选择在内存驻留时间很长的页面进行中置换，这个就是「先进先出置换」算法的思想。\n还是以前面的请求的页面序列作为例子，假设使用先进先出置换算法，则过程如下图：\n\n在这个请求的页面序列中，缺页共发生了 10 次，页面置换共发生了 7 次，跟最佳页面置换算法比较起来，性能明显差了很多。\n\n\n\n\n\n\n\n\n\n最近最久未使用的置换算法\n最近最久未使用（LRU）的置换算法的基本思路是，发生缺页时，选择最长时间没有被访问的页面进行置换，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。\n这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。\n还是以前面的请求的页面序列作为例子，假设使用最近最久未使用的置换算法，则过程如下图：\n\n在这个请求的页面序列中，缺页共发生了 9 次，页面置换共发生了 6 次，跟先进先出置换算法比较起来，性能提高了一些。\n虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。\n困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。\n所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。\n\n\n\n\n\n\n\n\n\n时钟页面置换算法\n那有没有一种即能优化置换的次数，也能方便实现的算法呢？\n时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。\n该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。\n当发生缺页中断时，算法首先检查表针指向的页面：\n\n如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；\n如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；\n\n我画了一副时钟页面置换算法的工作流程图，你可以在下方看到：\n\n了解了这个算法的工作方式，就明白为什么它被称为时钟（Clock）算法了。\n\n\n\n\n\n\n\n\n\n最不常用算法\n最不常用（LFU）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。\n它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。\n看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。\n要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。\n但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。\n那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。\n# 中断# 什么是中断？CPU停下当前的工作任务，去处理其他事情，处理完后回来继续执行刚才的任务，这一过程便是中断。\n中断分为外部中断和内部中断：\n\n外部中断分为可屏蔽中断和不可屏蔽中断：\n\n可屏蔽中断：通过INTR线向CPU请求的中断，主要来自外部设备如硬盘，打印机，网卡等。此类中断并不会影响系统运行，可随时处理，甚至不处理，所以名为可屏蔽。\n\n不可屏蔽中断：通过NMI线向CPU请求的中断，如电源掉电，硬件线路故障等。这里不可屏蔽的意思不是不可以屏蔽，不建议屏蔽，而是问题太大，屏蔽不了，不能屏蔽的意思。注：INTR和NMI都是CPU的引脚\n\n\n\n内部中断分为陷阱、故障、终止：\n\n陷阱：是一种有意的，预先安排的异常事件，一般是在编写程序时故意设下的陷阱指令，而后执行到陷阱指令后，CPU将会调用特定程序进行相应的处理，处理结束后返回到陷阱指令的下一条指令。如系统调用，程序调试功能等。如printf函数，最底层的实现中会有一条int 0x80指令，这就是一条陷阱指令，使用0x80号中断进行系统调用。\n\n**故障：故障是在引起故障的指令被执行，但还没有执行结束时，CPU检测到的一类的意外事件。**出错时交由故障处理程序处理，如果能处理修正这个错误，就将控制返回到引起故障的指令即CPU重新执这条指令。如果不能处理就报错。常见的故障为缺页，当CPU引用的虚拟地址对应的物理页不存在时就会发生故障。缺页异常是能够修正的，有着专门的缺页处理程序，它会将缺失的物理页从磁盘中重新调进主存。而后再次执行引起故障的指令时便能够顺利执行了。\n\n**终止：执行指令的过程中发生了致命错误，不可修复，程序无法继续运行，只能终止，通常会是一些硬件的错误。**终止处理程序不会将控制返回给原程序，而是直接终止原程序\n\n\n\n\n# 讲讲中断的流程中断是计算机系统中一种机制，用于在处理器执行指令时暂停当前任务，并转而执行其他任务或处理特定事件。以下是中断的基本流程：\n\n发生中断：当外部设备或者软件程序需要处理器的注意或者响应时，会发出中断信号。处理器在接收到中断信号后，会停止当前执行的指令，保存当前执行现场，并跳转到中断处理程序执行。\n\n中断响应：处理器接收到中断信号后，会根据中断向量表找到对应的中断处理程序的入口地址。 处理器会保存当前执行现场（如程序计数器、寄存器状态等），以便在中断处理完成后能够恢复执行。\n\n中断处理：处理器跳转到中断处理程序的入口地址开始执行中断处理程序。中断处理程序会根据中断类型进行相应的处理，可能涉及到保存现场、处理中断事件、执行特定任务等。\n\n\n# 中断的类型有哪些？中断按事件来源分类，可以分为外部中断和内部中断。中断事件来自于CPU外部的被称为外部中断，来自于CPU内部的则为内部中断。\n进一步细分，外部中断还可分为可屏蔽中断（maskable interrupt）和不可屏蔽中断（non-maskable interrupt）两种，而内部中断按事件是否正常来划分可分为软中断和异常两种。\n\n外部中断的中断事件来源于CPU外部，必然是某个硬件产生的，所以外部中断又被称为硬件中断（hardware interrupt）。计算机的外部设备，如网卡、声卡、显卡等都能产生中断。外部设备的中断信号是通过两根信号线通知CPU的，一根是INTR，另一根是NMI。CPU从INTR收到的中断信号都是不影响系统运行的，CPU可以选择屏蔽（通过设置中断屏蔽寄存器中的IF位），而从NMI中收到的中断信号则是影响系统运行的严重错误，不可屏蔽，因为屏蔽的意义不大，系统已经无法运行。\n内部中断来自于处理器内部，其中软中断是由软件主动发起的中断，常被用于系统调用（system call）；而异常则是指令执行期间CPU内部产生的错误引起的。异常也和不可屏蔽中断一样不受eflags寄存器的IF位影响，区别在于不可屏蔽中断发生的事件会导致处理器无法运行（如断电、电源故障等），而异常则是影响系统正常运行的中断（如除0、越界访问等）。\n\n# 中断的作用是什么？中断使得计算机系统具备应对对处理突发事件的能力，提高了CPU的工作效率，如果没有中断系统，CPU就只能按照原来的程序编写的先后顺序，对各个外设进行查询和处理，即轮询工作方式，轮询方法貌似公平，但实际工作效率却很低，却不能及时响应紧急事件。\n# 网络 i&#x2F;o# 你了解过哪些io模型？\n阻塞I&#x2F;O模型：应用程序发起I&#x2F;O操作后会被阻塞，直到操作完成才返回结果。适用于对实时性要求不高的场景。\n非阻塞I&#x2F;O模型：应用程序发起I&#x2F;O操作后立即返回，不会被阻塞，但需要不断轮询或者使用select&#x2F;poll&#x2F;epoll等系统调用来检查I&#x2F;O操作是否完成。适合于需要进行多路复用的场景，例如需要同时处理多个socket连接的服务器程序。\nI&#x2F;O复用模型：通过select、poll、epoll等系统调用，应用程序可以同时等待多个I&#x2F;O操作，当其中任何一个I&#x2F;O操作准备就绪时，应用程序会被通知。适合于需要同时处理多个I&#x2F;O操作的场景，比如高并发的服务端程序。\n信号驱动I&#x2F;O模型：应用程序发起I&#x2F;O操作后，可以继续做其他事情，当I&#x2F;O操作完成时，操作系统会向应用程序发送信号来通知其完成。适合于需要异步I&#x2F;O通知的场景，可以提高系统的并发能力。\n异步I&#x2F;O模型：应用程序发起I&#x2F;O操作后可以立即做其他事情，当I&#x2F;O操作完成时，应用程序会得到通知。异步I&#x2F;O模型由操作系统内核完成I&#x2F;O操作，应用程序只需等待通知即可。适合于需要大量并发连接和高性能的场景，能够减少系统调用次数，提高系统效率。\n\n# 服务器处理并发请求有哪几种方式？\n单线程web服务器方式：web服务器一次处理一个请求，结束后读取并处理下一个请求，性能比较低，一次只能处理一个请求。\n多进程&#x2F;多线程web服务器：web服务器生成多个进程或线程并行处理多个用户请求，进程或线程可以按需或事先生成。有的web服务器应用程序为每个用户请求生成一个单独的进程或线程来进行响应，不过，一旦并发请求数量达到成千上万时，多个同时运行的进程或线程将会消耗大量的系统资源。（即每个进程只能响应一个请求，并且一个进程对应一个线程）\nI&#x2F;O多路复用web服务器：web服务器可以I&#x2F;O多路复用，达到只用一个线程就能监听和处理多个客户端的 i&#x2F;o 事件。\n多路复用多线程web服务器：将多进程和多路复用的功能结合起来形成的web服务器架构，其避免了让一个进程服务于过多的用户请求，并能充分利用多CPU主机所提供的计算能力。（这种架构可以理解为有多个进程，并且一个进程又生成多个线程，每个线程处理一个请求）\n\n# 讲一下io多路复用IO多路复用是一种IO得处理方式，指的是复用一个线程，处理多个socket中的事件。能够资源复用，防止创建过多线程导致的上下文切换的开销。\n\n# select、poll、epoll 的区别是什么？我们熟悉的 select&#x2F;poll&#x2F;epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。\nselect&#x2F;poll&#x2F;epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。\nselect&#x2F;poll&#x2F;epoll 这是三个多路复用接口，都能实现 C10K 吗？接下来，我们分别说说它们。\n\n\n\n\n\n\n\n\n\nselect&#x2F;poll\nselect 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。\n所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。\nselect 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。\npoll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。\n但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。\n\n\n\n\n\n\n\n\n\nepoll\n先复习下 epoll 的用法。如下的代码中，先用epoll_create 创建一个 epol l对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到epfd中，最后调用 epoll_wait 等待数据。\n12345678910111213int s = socket(AF_INET, SOCK_STREAM, 0);bind(s, ...);listen(s, ...)int epfd = epoll_create(...);epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中while(1) &#123;    int n = epoll_wait(...);    for(接收到数据的socket)&#123;        //处理    &#125;&#125;\n\nepoll 通过两个方面，很好解决了 select&#x2F;poll 的问题。\n\n第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。而 select&#x2F;poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select&#x2F;poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。\n\n第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。\n\n\n从下图你可以看到 epoll 相关的接口作用：\n\nepoll 的方式即使监听的 Socket 数量越多的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题的利器。\n# epoll 的 边缘触发和水平触发有什么区别？epoll 支持两种事件触发模式，分别是边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）。\n这两个术语还挺抽象的，其实它们的区别还是很好理解的。\n\n使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；\n使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；\n\n举个例子，你的快递被放到了一个快递箱里，如果快递箱只会通过短信通知你一次，即使你一直没有去取，它也不会再发送第二条短信提醒你，这个方式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是水平触发的方式。\n这就是两者的区别，水平触发的意思是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。\n如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作。\n如果使用边缘触发模式，I&#x2F;O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK。\n一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。\n# redis，nginx，netty 是依赖什么做的这么高性能？主要是依赖Reactor 模式实现了高性能网络模式，这个是在i&#x2F;o多路复用接口基础上实现的了网络模型。Reactor 翻译过来的意思是「反应堆」，这里的反应指的是「对事件反应」，也就是来了一个事件，Reactor 就有相对应的反应&#x2F;响应。\nReactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：\n\nReactor 负责监听和分发事件，事件类型包含连接事件、读写事件；\n处理资源池负责处理事件，如 read -&gt; 业务逻辑 -&gt; send；\n\nReactor 模式是灵活多变的，可以应对不同的业务场景，灵活在于：\n\nReactor 的数量可以只有一个，也可以有多个；\n处理资源池可以是单个进程 &#x2F; 线程，也可以是多个进程 &#x2F;线程；\n\n\n\n\n\n\n\n\n\n\nRedis\nRedis 6.0 之前使用的 Reactor 模型就是单 Reactor 单进程模式。单 Reactor 单进程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。\n\n但是，这种方案存在 2 个缺点：\n\n第一个缺点，因为只有一个进程，无法充分利用 多核 CPU 的性能；\n第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟；\n\n所以，单 Reactor 单进程的方案不适用计算机密集型的场景，只适用于业务处理非常快速的场景。\nRedis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。\n\n\n\n\n\n\n\n\n\nNetty\nNetty 是采用了多 Reactor 多线程方案，如下图：\n\n多 Reactor 多线程的方案优势：\n\n主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。\n主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。\n\n\n\n\n\n\n\n\n\n\nnginx\nnginx 是多 Reactor 多进程方案，不过方案与标准的多 Reactor 多进程有些差异。\n\n具体差异表现在主进程中仅仅用来初始化 socket，并没有创建 mainReactor 来 accept 连接，而是由子进程的 Reactor 来 accept 连接，通过锁来控制一次只有一个子进程进行 accept（防止出现惊群现象），子进程 accept 新连接后就放到自己的 Reactor 进行处理，不会再分配给其他子进程。\n# 零拷贝是什么？传统 IO 的工作方式，从硬盘读取数据，然后再通过网卡向外发送，我们需要进行 4 上下文切换，和 4 次数据拷贝，其中 2 次数据拷贝发生在内存里的缓冲区和对应的硬件设备之间，这个是由 DMA 完成，另外 2 次则发生在内核态和用户态之间，这个数据搬移工作是由 CPU 完成的。\n\n为了提高文件传输的性能，于是就出现了零拷贝技术，它通过一次系统调用（sendfile 方法）合并了磁盘读取与网络发送两个操作，降低了上下文切换次数。另外，拷贝数据都是发生在内核中的，天然就降低了数据拷贝的次数。\n\n零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。\n总体来看，零拷贝技术可以把文件传输的性能提高至少一倍以上。\n\n","slug":"计网/操作系统面试题","date":"2024-12-04T04:25:14.000Z","categories_index":"八股","tags_index":"精选,操作系统","author_index":"Ivan"},{"id":"293c17b4d2a4292133cc4d1ffd7f8725","title":"计算机网络","content":"# 计算机网络# 网络模型# 网络OSI模型和TCP&#x2F;IP模型分别介绍一下\n\n\n\n\n\n\n\n\nOSI七层模型\n为了使得多种设备能通过网络相互通信，和为了解决各种不同设备在网络互联中的兼容性问题，国际标准化组织制定了开放式系统互联通信参考模型（Open System Interconnection Reference Model），也就是 OSI 网络模型，该模型主要有 7 层，分别是应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层。\n\n每一层负责的职能都不同，如下：\n\n应用层，负责给应用程序提供统一的接口；\n表示层，负责把数据转换成兼容另一个系统能识别的格式；\n会话层，负责建立、管理和终止表示层实体之间的通信会话；\n传输层，负责端到端的数据传输；\n网络层，负责数据的路由、转发、分片；\n数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；\n物理层，负责在物理网络中传输数据帧；\n\n由于 OSI 模型实在太复杂，提出的也只是概念理论上的分层，并没有提供具体的实现方案。\n事实上，我们比较常见，也比较实用的是四层模型，即 TCP&#x2F;IP 网络模型，Linux 系统正是按照这套网络模型来实现网络协议栈的。\n\n\n\n\n\n\n\n\n\nTCP&#x2F;IP模型\nTCP&#x2F;IP协议被组织成四个概念层，其中有三层对应于ISO参考模型中的相应层。ICP&#x2F;IP协议族并不包含物理层和数据链路层，因此它不能独立完成整个计算机网络系统的功能，必须与许多其他的协议协同工作。TCP&#x2F;IP 网络通常是由上到下分成 4 层，分别是应用层，传输层，网络层和网络接口层。\n\n\n应用层 支持 HTTP、SMTP 等最终用户进程\n传输层 处理主机到主机的通信（TCP、UDP）\n网络层 寻址和路由数据包（IP 协议）\n链路层 通过网络的物理电线、电缆或无线信道移动比特\n\n# tcp、ip分别位于哪一层？\ntcp 在传输层\nip 在网络层\n\n# 应用层# 应用层有哪些协议？HTTP、HTTPS、CDN、DNS、FTP 都是应用层协议\n# HTTP报文有哪些部分？\n分请求报文和响应报文来说明。\n请求报文：\n\n请求行：包含请求方法、请求目标（URL或URI）和HTTP协议版本。\n请求头部：包含关于请求的附加信息，如Host、User-Agent、Content-Type等。\n空行：请求头部和请求体之间用空行分隔。\n请求体：可选，包含请求的数据，通常用于POST请求等需要传输数据的情况。\n\n响应报文：\n\n状态行：包含HTTP协议版本、状态码和状态信息。\n响应头部：包含关于响应的附加信息，如Content-Type、Content-Length等。\n空行：响应头部和响应体之间用空行分隔。\n响应体：包含响应的数据，通常是服务器返回的HTML、JSON等内容。\n\n# HTTP常用的状态码？\nHTTP 状态码分为 5 大类\n\n1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。\n2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。\n3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。\n4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。\n5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。\n\n其中常见的具体状态码有：\n\n200：请求成功；\n301：永久重定向；302：临时重定向；\n404：无法找到此页面；405：请求的方法类型不支持；\n500：服务器内部出错。\n\n# HTTP返回状态301 302分别是什么？3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。\n\n「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。\n「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。\n\n301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。\n# http 502和 504 的区别？\n502 Bad Gateway：作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。\n504 Gateway Time-out：作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器收到响应。\n\n举一个例子，假设 nginx 是代理服务器，收到客户端的请求后，将请求转发到后端服务器（tomcat 等）。\n\n当nginx收到了无效的响应时，就返回502。\n当nginx超过自己配置的超时时间，还没有收到请求时，就返回504错误。\n\n# HTTP层请求的类型有哪些？\nGET：用于请求获取指定资源，通常用于获取数据。\nPOST：用于向服务器提交数据，通常用于提交表单数据或进行资源的创建。\nPUT：用于向服务器更新指定资源，通常用于更新已存在的资源。\nDELETE：用于请求服务器删除指定资源。\nHEAD：类似于GET请求，但只返回资源的头部信息，用于获取资源的元数据而不获取实际内容。\n\n# GET和POST的使用场景，有哪些区别？根据 RFC 规范，GET 的语义是从服务器获取指定的资源，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。\n比如，你打开我的文章，浏览器就会发送 GET 请求给服务器，服务器就会返回文章的所有文字及资源。\n\n根据 RFC 规范，POST 的语义是根据请求负荷（报文body）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。\n比如，你在我文章底部，敲入了留言后点击「提交」（暗示你们留言），浏览器就会执行一次 POST 请求，把你的留言文字放进了报文 body 里，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。\n\n如果从 RFC 规范定义的语义来看：\n\nGET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签。\nPOST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。所以，浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签。\n\n但是实际过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。比如：\n\n可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。\n可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。\n\n# HTTP的长连接是什么？HTTP 协议采用的是「请求-应答」的模式，也就是客户端发起了请求，服务端才会返回响应，一来一回这样子。\n\n由于 HTTP 是基于 TCP 传输协议实现的，客户端与服务端要进行 HTTP 通信前，需要先建立 TCP 连接，然后客户端发送 HTTP 请求，服务端收到后就返回响应，至此「请求-应答」的模式就完成了，随后就会释放 TCP 连接。\n\n如果每次请求都要经历这样的过程：建立 TCP -&gt; 请求资源 -&gt; 响应资源 -&gt; 释放连接，那么此方式就是 HTTP 短连接，如下图：\n\n这样实在太累人了，一次连接只能请求一次资源。\n能不能在第一个 HTTP 请求完后，先不断开 TCP 连接，让后续的 HTTP 请求继续使用此连接？\n当然可以，HTTP 的 Keep-Alive 就是实现了这个功能，可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求&#x2F;应答，避免了连接建立和释放的开销，这个方法称为 HTTP 长连接。\n\nHTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。\n# HTTP默认的端口是什么？http 是 80，https 默认是 443。\n# HTTP1.1怎么对请求做拆包，具体来说怎么拆的？在HTTP&#x2F;1.1中，请求的拆包是通过”Content-Length”头字段来进行的。该字段指示了请求正文的长度，服务器可以根据该长度来正确接收和解析请求。\n\n具体来说，当客户端发送一个HTTP请求时，会在请求头中添加”Content-Length”字段，该字段的值表示请求正文的字节数。\n服务器在接收到请求后，会根据”Content-Length”字段的值来确定请求的长度，并从请求中读取相应数量的字节，直到读取完整个请求内容。\n这种基于”Content-Length”字段的拆包机制可以确保服务器正确接收到完整的请求，避免了请求的丢失或截断问题。\n# HTTP为什么不安全？HTTP 由于是明文传输，所以安全上存在以下三个风险：\n\n窃听风险，比如通信链路上可以获取通信内容，用户号容易没。\n篡改风险，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。\n冒充风险，比如冒充淘宝网站，用户钱容易没。\n\n\nHTTPS 在 HTTP 与 TCP 层之间加入了 SSL&#x2F;TLS 协议，可以很好的解决了上述的风险：\n\n信息加密：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。\n校验机制：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。\n身份证书：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。\n\n# HTTP和HTTPS 的区别？区别主要有以下四点：\n\nHTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL&#x2F;TLS 安全协议，使得报文能够加密传输。\nHTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL&#x2F;TLS 的握手过程，才可进入加密报文传输。\n两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。\nHTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。\n\n# HTTPS握手过程说一下传统的 TLS 握手基本都是使用 RSA 算法来实现密钥交换的，在将 TLS 证书部署服务端时，证书文件其实就是服务端的公钥，会在 TLS 握手阶段传递给客户端，而服务端的私钥则一直留在服务端，一定要确保私钥不能被窃取。\n在 RSA 密钥协商算法中，客户端会生成随机密钥，并使用服务端的公钥加密后再传给服务端。根据非对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务端解密后，双方就得到了相同的密钥，再用它加密应用消息。\n我用 Wireshark 工具抓了用 RSA 密钥交换的 TLS 握手过程，你可以从下面看到，一共经历了四次握手：\n\n\n\n\n\n\n\n\n\n\n\nTLS 第一次握手\n首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。在这一步，客户端主要向服务器发送以下信息：\n\n（1）客户端支持的 TLS 协议版本，如 TLS 1.2 版本。\n（2）客户端生产的随机数（Client Random），后面用于生成「会话秘钥」条件之一。\n（3）客户端支持的密码套件列表，如 RSA 加密算法。\n\n\n\n\n\n\n\n\n\n\nTLS 第二次握手\n服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。服务器回应的内容有如下内容：\n\n（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。\n（2）服务器生产的随机数（Server Random），也是后面用于生产「会话秘钥」条件之一。\n（3）确认的密码套件列表，如 RSA 加密算法。（4）服务器的数字证书。\n\n\n\n\n\n\n\n\n\n\nTLS 第三次握手\n客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。\n如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：\n\n（1）一个随机数（pre-master key）。该随机数会被服务器公钥加密。\n（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。\n（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。\n\n上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。\n服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。\n\n\n\n\n\n\n\n\n\nTLS 第四次握手\n服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。\n然后，向客户端发送最后的信息：\n\n（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。\n（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。\n\n至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。\n# HTTPS是如何防范中间人的攻击？主要通过加密和身份校验机制来防范中间人攻击的:\n\n加密：https 握手期间会通过非对称加密的方式来协商出对称加密密钥。\n身份校验：服务器会向证书颁发机构申请数字证书，证书中包含了服务器的公钥和其他相关信息。当客户端与服务器建立连接时，服务器会将证书发送给客户端。客户端会验证证书的合法性，包括检查证书的有效期、颁发机构的信任等。如果验证通过，客户端会使用证书中的公钥来加密通信数据，并将加密后的数据发送给服务器，然后由服务端用私钥解密。\n\n中间人攻击的关键在于攻击者冒充服务器与客户端建立连接，并同时与服务器建立连接。\n但由于攻击者无法获得服务器的私钥，因此无法正确解密客户端发送的加密数据。同时，客户端会在建立连接时验证服务器的证书，如果证书验证失败或存在问题，客户端会发出警告或中止连接。\n# Http1.1和2.0的区别是什么？HTTP&#x2F;2 相比 HTTP&#x2F;1.1 性能上的改进：\n\n头部压缩：HTTP&#x2F;2 会压缩头（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的部分。这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。\n二进制格式：HTTP&#x2F;2 不再像 HTTP&#x2F;1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧（Headers Frame）和数据帧（Data Frame）。这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这增加了数据传输的效率。\n并发传输：引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。解决了HTTP&#x2F;1.1 队头阻塞的问题：\n服务器主动推送资源：HTTP&#x2F;2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以主动向客户端发送消息。\n\n# HTTP进行TCP连接之后，在什么情况下会中断\n当服务端或者客户端执行 close 系统调用的时候，会发送FIN报文，就会进行四次挥手的过程\n当发送方发送了数据之后，接收方超过一段时间没有响应ACK报文，发送方重传数据达到最大次数的时候，就会断开TCP连接\n当HTTP长时间没有进行请求和响应的时候，超过一定的时间，就会释放连接\n\n# HTTP、SOCKET和TCP的区别HTTP是应用层协议，定义了客户端和服务器之间交换的数据格式和规则；Socket是通信的一端，提供了网络通信的接口；TCP是传输层协议，负责在网络中建立可靠的数据传输连接。它们在网络通信中扮演不同的角色和层次。\n\nHTTP是一种用于传输超文本数据的应用层协议，用于在客户端和服务器之间传输和显示Web页面。\nSocket是计算机网络中的一种抽象，用于描述通信链路的一端，提供了底层的通信接口，可实现不同计算机之间的数据交换。\nTCP是一种面向连接的、可靠的传输层协议，负责在通信的两端之间建立可靠的数据传输连接。\n\n# DNS的全称了解么？DNS的全称是Domain Name System（域名系统），它是互联网中用于将域名转换为对应IP地址的分布式数据库系统。DNS扮演着重要的角色，使得人们可以通过易记的域名访问互联网资源，而无需记住复杂的IP地址。\nDNS 中的域名都是用句点来分隔的，比如 www.server.com，这里的句点代表了不同层次之间的**界限**。\n在域名中，越靠右的位置表示其层级越高。\n毕竟域名是外国人发明，所以思维和中国人相反，比如说一个城市地点的时候，外国喜欢从小到大的方式顺序说起（如 XX 街道 XX 区 XX 市 XX 省），而中国则喜欢从大到小的顺序（如 XX 省 XX 市 XX 区 XX 街道）。\n实际上域名最后还有一个点，比如 www.server.com.，这个最后的一个点代表根域名。\n也就是，. 根域是在最顶层，它的下一层就是 .com 顶级域，再下面是 server.com。\n所以域名的层级关系类似一个树状结构：\n\n根 DNS 服务器（.）\n顶级域 DNS 服务器（.com）\n权威 DNS 服务器（server.com）\n\n\n根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。\n这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。\n因此，客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器。\n# DNS 域名解析的工作流程？\n客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP&#x2F;IP 设置中填写的 DNS 服务器地址）。\n本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。\n根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”\n本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？”\n顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。\n本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。\n权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。\n本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。\n\n至此，我们完成了 DNS 的解析过程。现在总结一下，整个过程我画成了一个图。\n\n# DNS的端口是多少？默认端口号是53。\n# DNS的底层使用TCP还是UDP？DNS 基于UDP协议实现，DNS使用UDP协议进行域名解析和数据传输。因为基于UDP实现DNS能够提供低延迟、简单快速、轻量级的特性，更适合DNS这种需要快速响应的域名解析服务。\n\n低延迟： UDP是一种无连接的协议，不需要在数据传输前建立连接，因此可以减少传输时延，适合DNS这种需要快速响应的应用场景。\n简单快速： UDP相比于TCP更简单，没有TCP的连接管理和流量控制机制，传输效率更高，适合DNS这种需要快速传输数据的场景。\n轻量级：UDP头部较小，占用较少的网络资源，对于小型请求和响应来说更加轻量级，适合DNS这种频繁且短小的数据交换。\n\n尽管 UDP 存在丢包和数据包损坏的风险，但在 DNS 的设计中，这些风险是可以被容忍的。DNS 使用了一些机制来提高可靠性，例如查询超时重传、请求重试、缓存等，以确保数据传输的可靠性和正确性。\n# HTTP到底是不是无状态的？HTTP是无状态的，这意味着每个请求都是独立的，服务器不会在多个请求之间保留关于客户端状态的信息。在每个HTTP请求中，服务器不会记住之前的请求或会话状态，因此每个请求都是相互独立的。\n虽然HTTP本身是无状态的，但可以通过一些机制来实现状态保持，其中最常见的方式是使用Cookie和Session来跟踪用户状态。通过在客户端存储会话信息或状态信息，服务器可以识别和跟踪特定用户的状态，以提供一定程度的状态保持功能。\n# 携带Cookie的HTTP请求是有状态还是无状态的？Cookie是HTTP协议簇的一部分，那为什么还说HTTP是无状态的？携带Cookie的HTTP请求实际上是可以在一定程度上实现状态保持的，因为Cookie是用来在客户端存储会话信息和状态信息的一种机制。当浏览器发送包含Cookie的HTTP请求时，服务器可以通过读取这些Cookie来识别用户、管理会话状态以及保持特定的用户状态。因此，可以说即使HTTP本身是无状态的协议，但通过Cookie的使用可以实现一定程度的状态保持功能。\nHTTP被描述为“无状态”的主要原因是每个HTTP请求都是独立的，服务器并不保存关于客户端的状态信息，每个请求都需要提供足够的信息来理解请求的意图。这样的设计使得Web系统更具有规模化和简单性，但也导致了一些挑战，比如需要额外的机制来处理用户状态和会话管理。\n虽然Cookie是HTTP协议簇的一部分，但是HTTP协议在设计初衷上仍然保持无状态特性，即每个请求都是相互独立的。使用Cookie只是在无状态协议下的一种补充机制，用于在客户端存储状态信息以实现状态保持。\n# cookie和session有什么区别？Cookie和Session都是Web开发中用于跟踪用户状态的技术，但它们在存储位置、数据容量、安全性以及生命周期等方面存在显著差异：\n\n**存储位置：**Cookie的数据存储在客户端（通常是浏览器）。当浏览器向服务器发送请求时，会自动附带Cookie中的数据。Session的数据存储在服务器端。服务器为每个用户分配一个唯一的Session ID，这个ID通常通过Cookie或URL重写的方式发送给客户端，客户端后续的请求会带上这个Session ID，服务器根据ID查找对应的Session数据。\n**数据容量：**单个Cookie的大小限制通常在4KB左右，而且大多数浏览器对每个域名的总Cookie数量也有限制。由于Session存储在服务器上，理论上不受数据大小的限制，主要受限于服务器的内存大小。\n**安全性：**Cookie相对不安全，因为数据存储在客户端，容易受到XSS（跨站脚本攻击）的威胁。不过，可以通过设置HttpOnly属性来防止JavaScript访问，减少XSS攻击的风险，但仍然可能受到CSRF（跨站请求伪造）的攻击。Session通常认为比Cookie更安全，因为敏感数据存储在服务器端。但仍然需要防范Session劫持（通过获取他人的Session ID）和会话固定攻击。\n**生命周期：**Cookie可以设置过期时间，过期后自动删除。也可以设置为会话Cookie，即浏览器关闭时自动删除。Session在默认情况下，当用户关闭浏览器时，Session结束。但服务器也可以设置Session的超时时间，超过这个时间未活动，Session也会失效。\n**性能：**使用Cookie时，因为数据随每个请求发送到服务器，可能会影响网络传输效率，尤其是在Cookie数据较大时。使用Session时，因为数据存储在服务器端，每次请求都需要查询服务器上的Session数据，这可能会增加服务器的负载，特别是在高并发场景下。\n\n# token，session，cookie的区别？\nsession存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session，依赖cookie。\ncookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。\ntoken也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户，需要开发者手动添加。\n\n# 如果客户端禁用了cookie，session还能用吗？默认情况下禁用 Cookie 后，Session 是无法正常使用的，因为大多数 Web 服务器都是依赖于 Cookie 来传递 Session 的会话 ID 的。\n客户端浏览器禁用 Cookie 时，服务器将无法把会话 ID 发送给客户端，客户端也无法在后续请求中携带会话 ID 返回给服务器，从而导致服务器无法识别用户会话。\n但是，有几种方法可以绕过这个问题，尽管它们可能会引入额外的复杂性和&#x2F;或降低用户体验：\n\n**URL重写：**每当服务器响应需要保持状态的请求时，将Session ID附加到URL中作为参数。例如，原本的链接http://example.com/page变为http://example.com/page;jsessionid=XXXXXX，服务器端需要相应地解析 URL 来获取 Session ID，并维护用户的会话状态。这种方式的缺点是URL变得不那么整洁，且如果用户通过电子邮件或其他方式分享了这样的链接，可能导致Session ID的意外泄露。\n隐藏表单字段：在每个需要Session信息的HTML表单中包含一个隐藏字段，用来存储Session ID。当表单提交时，Session ID随表单数据一起发送回服务器，服务器通过解析表单数据中的 Session ID 来获取用户的会话状态。这种方法仅适用于通过表单提交的交互模式，不适合链接点击或Ajax请求。\n\n# 如果我把数据存储到 localStorage，和Cookie有什么区别？\n存储容量: Cookie 的存储容量通常较小,每个 Cookie 的大小限制在几 KB 左右。而 LocalStorage 的存储容量通常较大,一般限制在几 MB 左右。因此,如果需要存储大量数据，LocalStorage 通常更适合;\n数据发送: Cookie 在每次 HTTP 请求中都会自动发送到服务器,这使得 Cookie 适合用于在客户端和服务器之间传递数据。而 localStorage 的数据不会自动发送到服务器,它仅在浏览器端存储数据,因此 LocalStorage 适合用于在同一域名下的不同页面之间共享数据;\n生命周期：Cookie 可以设置一个过期时间,使得数据在指定时间后自动过期。而 LocalStorage 的数据将永久存储在浏览器中,除非通过 JavaScript 代码手动删除;\n安全性：Cookie 的安全性较低,因为 Cookie 在每次 HTTP 请求中都会自动发送到服务器,存在被窃取或篡改的风险。而 LocalStorage 的数据仅在浏览器端存储,不会自动发送到服务器,相对而言更安全一些;\n\n# 什么数据应该存在到cookie，什么数据存放到 LocalstorageCookie 适合用于在客户端和服务器之间传递数据、跨域访问和设置过期时间，而 LocalStorage 适合用于在同一域名下的不同页面之间共享数据、存储大量数据和永久存储数据。\n# JWT 令牌和传统方式有什么区别？\n无状态性：JWT是无状态的令牌，不需要在服务器端存储会话信息。相反，JWT令牌中包含了所有必要的信息，如用户身份、权限等。这使得JWT在分布式系统中更加适用，可以方便地进行扩展和跨域访问。\n安全性：JWT使用密钥对令牌进行签名，确保令牌的完整性和真实性。只有持有正确密钥的服务器才能对令牌进行验证和解析。这种方式比传统的基于会话和Cookie的验证更加安全，有效防止了CSRF（跨站请求伪造）等攻击。\n跨域支持：JWT令牌可以在不同域之间传递，适用于跨域访问的场景。通过在请求的头部或参数中携带JWT令牌，可以实现无需Cookie的跨域身份验证。\n\n# JWT 令牌都有哪些字段？（ 没答上来，忘了有哪些，没想到会问）JWT令牌由三个部分组成：头部（Header）、载荷（Payload）和签名（Signature）。其中，头部和载荷均为JSON格式，使用Base64编码进行序列化，而签名部分是对头部、载荷和密钥进行签名后的结果。\n\n# JWT 令牌为什么能解决集群部署，什么是集群部署？（ 答上来了）在传统的基于会话和Cookie的身份验证方式中，会话信息通常存储在服务器的内存或数据库中。但在集群部署中，不同服务器之间没有共享的会话信息，这会导致用户在不同服务器之间切换时需要重新登录，或者需要引入额外的共享机制（如Redis），增加了复杂性和性能开销。\n\n而JWT令牌通过在令牌中包含所有必要的身份验证和会话信息，使得服务器无需存储会话信息，从而解决了集群部署中的身份验证和会话管理问题。当用户进行登录认证后，服务器将生成一个JWT令牌并返回给客户端。客户端在后续的请求中携带该令牌，服务器可以通过对令牌进行验证和解析来获取用户身份和权限信息，而无需访问共享的会话存储。\n由于JWT令牌是自包含的，服务器可以独立地对令牌进行验证，而不需要依赖其他服务器或共享存储。这使得集群中的每个服务器都可以独立处理请求，提高了系统的可伸缩性和容错性。\n# jwt的缺点是什么？JWT 一旦派发出去，在失效之前都是有效的，没办法即使撤销JWT。\n要解决这个问题的话，得在业务层增加判断逻辑，比如增加**黑名单机制。**使用内存数据库比如 Redis 维护一个黑名单，如果想让某个 JWT 失效的话就直接将这个 JWT 加入到 黑名单 即可。然后，每次使用 JWT 进行请求的话都会先判断这个 JWT 是否存在于黑名单中。\n# JWT 令牌如果泄露了，怎么解决，JWT是怎么做的？\n及时失效令牌：当检测到JWT令牌泄露或存在风险时，可以立即将令牌标记为失效状态。服务器在接收到带有失效标记的令牌时，会拒绝对其进行任何操作，从而保护用户的身份和数据安全。\n刷新令牌：JWT令牌通常具有一定的有效期，过期后需要重新获取新的令牌。当检测到令牌泄露时，可以主动刷新令牌，即重新生成一个新的令牌，并将旧令牌标记为失效状态。这样，即使泄露的令牌被恶意使用，也会很快失效，减少了被攻击者滥用的风险。\n使用黑名单：服务器可以维护一个令牌的黑名单，将泄露的令牌添加到黑名单中。在接收到令牌时，先检查令牌是否在黑名单中，如果在则拒绝操作。这种方法需要服务器维护黑名单的状态，对性能有一定的影响，但可以有效地保护泄露的令牌不被滥用。\n\n# 前端是如何存储JWT的？JSON Web Token（缩写 JWT）是目前最流行的跨域认证解决方案。互联网服务离不开用户认证。\n一般流程如下：\n\n用户向服务器发送用户名和密码。\n服务器验证通过后，在当前对话（session）里面保存相关数据，比如用户角色、登录时间等等。\n服务器向用户返回一个 session_id，写入用户的 Cookie。\n用户随后的每一次请求，都会通过 Cookie，将 session_id 传回服务器。\n服务器收到 session_id，找到前期保存的数据，由此得知用户的身份。\n\n这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，就要求 session 数据共享，每台服务器都能够读取 session。\n举例来说，A 网站和 B 网站是同一家公司的关联服务。现在要求，用户只要在其中一个网站登录，再访问另一个网站就会自动登录，请问怎么实现？\n一种解决方案是 session 数据持久化，写入数据库或别的持久层。各种服务收到请求后，都向持久层请求数据。这种方案的优点是架构清晰，缺点是工程量比较大。另外，持久层万一挂了，就会单点失败。\n另一种方案是服务器索性不保存 session 数据了，所有数据都保存在客户端，每次请求都发回服务器。JWT 就是这种方案的一个代表。\n客户端收到服务器返回的 JWT，可以储存在 Local Storage 里面，也可以储存在Cookie里面，还可以存储在Session Storage里面。下面将说明存在上述各个地方的优劣势：\n\n\n\n\n\n\n\n\n\nLocal Storage（本地存储）\n\n优点：Local Storage 提供了较大的存储空间（一般为5MB），且不会随着HTTP请求一起发送到服务器，因此不会出现在HTTP缓存或日志中。\n缺点：存在XSS（跨站脚本攻击）的风险，恶意脚本可以通过JavaScript访问到存储在Local Storage中的JWT，从而盗取用户凭证。\n\n\n\n\n\n\n\n\n\n\nSession Storage（会话存储）\n\n优点：与Local Storage类似，但仅限于当前浏览器窗口或标签页，当窗口关闭后数据会被清除，这在一定程度上减少了数据泄露的风险。\n缺点：用户体验可能受影响，因为刷新页面或在新标签页打开相同应用时需要重新认证。\n\n\n\n\n\n\n\n\n\n\nCookie\n\n优点：可以设置HttpOnly标志来防止通过JavaScript访问，减少XSS攻击的风险；可以利用Secure标志确保仅通过HTTPS发送，增加安全性。\n缺点：大小限制较小（通常4KB），并且每次HTTP请求都会携带Cookie，可能影响性能；设置不当可能会受到CSRF（跨站请求伪造）攻击。\n\n# 为什么有HTTP协议了?还要用RPC?\nRPC 本质上不算是协议，而是一种调用方式，而像 gRPC 和 Thrift 这样的具体实现，才是协议，它们是实现了 RPC 调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时 RPC 有很多种实现方式，不一定非得基于 TCP 协议。\n从发展历史来说，HTTP 主要用于 B&#x2F;S 架构，而 RPC 更多用于 C&#x2F;S 架构。但现在其实已经没分那么清了，B&#x2F;S 和 C&#x2F;S 在慢慢融合。很多软件同时支持多端，所以对外一般用 HTTP 协议，而内部集群的微服务之间则采用 RPC 协议进行通讯。\nRPC 其实比 HTTP 出现的要早，且比目前主流的 HTTP&#x2F;1.1 性能要更好，所以大部分公司内部都还在使用 RPC。\nHTTP&#x2F;2.0在 HTTP&#x2F;1.1的基础上做了优化，性能可能比很多 RPC 协议都要好，但由于是这几年才出来的，所以也不太可能取代掉 RPC。\n\n# HTTP长连接与WebSocket有什么区别？\n全双工和半双工：TCP 协议本身是全双工的，但我们最常用的 HTTP&#x2F;1.1，虽然是基于 TCP 的协议，但它是半双工的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。\n应用场景区别：在 HTTP&#x2F;1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用定时轮询或者长轮询的方式实现服务器推送(comet)的效果。对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。\n\n# Nginx有哪些负载均衡算法？Nginx支持的负载均衡算法包括：\n\n轮询：按照顺序依次将请求分配给后端服务器。这种算法最简单，但是也无法处理某个节点变慢或者客户端操作有连续性的情况。\nIP哈希：根据客户端IP地址的哈希值来确定分配请求的后端服务器。适用于需要保持同一客户端的请求始终发送到同一台后端服务器的场景，如会话保持。\nURL哈希：按访问的URL的哈希结果来分配请求，使每个URL定向到一台后端服务器，可以进一步提高后端缓存服务器的效率。\n最短响应时间：按照后端服务器的响应时间来分配请求，响应时间短的优先分配。适用于后端服务器性能不均的场景，能够将请求发送到响应时间快的服务器，实现负载均衡。\n加权轮询：按照权重分配请求给后端服务器，权重越高的服务器获得更多的请求。适用于后端服务器性能不同的场景，可以根据服务器权重分配请求，提高高性能服务器的利用率。\n\n# Nginx位于七层网络结构中的哪一层？应用层，nginx 是七层负载均衡。\n# 传输层# 说一下tcp的头部\n标注颜色的表示与本文关联比较大的字段，其他字段不做详细阐述。\n序列号：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。\n确认应答号：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。\n控制位：\n\nACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1 。\nRST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。\nSYN：该位为 1 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。\nFIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。\n\n# TCP三次握手过程说一下？TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而建立连接是通过三次握手来进行的。三次握手的过程如下图：\n\n\n一开始，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态\n\n\n\n客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。\n\n\n\n服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。\n\n\n\n客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态。\n服务端收到客户端的应答报文后，也进入 ESTABLISHED 状态。\n\n从上面的过程可以发现第三次握手是可以携带数据的，前两次握手是不可以携带数据的，这也是面试常问的题。\n一旦完成三次握手，双方都处于 ESTABLISHED 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。\n# tcp为什么需要三次握手建立连接？三次握手的原因：\n\n三次握手才可以阻止重复历史连接的初始化（主要原因）\n三次握手才可以同步双方的初始序列号\n三次握手才可以避免资源浪费\n\n原因一：避免历史连接\n我们来看看 RFC 793 指出的 TCP 连接使用三次握手的首要原因：\nThe principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion.\n简单来说，三次握手的首要原因是为了防止旧的重复连接初始化造成混乱。\n我们考虑一个场景，客户端先发送了 SYN（seq &#x3D; 90）报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq &#x3D; 100）报文（注意！不是重传 SYN，重传的 SYN 的序列号是一样的）。\n看看三次握手是如何阻止历史连接的：\n\n客户端连续发送多次 SYN（都是同一个四元组）建立连接的报文，在网络拥堵情况下：\n\n一个「旧 SYN 报文」比「最新的 SYN」 报文早到达了服务端，那么此时服务端就会回一个 SYN + ACK 报文给客户端，此报文中的确认号是 91（90+1）。\n客户端收到后，发现自己期望收到的确认号应该是 100 + 1，而不是 90 + 1，于是就会回 RST 报文。\n服务端收到 RST 报文后，就会释放连接。\n后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。\n\n上述中的「旧 SYN 报文」称为历史连接，TCP 使用三次握手建立连接的最主要原因就是防止「历史连接」初始化了连接。\n如果是两次握手连接，就无法阻止历史连接，那为什么 TCP 两次握手为什么无法阻止历史连接呢？\n我先直接说结论，主要是因为在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费。\n你想想，在两次握手的情况下，服务端在收到 SYN 报文后，就进入 ESTABLISHED 状态，意味着这时可以给对方发送数据，但是客户端此时还没有进入 ESTABLISHED 状态，假设这次是历史连接，客户端判断到此次连接为历史连接，那么就会回 RST 报文来断开连接，而服务端在第一次握手的时候就进入 ESTABLISHED 状态，所以它可以发送数据的，但是它并不知道这个是历史连接，它只有在收到 RST 报文后，才会断开连接。\n\n可以看到，如果采用两次握手建立 TCP 连接的场景下，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据，妥妥地浪费了服务端的资源。\n因此，要解决这种现象，最好就是在服务端发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手。\n所以，TCP 使用三次握手建立连接的最主要原因是防止「历史连接」初始化了连接。\n原因二：同步双方初始序列号\nTCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：\n\n接收方可以去除重复的数据；\n接收方可以根据数据包的序列号按序接收；\n可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；\n\n可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。\n\n四次握手与三次握手\n四次握手其实也能够可靠的同步双方的初始化序号，但由于第二步和第三步可以优化成一步，所以就成了「三次握手」。\n而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。\n原因三：避免资源浪费\n如果只有「两次握手」，当客户端发生的 SYN 报文在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 ACK 报文，所以服务端每收到一个 SYN 就只能先主动建立一个连接，这会造成什么情况呢？\n如果客户端发送的 SYN 报文在网络中阻塞了，重复发送多次 SYN 报文，那么服务端在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。\n\n即两次握手会造成消息滞留情况下，服务端重复接受无用的连接请求 SYN 报文，而造成重复分配资源。\n# TCP 三次握手，客户端第三次发送的确认包丢失了发生什么？客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 ESTABLISH 状态。\n因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。\n注意，ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文。\n举个例子，假设 tcp_synack_retries 参数值为 2，那么当第三次握手一直丢失时，发生的过程如下图：\n\n具体过程：\n\n当服务端超时重传 2 次 SYN-ACK 报文后，由于 tcp_synack_retries 为 2，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第三次握手（ACK 报文），那么服务端就会断开连接。\n\n# 服务端发送第二个报文后连接的状态进入什么状态syn_rcvd 状态\n# 三次握手和 accept 是什么关系？ accept 做了哪些事情？tcp 完成三次握手后，连接会被保存到内核的全连接队列，调用 accpet 就是从把连接取出来给用户程序使用。\n\n# 客户端发送的第一个 SYN 报文，服务器没有收到怎么办？当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 SYN_SENT 状态。\n在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，而且重传的 SYN 报文的序列号都是一样的。\n不同版本的操作系统可能超时时间不同，有的 1 秒的，也有 3 秒的，这个超时时间是写死在内核里的，如果想要更改则需要重新编译内核，比较麻烦。\n当客户端在 1 秒后没收到服务端的 SYN-ACK 报文后，客户端就会重发 SYN 报文，那到底重发几次呢？\n在 Linux 里，客户端的 SYN 报文最大重传次数由 tcp_syn_retries内核参数控制，这个参数是可以自定义的，默认值一般是 5。\n12# cat /proc/sys/net/ipv4/tcp_syn_retries5\n\n通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，每次超时的时间是上一次的 2 倍。\n当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接。\n所以，总耗时是 1+2+4+8+16+32&#x3D;63 秒，大约 1 分钟左右。\n举个例子，假设 tcp_syn_retries 参数值为 3，那么当客户端的 SYN 报文一直在网络中丢失时，会发生下图的过程：\n\n具体过程：\n\n当客户端超时重传 3 次 SYN 报文后，由于 tcp_syn_retries 为 3，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次握手（SYN-ACK 报文），那么客户端就会断开连接。\n\n# 服务器收到第一个 SYN 报文，回复的 SYN + ACK 报文丢失了怎么办？当服务端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务端会进入 SYN_RCVD 状态。\n第二次握手的 SYN-ACK 报文其实有两个目的 ：\n\n第二次握手里的 ACK， 是对第一次握手的确认报文；\n第二次握手里的 SYN，是服务端发起建立 TCP 连接的报文；\n\n所以，如果第二次握手丢了，就会发生比较有意思的事情，具体会怎么样呢？\n因为第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是客户端就会触发超时重传机制，重传 SYN 报文。\n然后，因为第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手），服务端才会认为该 SYN 报文被客户端收到了。\n那么，如果第二次握手丢失了，服务端就收不到第三次握手，于是服务端这边会触发超时重传机制，重传 SYN-ACK 报文。\n在 Linux 下，SYN-ACK 报文的最大重传次数由 tcp_synack_retries内核参数决定，默认值是 5。\n12# cat /proc/sys/net/ipv4/tcp_synack_retries5\n\n因此，当第二次握手丢失了，客户端和服务端都会重传：\n\n客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 tcp_syn_retries内核参数决定；\n服务端会重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 tcp_synack_retries 内核参数决定。\n\n举个例子，假设 tcp_syn_retries 参数值为 1，tcp_synack_retries 参数值为 2，那么当第二次握手一直丢失时，发生的过程如下图：\n\n具体过程：\n\n当客户端超时重传 1 次 SYN 报文后，由于 tcp_syn_retries 为 1，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次握手（SYN-ACK 报文），那么客户端就会断开连接。\n当服务端超时重传 2 次 SYN-ACK 报文后，由于 tcp_synack_retries 为 2，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第三次握手（ACK 报文），那么服务端就会断开连接。\n\n# 假设客户端重传了 SYN 报文，服务端这边又收到重复的 SYN 报文怎么办？会继续发送第二次握手报文。\n# 第一次握手，客户端发送SYN报后，服务端回复ACK报，那这个过程中服务端内部做了哪些工作？服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。\n\n不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。\n# 大量SYN包发送给服务端服务端会发生什么事情？有可能会导致TCP 半连接队列打满，这样当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。\n避免 SYN 攻击方式，可以有以下四种方法：\n\n调大 netdev_max_backlog；\n增大 TCP 半连接队列；\n开启 tcp_syncookies；\n减少 SYN+ACK 重传次数\n\n\n\n\n\n\n\n\n\n\n方式一：调大 netdev_max_backlog\n当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数，默认值是 1000，我们要适当调大该参数的值，比如设置为 10000：\n1net.core.netdev_max_backlog = 10000\n\n\n\n\n\n\n\n\n\n\n方式二：增大 TCP 半连接队列\n增大 TCP 半连接队列，要同时增大下面这三个参数：\n\n增大 net.ipv4.tcp_max_syn_backlog\n增大 listen() 函数中的 backlog\n增大 net.core.somaxconn\n\n\n\n\n\n\n\n\n\n\n方式三：开启 net.ipv4.tcp_syncookies\n开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接。\n\n具体过程：\n\n当 「 SYN 队列」满之后，后续服务端收到 SYN 包，不会丢弃，而是根据算法，计算出一个 cookie 值；\n将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端；\n服务端接收到客户端的应答报文时，服务端会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」。\n最后应用程序通过调用 accpet() 接口，从「 Accept 队列」取出的连接。\n\n可以看到，当开启了 tcp_syncookies 了，即使受到 SYN 攻击而导致 SYN 队列满时，也能保证正常的连接成功建立。\nnet.ipv4.tcp_syncookies 参数主要有以下三个值：\n\n0 值，表示关闭该功能；\n1 值，表示仅当 SYN 半连接队列放不下时，再启用它；\n2 值，表示无条件开启功能；\n\n那么在应对 SYN 攻击时，只需要设置为 1 即可。\n1$ echo 1 &gt; /proc/sys/net/ipv4/tcp_syncookies\n\n\n\n\n\n\n\n\n\n\n方式四：减少 SYN+ACK 重传次数\n当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。\n那么针对 SYN 攻击的场景，我们可以减少 SYN-ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。\nSYN-ACK 报文的最大重传次数由 tcp_synack_retries内核参数决定（默认值是 5 次），比如将 tcp_synack_retries 减少到 2 次：\n1$ echo 2 &gt; /proc/sys/net/ipv4/tcp_synack_retries\n\n# TCP 四次挥手过程说一下？\n具体过程：\n\n客户端主动调用关闭连接的函数，于是就会发送 FIN 报文，这个 FIN 报文代表客户端不会再发送数据了，进入 FIN_WAIT_1 状态；\n服务端收到了 FIN 报文，然后马上回复一个 ACK 确认报文，此时服务端进入 CLOSE_WAIT 状态。在收到 FIN 报文的时候，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，服务端应用程序可以通过 read 调用来感知这个 FIN 包，这个 EOF 会被放在已排队等候的其他已接收的数据之后，所以必须要得继续 read 接收缓冲区已接收的数据；\n接着，当服务端在 read 数据的时候，最后自然就会读到 EOF，接着 read() 就会返回 0，这时服务端应用程序如果有数据要发送的话，就发完数据后才调用关闭连接的函数，如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，这时服务端就会发一个 FIN 包，这个 FIN 报文代表服务端不会再发送数据了，之后处于 LAST_ACK 状态；\n客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；\n服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；\n客户端经过 2MSL 时间之后，也进入 CLOSE 状态；\n\n# 为什么4次握手中间两次不能变成一次？服务器收到客户端的 FIN 报文时，内核会马上回一个 ACK 应答报文，但是服务端应用程序可能还有数据要发送，所以并不能马上发送 FIN 报文，而是将发送 FIN 报文的控制权交给服务端应用程序：\n\n如果服务端应用程序有数据要发送的话，就发完数据后，才调用关闭连接的函数；\n如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，\n\n从上面过程可知，是否要发送第三次挥手的控制权不在内核，而是在被动关闭方（上图的服务端）的应用程序，因为应用程序可能还有数据要发送，由应用程序决定什么时候调用关闭连接的函数，当调用了关闭连接的函数，内核就会发送 FIN 报文了，所以服务端的 ACK 和 FIN 一般都会分开发送。\n# 第二次和第三次挥手能合并嘛当被动关闭方在 TCP 挥手过程中，「没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。\n\n# 第三次挥手一直没发，会发生什么？当主动方收到 ACK 报文后，会处于 FIN_WAIT2 状态，就表示主动方的发送通道已经关闭，接下来将等待对方发送 FIN 报文，关闭对方的发送通道。\n这时，如果连接是用 shutdown 函数关闭的，连接可以一直处于 FIN_WAIT2 状态，因为它可能还可以发送或接收数据。但对于 close 函数关闭的孤儿连接，由于无法再发送和接收数据，所以这个状态不可以持续太久，而 tcp_fin_timeout 控制了这个状态下连接的持续时长，默认值是 60 秒：\n\n它意味着对于孤儿连接（调用 close 关闭的连接），如果在 60 秒后还没有收到 FIN 报文，连接就会直接关闭。\n# 第二次和第三次挥手之间，主动断开的那端能干什么如果主动断开的一方，是调用了 shutdown 函数来关闭连接，并且只选择了关闭发送能力且没有关闭接收能力的话，那么主动断开的一方在第二次和第三次挥手之间还可以接收数据。\n\n# 断开连接时客户端 FIN 包丢失，服务端的状态是什么？当客户端（主动关闭方）调用 close 函数后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 FIN_WAIT_1 状态。\n正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 FIN_WAIT2状态。\n如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。\n当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，那么客户端直接进入到 close 状态，而服务端还是ESTABLISHED状态\n举个例子，假设 tcp_orphan_retries 参数值为 3，当第一次挥手一直丢失时，发生的过程如下图：\n\n# 为什么四次挥手之后要等2MSL?MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。\nMSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。\nTTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了。\nTIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。\n比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 FIN 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。\n可以看到 2MSL时长 这其实是相当于至少允许报文丢失一次。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。\n# 服务端出现大量的timewait有哪些原因?问题来了，什么场景下服务端会主动断开连接呢？\n\n第一个场景：HTTP 没有使用长连接\n第二个场景：HTTP 长连接超时\n第三个场景：HTTP 长连接的请求数量达到上限\n\n接下来，分别介绍下。\n第一个场景：HTTP 没有使用长连接\n我们先来看看 HTTP 长连接（Keep-Alive）机制是怎么开启的。\n在 HTTP&#x2F;1.0 中默认是关闭的，如果浏览器要开启 Keep-Alive，它必须在请求的 header 中添加：\n然后当服务器收到请求，作出回应的时候，它也被添加到响应中 header 里：\n这样做，TCP 连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个 TCP 连接。这一直继续到客户端或服务器端提出断开连接。\n从 HTTP&#x2F;1.1 开始， 就默认是开启了 Keep-Alive，现在大多数浏览器都默认是使用 HTTP&#x2F;1.1，所以 Keep-Alive 都是默认打开的。一旦客户端和服务端达成协议，那么长连接就建立好了。\n如果要关闭 HTTP Keep-Alive，需要在 HTTP 请求或者响应的 header 里添加 Connection:close 信息，也就是说，只要客户端和服务端任意一方的 HTTP header 中有 Connection:close 信息，那么就无法使用 HTTP 长连接的机制。\n关闭 HTTP 长连接机制后，每次请求都要经历这样的过程：建立 TCP -&gt; 请求资源 -&gt; 响应资源 -&gt; 释放连接，那么此方式就是 HTTP 短连接，如下图：\n\n在前面我们知道，只要任意一方的 HTTP header 中有 Connection:close 信息，就无法使用 HTTP 长连接机制，这样在完成一次 HTTP 请求&#x2F;处理后，就会关闭连接。\n问题来了，这时候是客户端还是服务端主动关闭连接呢？\n在 RFC 文档中，并没有明确由谁来关闭连接，请求和响应的双方都可以主动关闭 TCP 连接。\n不过，根据大多数 Web 服务的实现，不管哪一方禁用了 HTTP Keep-Alive，都是由服务端主动关闭连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。\n第二个场景：HTTP 长连接超时\nHTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。\nHTTP 长连接可以在同一个 TCP 连接上接收和发送多个 HTTP 请求&#x2F;应答，避免了连接建立和释放的开销。\n\n可能有的同学会问，如果使用了 HTTP 长连接，如果客户端完成一个 HTTP 请求后，就不再发起新的请求，此时这个 TCP 连接一直占用着不是挺浪费资源的吗？\n对没错，所以为了避免资源浪费的情况，web 服务软件一般都会提供一个参数，用来指定 HTTP 长连接的超时时间，比如 nginx 提供的 keepalive_timeout 参数。\n假设设置了 HTTP 长连接的超时时间是 60 秒，nginx 就会启动一个「定时器」，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。\n\n当服务端出现大量 TIME_WAIT 状态的连接时，如果现象是有大量的客户端建立完 TCP 连接后，很长一段时间没有发送数据，那么大概率就是因为 HTTP 长连接超时，导致服务端主动关闭连接，产生大量处于 TIME_WAIT 状态的连接。\n可以往网络问题的方向排查，比如是否是因为网络问题，导致客户端发送的数据一直没有被服务端接收到，以至于 HTTP 长连接超时。\n第三个场景：HTTP 长连接的请求数量达到上限\nWeb 服务端通常会有个参数，来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接。\n比如 nginx 的 keepalive_requests 这个参数，这个参数是指一个 HTTP 长连接建立之后，nginx 就会为这个连接设置一个计数器，记录这个 HTTP 长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则 nginx 会主动关闭这个长连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。\nkeepalive_requests 参数的默认值是 100 ，意味着每个 HTTP 长连接最多只能跑 100 次请求，这个参数往往被大多数人忽略，因为当 QPS (每秒请求数) 不是很高时，默认值 100 凑合够用。\n但是，对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果 keepalive_requests 参数值是 100，这时候就 nginx 就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态。\n针对这个场景下，解决的方式也很简单，调大 nginx 的 keepalive_requests 参数就行。\n# TCP和UDP区别是什么？\n连接：TCP 是面向连接的传输层协议，传输数据前先要建立连接；UDP 是不需要连接，即刻传输数据。\n服务对象：TCP 是一对一的两点服务，即一条连接只有两个端点。UDP 支持一对一、一对多、多对多的交互通信\n可靠性：TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议\n拥塞控制、流量控制：TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。\n首部开销：TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。UDP 首部只有 8 个字节，并且是固定不变的，开销较小。\n传输方式：TCP 是流式传输，没有边界，但保证顺序和可靠。UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。\n\n# TCP为什么可靠传输TCP协议主要通过以下几点来保证传输可靠性：连接管理、序列号、确认应答、超时重传、流量控制、拥塞控制。\n\n连接管理：即三次握手和四次挥手。连接管理机制能够建立起可靠的连接，这是保证传输可靠性的前提。\n序列号：TCP将每个字节的数据都进行了编号，这就是序列号。序列号的具体作用如下：能够保证可靠性，既能防止数据丢失，又能避免数据重复。能够保证有序性，按照序列号顺序进行数据包还原。能够提高效率，基于序列号可实现多次发送，一次确认。\n确认应答：接收方接收数据之后，会回传ACK报文，报文中带有此次确认的序列号，用于告知发送方此次接收数据的情况。在指定时间后，若发送端仍未收到确认应答，就会启动超时重传。\n超时重传：超时重传主要有两种场景：数据包丢失：在指定时间后，若发送端仍未收到确认应答，就会启动超时重传，向接收端重新发送数据包。确认包丢失：当接收端收到重复数据(通过序列号进行识别)时将其丢弃，并重新回传ACK报文。\n流量控制：接收端处理数据的速度是有限的，如果发送方发送数据的速度过快，就会导致接收端的缓冲区溢出，进而导致丢包。为了避免上述情况的发生，TCP支持根据接收端的处理能力，来决定发送端的发送速度。这就是流量控制。流量控制是通过在TCP报文段首部维护一个滑动窗口来实现的。\n拥塞控制：拥塞控制就是当网络拥堵严重时，发送端减少数据发送。拥塞控制是通过发送端维护一个拥塞窗口来实现的。可以得出，发送端的发送速度，受限于滑动窗口和拥塞窗口中的最小值。拥塞控制方法分为：慢开始，拥塞避免、快重传和快恢复。\n\n# 怎么用udp实现http？UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输，在http3 就用了 quic 协议。\n\n连接迁移：QUIC支持在网络变化时快速迁移连接，例如从WiFi切换到移动数据网络，以保持连接的可靠性。\n重传机制：QUIC使用重传机制来确保丢失的数据包能够被重新发送，从而提高数据传输的可靠性。\n前向纠错：QUIC可以使用前向纠错技术，在接收端修复部分丢失的数据，降低重传的需求，提高可靠性和传输效率。\n拥塞控制：QUIC内置了拥塞控制机制，可以根据网络状况动态调整数据传输速率，以避免网络拥塞和丢包，提高可靠性。\n\n# tcp粘包怎么解决？粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。\n一般有三种方式分包的方式：\n\n固定长度的消息；\n特殊字符作为边界；\n自定义消息结构。\n\n\n\n\n\n\n\n\n\n\n固定长度的消息\n这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。\n但是这种方式灵活性不高，实际中很少用。\n\n\n\n\n\n\n\n\n\n特殊字符作为边界\n我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。\nHTTP 是一个非常好的例子。\n\nHTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。\n有一点要注意，这个作为边界点的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。\n\n\n\n\n\n\n\n\n\n自定义消息结构\n我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。\n比如这个消息结构体，首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。\n1234struct &#123;     u_int32_t message_length;     char message_data[]; &#125; message;\n\n当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。\n# TCP的拥塞控制介绍一下？一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。\n在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….\n所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。\n于是，就有了拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。\n为了在「发送方」调节所要发送数据的量，定义了一个叫做「拥塞窗口」的概念。\n拥塞窗口 cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd &#x3D; min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。\n拥塞窗口 cwnd 变化的规则：\n\n只要网络中没有出现拥塞，cwnd 就会增大；\n但网络中出现了拥塞，cwnd 就减少；\n\n那么怎么知道当前网络是否出现了拥塞呢？其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了拥塞。\n拥塞控制有哪些控制算法？\n拥塞控制主要是四个算法：\n\n慢启动\n拥塞避免\n拥塞发生\n快速恢复\n\n\n\n\n\n\n\n\n\n\n慢启动\nTCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？\n慢启动的算法记住一个规则就行：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。\n这里假定拥塞窗口 cwnd 和发送窗口 swnd 相等，下面举个栗子：\n\n连接建立完成后，一开始初始化 cwnd &#x3D; 1，表示可以传一个 MSS 大小的数据。\n当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个\n当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个\n当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。\n\n慢启动算法的变化过程如下图：\n\n可以看出慢启动算法，发包的个数是指数性的增长。\n那慢启动涨到什么时候是个头呢？\n有一个叫慢启动门限 ssthresh （slow start threshold）状态变量。\n\n当 cwnd &lt; ssthresh 时，使用慢启动算法。\n当 cwnd &gt;&#x3D; ssthresh 时，就会使用「拥塞避免算法」。\n\n\n\n\n\n\n\n\n\n\n拥塞避免算法\n前面说道，当拥塞窗口 cwnd 「超过」慢启动门限 ssthresh 就会进入拥塞避免算法。\n一般来说 ssthresh 的大小是 65535 字节。\n那么进入拥塞避免算法后，它的规则是：每当收到一个 ACK 时，cwnd 增加 1&#x2F;cwnd。\n接上前面的慢启动的栗子，现假定 ssthresh 为 8：\n\n当 8 个 ACK 应答确认到来时，每个确认增加 1&#x2F;8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 MSS 大小的数据，变成了线性增长。\n\n拥塞避免算法的变化过程如下图：\n\n所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。\n就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。\n当触发了重传机制，也就进入了「拥塞发生算法」。\n\n\n\n\n\n\n\n\n\n拥塞发生\n当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：\n\n超时重传\n快速重传\n\n这两种使用的拥塞发送算法是不同的，接下来分别来说说。\n发生超时重传的拥塞发生算法\n当发生了「超时重传」，则就会使用拥塞发生算法。\n这个时候，ssthresh 和 cwnd 的值会发生变化：\n\nssthresh 设为 cwnd&#x2F;2，\ncwnd 重置为 1 （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）\n\n拥塞发生算法的变化如下图：\n\n接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。\n就好像本来在秋名山高速漂移着，突然来个紧急刹车，轮胎受得了吗。。。\n发生快速重传的拥塞发生算法\n还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。\nTCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 ssthresh 和 cwnd 变化如下：\n\ncwnd &#x3D; cwnd&#x2F;2 ，也就是设置为原来的一半;\nssthresh &#x3D; cwnd;\n进入快速恢复算法\n\n\n\n\n\n\n\n\n\n\n快速恢复\n快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 RTO 超时那么强烈。\n正如前面所说，进入快速恢复之前，cwnd 和 ssthresh 已被更新了：\n\ncwnd &#x3D; cwnd&#x2F;2 ，也就是设置为原来的一半;\nssthresh &#x3D; cwnd;\n\n然后，进入快速恢复算法如下：\n\n拥塞窗口 cwnd &#x3D; ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）；\n重传丢失的数据包；\n如果再收到重复的 ACK，那么 cwnd 增加 1；\n如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；\n\n快速恢复算法的变化过程如下图：\n\n也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长。\n# 网络场景# 描述一下打开百度首页后发生的网络过程\n\n解析URL：分析 URL 所需要使用的传输协议和请求的资源路径。如果输入的 URL 中的协议或者主机名不合法，将会把地址栏中输入的内容传递给搜索引擎。如果没有问题，浏览器会检查 URL 中是否出现了非法字符，则对非法字符进行转义后在进行下一过程。\n缓存判断：浏览器会判断所请求的资源是否在缓存里，如果请求的资源在缓存里且没有失效，那么就直接使用，否则向服务器发起新的请求。\nDNS解析：如果资源不在本地缓存，首先需要进行DNS解析。浏览器会向本地DNS服务器发送域名解析请求，本地DNS服务器会逐级查询，最终找到对应的IP地址。\n获取MAC地址：当浏览器得到 IP 地址后，数据传输还需要知道目的主机 MAC 地址，因为应用层下发数据给传输层，TCP 协议会指定源端口号和目的端口号，然后下发给网络层。网络层会将本机地址作为源地址，获取的 IP 地址作为目的地址。然后将下发给数据链路层，数据链路层的发送需要加入通信双方的 MAC 地址，本机的 MAC 地址作为源 MAC 地址，目的 MAC 地址需要分情况处理。通过将 IP 地址与本机的子网掩码相结合，可以判断是否与请求主机在同一个子网里，如果在同一个子网里，可以使用 APR 协议获取到目的主机的 MAC 地址，如果不在一个子网里，那么请求应该转发给网关，由它代为转发，此时同样可以通过 ARP 协议来获取网关的 MAC 地址，此时目的主机的 MAC 地址应该为网关的地址。\n建立TCP连接：主机将使用目标 IP地址和目标MAC地址发送一个TCP SYN包，请求建立一个TCP连接，然后交给路由器转发，等路由器转到目标服务器后，服务器回复一个SYN-ACK包，确认连接请求。然后，主机发送一个ACK包，确认已收到服务器的确认，然后 TCP 连接建立完成。\nHTTPS 的 TLS 四次握手：如果使用的是 HTTPS 协议，在通信前还存在 TLS 的四次握手。\n发送HTTP请求：连接建立后，浏览器会向服务器发送HTTP请求。请求中包含了用户需要获取的资源的信息，例如网页的URL、请求方法（GET、POST等）等。\n服务器处理请求并返回响应：服务器收到请求后，会根据请求的内容进行相应的处理。例如，如果是请求网页，服务器会读取相应的网页文件，并生成HTTP响应。\n\n# 网页非常慢转圈圈的时候，要定位问题需要从哪些角度？最直接的办法就是抓包，排查的思路大概有：\n\n先确定是服务端的问题，还是客户端的问题。先确认浏览器是否可以访问其他网站，如果不可以，说明客户端网络自身的问题，然后检查客户端网络配置（连接wifi正不正常，有没有插网线）；如果可以正常其他网页，说明客户端网络是可以正常上网的。\n如果客户端网络没问题，就抓包确认 DNS 是否解析出了 IP 地址，如果没有解析出来，说明域名写错了，如果解析出了 IP 地址，抓包确认有没有和服务端建立三次握手，如果能成功建立三次握手，并且发出了 HTTP 请求，但是就是没有显示页面，可以查看服务端返回的响应码：\n如果是404错误码，检查输入的url是否正确；\n如果是500，说明服务器此时有问题；\n如果是200，F12看看前端代码有问题导致浏览器没有渲染出页面。\n\n\n如果客户端网络是正常的，但是访问速度很慢，导致很久才显示出来。这时候要看客户端的网口流量是否太大的了，导致tcp发生丢包之类的问题。\n\n总之就是一层一层有没有插网线，网络配置是否正确、DNS有没有解析出 IP地址、TCP有没有三次握手、HTTP返回的响应码是什么。\n推荐阅读：网站显示不出来，怎么排查？ (opens new window)\n# server a和server b，如何判断两个服务器正常连接？出错怎么办？直不会发送数据给客户端，那么服务端是永远无法感知到客户端宕机这个事件的，也就是服务端的 TCP 连接将一直处于 ESTABLISH 状态，占用着系统资源。\n为了避免这种情况，TCP 搞了个保活机制。这个机制的原理是这样的：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。\n在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：\n123net.ipv4.tcp_keepalive_time=7200net.ipv4.tcp_keepalive_intvl=75  net.ipv4.tcp_keepalive_probes=9\n\n\ntcp_keepalive_time&#x3D;7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制\ntcp_keepalive_intvl&#x3D;75：表示每次检测间隔 75 秒；\ntcp_keepalive_probes&#x3D;9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。\n\n也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。\n\n注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 SO_KEEPALIVE 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。\n如果开启了 TCP 保活，需要考虑以下几种情况：\n\n第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。\n第二种，对端主机宕机并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产生一个 RST 报文，这样很快就会发现 TCP 连接已经被重置。\n第三种，是对端主机宕机（注意不是进程崩溃，进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而主机宕机则是无法感知的，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机），或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。\n\nTCP 保活的这个机制检测的时间是有点长，我们可以自己在应用层实现一个心跳机制。\n比如，web 服务软件一般都会提供 keepalive_timeout 参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会启动一个定时器，如果客户端在完成一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，就会触发回调函数来释放该连接。\n\n# 服务端正常启动了，但是客户端请求不到有哪些原因?如何排查?如果客户端请求的接口没有响应，排查的方式：\n\n检查接口IP地址是否正确，ping一下接口地址。\n检查被测接口端口号是否正确，可以在本机Telnet接口的IP和端口号，检查端口号能否连通\n检查服务器的防火墙是否关闭，如果是以为安全或者权限问题不能关闭，需要找运维进行策略配置，开放对应的IP和端口。\n检查你的客户端（浏览器、测试工具 (opens new window)），是否设置了网络代理，网络代理可以造成请求失败。\n\n如果客户端的请求有响应，但是返回了错误状态码，那么根据错误码做对应的排查：\n\n400：客户端请求错误，比如请求参数格式错误\n401：未授权，比如请求header里，缺乏必要的信息头。（token，auth等）\n403：禁止，常见原因是因为用户的账号没有对应的URL权限，还有就是项目中所用的中间件，不允许远程连接（Tomcat）\n404：资源未找到，导致这种情况的原因很多，比如URL地址不正确\n500：服务器内部错误，出现这种情况，说明服务器内部报错了 ，需要登录服务器，检查错误日志，根具体的提示信息在进行排查\n502&#x2F;503&#x2F;504（错误的网关、服务器无法获得、网关超时）：如果单次调用接口就报该错误，说明后端服务器配置有问题或者服务不可用，挂掉了；如果是并发压测时出现的，说明后端压力太大，出现异常，此问题一般是后端出现了响应时间过长或者是无响应造成的\n\n# 服务器ping不通但是http能请求成功，会出现这种情况吗?什么原因造成的?ping 走的是 icmp 协议，http 走的是 tcp 协议。\n有可能服务器的防火墙禁止 icmp 协议，但是 tcp 协议没有禁止，就会出现服务器 ping 不通，但是 http 能请求成果。\n# 网络攻击# 什么是ddos攻击？怎么防范？分布式拒绝服务（DDoS）攻击是通过大规模互联网流量淹没目标服务器或其周边基础设施，以破坏目标服务器、服务或网络正常流量的恶意行为。\nDDoS 攻击是通过连接互联网的计算机网络进行的。这些网络由计算机和其他设备（例如 IoT 设备）组成，它们感染了恶意软件，从而被攻击者远程控制。这些个体设备称为机器人（或僵尸），一组机器人则称为僵尸网络。\n\n一旦建立了僵尸网络，攻击者就可通过向每个机器人发送远程指令来发动攻击。当僵尸网络将受害者的服务器或网络作为目标时，每个机器人会将请求发送到目标的 IP 地址，这可能导致服务器或网络不堪重负，从而造成对正常流量的拒绝服务。由于每个机器人都是合法的互联网设备，因而可能很难区分攻击流量与正常流量。\n常见的DDoS攻击包括以下几类：\n\n网络层攻击：比较典型的攻击类型是UDP反射攻击，例如：NTP Flood攻击，这类攻击主要利用大流量拥塞被攻击者的网络带宽，导致被攻击者的业务无法正常响应客户访问。\n传输层攻击：比较典型的攻击类型包括SYN Flood攻击、连接数攻击等，这类攻击通过占用服务器的连接池资源从而达到拒绝服务的目的。\n会话层攻击：比较典型的攻击类型是SSL连接攻击，这类攻击占用服务器的SSL会话资源从而达到拒绝服务的目的。\n应用层攻击：比较典型的攻击类型包括DNS flood攻击、HTTP flood攻击、游戏假人攻击等，这类攻击占用服务器的应用处理资源极大的消耗服务器处理性能从而达到拒绝服务的目的。\n\n为了防范DDoS攻击，可以采取以下措施：\n\n增强网络基础设施：提升网络带宽、增加服务器的处理能力和承载能力，通过增强基础设施的能力来抵御攻击。\n使用防火墙和入侵检测系统：配置防火墙规则，限制不必要的网络流量，阻止来自可疑IP地址的流量。入侵检测系统可以帮助及时发现并响应DDoS攻击。\n流量清洗和负载均衡：使用专业的DDoS防护服务提供商，通过流量清洗技术过滤掉恶意流量，将合法流量转发给目标服务器。负载均衡可以将流量均匀地分发到多台服务器上，减轻单一服务器的压力。\n配置访问控制策略：限制特定IP地址或IP段的访问，设置访问频率限制，防止过多请求集中在单个IP上。\n\n# SQL注入问题是什么？SQL注入发生在当应用程序直接使用用户提供的输入作为SQL查询的一部分时。当用户输入被错误地用作数据库查询的一部分，而应用程序没有对其进行适当的验证和转义，就可能会发生SQL注入。\n例如，如果一个用户输入了一个字符串来查找特定用户的信息，但应用程序将此用户输入直接用作SQL查询的一部分（例如，作为SELECT语句的一部分），而不考虑可能的安全问题，那么攻击者可能会利用这一点来执行他们自己的恶意SQL查询。\n\n解决SQL注入问题的方法主要有以下几种：\n\n输入验证和转义：在将用户输入用作SQL查询的一部分之前，对输入进行验证和转义。确保输入符合预期格式，并防止任何可能导致SQL注入的特殊字符。\n使用参数化查询：使用参数化查询可以避免直接将用户输入嵌入到SQL查询中。参数化查询使用预定义的变量来接收用户输入，并将其传递给数据库引擎，而不是直接将其用作查询的一部分。这样可以防止SQL注入攻击。\n限制数据库权限：限制数据库用户的权限，只授予他们执行所需操作所需的最低权限。攻击者可能具有比预期更多的权限，这可能会使攻击更加容易。\n实施输入过滤：在某些情况下，实施输入过滤可以进一步减少SQL注入的风险。这可能涉及检查和过滤用户输入中的特殊字符和词汇，以排除可能的恶意输入。\n\n# CSRF攻击是什么？CSRF（跨站请求伪造）是一种攻击手段，攻击者通过诱导用户执行恶意操作，从而获取用户数据或执行恶意代码。CSRF攻击通常通过伪造一个合法的HTTP请求来实现，这个请求看起来是合法的，但实际上是为了执行一个攻击者控制的操作。\n\n解决CSRF攻击的方法主要有以下几种：\n\n验证用户会话：在服务器端对用户会话进行验证，确保请求的会话标识符与当前会话标识符匹配。这样可以防止攻击者伪造会话标识符。\n使用双重验证：除了会话验证，还可以使用其他验证方式，例如验证码、签名验证等。这些验证方式可以增加攻击的难度。\n防止跨站请求：通过设置CSP（内容安全策略）来防止跨站请求，限制网页中可执行的脚本源，减少攻击者诱导用户执行恶意操作的可能性。\n避免使用自动提交表单：禁用默认的自动提交功能，要求用户在提交表单前确认操作，防止攻击者诱导用户在未经授权的情况下提交表单。\n强制Referer头部：在服务器端检查请求的Referer头部，确保请求来自可信来源。\n\n# XSS攻击是什么？XSS是跨站脚本攻击，攻击者通过在Web页面中插入恶意脚本代码，然后诱使用户访问该页面，从而使得恶意脚本在用户浏览器中执行，从而盗取用户信息、会话信息等敏感数据，甚至控制用户账户。\n\nXSS 攻击可以分为 3 类：存储型（持久型）、反射型（非持久型）、DOM 型。\n\n存储型 XSS (opens new window)：注入型脚本永久存储在目标服务器上。当浏览器请求数据时，脚本从服务器上传回并执行。\n反射型 XSS (opens new window)：当用户点击一个恶意链接，或者提交一个表单，或者进入一个恶意网站时，注入脚本进入被攻击者的网站。Web 服务器将注入脚本，比如一个错误信息，搜索结果等 返回到用户的浏览器上。由于浏览器认为这个响应来自”可信任”的服务器，所以会执行这段脚本。\n基于 DOM 的 XSS (opens new window)：通过修改原始的客户端代码，受害者浏览器的 DOM 环境改变，导致有效载荷的执行。也就是说，页面本身并没有变化，但由于 DOM 环境被恶意修改，有客户端代码被包含进了页面，并且意外执行。\n\n预防XSS攻击的方法主要包括以下几点：\n\n输入验证：对所有用户输入的数据进行有效性检验，过滤或转义特殊字符。例如，禁止用户输入HTML标签和JavaScript代码。\n输出编码：在网页输出用户输入内容时，使用合适的编码方式，如HTML转义、URL编码等，防止恶意脚本注入。\nContent Security Policy（CSP）：通过设置CSP策略，限制网页中可执行的脚本源，有效防范XSS攻击。\n使用HttpOnly标记：在设置Cookie时，设置HttpOnly属性，使得Cookie无法被JavaScript代码读取，减少受到XSS攻击的可能。\n\n# 了解过DNS劫持吗？DNS劫持的原理是攻击者在用户查询DNS服务器时篡改响应，将用户请求的域名映射到攻击者控制的虚假IP地址上，使用户误以为访问的是正常网站，实际上被重定向到攻击者操控的恶意网站。这种劫持可以通过植入恶意的DNS记录或劫持用户的DNS流量来实现。\n\n\n","slug":"计网/计算机网络面试题","date":"2024-12-04T04:15:38.000Z","categories_index":"八股","tags_index":"精选,计算机网络","author_index":"Ivan"},{"id":"a978a5e93d8e6628e9f4ee713be55be8","title":"Redis","content":"# Redis# 数据结构# 讲一下Redis底层的数据结构Redis 提供了丰富的数据类型，常见的有五种数据类型：String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）。\n\n\n随着 Redis 版本的更新，后面又支持了四种数据类型：BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）。Redis 五种数据类型的应用场景：\n\nString 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。\nList 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。\nHash 类型：缓存对象、购物车等。\nSet 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。\nZset 类型：排序场景，比如排行榜、电话和姓名排序等。\n\nRedis 后续版本又支持四种数据类型，它们的应用场景如下：\n\nBitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；\nHyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；\nGEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；\nStream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。\n\n# ZSet用过吗用过 zset 实现排行榜的功能。\n以博文点赞排名为例，小林发表了五篇博文，分别获得赞为 200、40、100、50、150。\n123456789101112131415# arcticle:1 文章获得了200个赞&gt; ZADD user:xiaolin:ranking 200 arcticle:1(integer) 1# arcticle:2 文章获得了40个赞&gt; ZADD user:xiaolin:ranking 40 arcticle:2(integer) 1# arcticle:3 文章获得了100个赞&gt; ZADD user:xiaolin:ranking 100 arcticle:3(integer) 1# arcticle:4 文章获得了50个赞&gt; ZADD user:xiaolin:ranking 50 arcticle:4(integer) 1# arcticle:5 文章获得了150个赞&gt; ZADD user:xiaolin:ranking 150 arcticle:5(integer) 1\n\n文章 arcticle:4 新增一个赞，可以使用 ZINCRBY 命令（为有序集合key中元素member的分值加上increment）：\n12&gt; ZINCRBY user:xiaolin:ranking 1 arcticle:4&quot;51&quot;\n\n查看某篇文章的赞数，可以使用 ZSCORE 命令（返回有序集合key中元素个数）：\n12&gt; ZSCORE user:xiaolin:ranking arcticle:4&quot;50&quot;\n\n获取小林文章赞数最多的 3 篇文章，可以使用 ZREVRANGE 命令（倒序获取有序集合 key 从start下标到stop下标的元素）：\n12345678# WITHSCORES 表示把 score 也显示出来&gt; ZREVRANGE user:xiaolin:ranking 0 2 WITHSCORES1) &quot;arcticle:1&quot;2) &quot;200&quot;3) &quot;arcticle:5&quot;4) &quot;150&quot;5) &quot;arcticle:3&quot;6) &quot;100&quot;\n\n获取小林 100 赞到 200 赞的文章，可以使用 ZRANGEBYSCORE 命令（返回有序集合中指定分数区间内的成员，分数由低到高排序）：\n1234567&gt; ZRANGEBYSCORE user:xiaolin:ranking 100 200 WITHSCORES1) &quot;arcticle:3&quot;2) &quot;100&quot;3) &quot;arcticle:5&quot;4) &quot;150&quot;5) &quot;arcticle:1&quot;6) &quot;200&quot;\n\n# Zset 底层是怎么实现的？Zset 类型的底层数据结构是由压缩列表或跳表实现的：\n\n如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用压缩列表作为 Zset 类型的底层数据结构；\n如果有序集合的元素不满足上面的条件，Redis 会使用跳表作为 Zset 类型的底层数据结构；\n\n在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。\n# 跳表是怎么实现的？链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N)，于是就出现了跳表。跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表，这样的好处是能快读定位数据。\n那跳表长什么样呢？我这里举个例子，下图展示了一个层级为 3 的跳表。\n\n图中头节点有 L0~L2 三个头指针，分别指向了不同层级的节点，然后每个层级的节点都通过指针连接起来：\n\nL0 层级共有 5 个节点，分别是节点1、2、3、4、5；\nL1 层级共有 3 个节点，分别是节点 2、3、5；\nL2 层级只有 1 个节点，也就是节点 3 。\n\n如果我们要在链表中查找节点 4 这个元素，只能从头开始遍历链表，需要查找 4 次，而使用了跳表后，只需要查找 2 次就能定位到节点 4，因为可以在头节点直接从 L2 层级跳到节点 3，然后再往前遍历找到节点 4。\n可以看到，这个查找过程就是在多个层级上跳来跳去，最后定位到元素。当数据量很大时，跳表的查找复杂度就是 O(logN)。\n那跳表节点是怎么实现多层级的呢？这就需要看「跳表节点」的数据结构了，如下：\n1234567891011121314typedef struct zskiplistNode &#123;    //Zset 对象的元素值    sds ele;    //元素权重值    double score;    //后向指针    struct zskiplistNode *backward;      //节点的level数组，保存每层上的前向指针和跨度    struct zskiplistLevel &#123;        struct zskiplistNode *forward;        unsigned long span;    &#125; level[];&#125; zskiplistNode;\n\nZset 对象要同时保存「元素」和「元素的权重」，对应到跳表节点结构里就是 sds 类型的 ele 变量和 double 类型的 score 变量。每个跳表节点都有一个后向指针（struct zskiplistNode *backward），指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。\n跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的zskiplistLevel 结构体类型的 level 数组。\nlevel 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。zskiplistLevel 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。\n比如，下面这张图，展示了各个节点的跨度。\n\n第一眼看到跨度的时候，以为是遍历操作有关，实际上并没有任何关系，遍历操作只需要用前向指针（struct zskiplistNode *forward）就可以完成了。\nRedis 跳表在创建节点的时候，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。\n具体的做法是，跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。\n这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。\n虽然我前面讲解跳表的时候，图中的跳表的「头节点」都是 3 层高，但是其实如果层高最大限制是 64，那么在创建跳表「头节点」的时候，就会直接创建 64 层高的头节点。\n# 跳表是怎么设置层高的？跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。\n# Redis为什么使用跳表而不是用B+树?主要是从内存占用、对范围查找的支持、实现难易程度这三方面总结的原因：\n\n从内存占用上来比较，跳表比平衡树更灵活一些。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1&#x2F;(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p&#x3D;1&#x2F;4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。\n在做范围查找的时候，跳表比平衡树操作要简单。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。\n从算法实现难度上来比较，跳表比平衡树要简单得多。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。\n\n# 压缩列表是怎么实现的？压缩列表是 Redis 为了节约内存而开发的，它是由连续内存块组成的顺序型数据结构，有点类似于数组。\n\n压缩列表在表头有三个字段：\n\n***zlbytes***，记录整个压缩列表占用对内存字节数；\n***zltail***，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；\n***zllen***，记录压缩列表包含的节点数量；\n***zlend***，标记压缩列表的结束点，固定值 0xFF（十进制255）。\n\n在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段（zllen）的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素。\n另外，压缩列表节点（entry）的构成如下：\n\n压缩列表节点包含三部分内容：\n\nprevlen，记录了「前一个节点」的长度，目的是为了实现从后向前遍历；\nencoding，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。\ndata，记录了当前节点的实际数据，类型和长度都由 encoding 决定；\n\n当我们往压缩列表中插入数据时，压缩列表就会根据数据类型是字符串还是整数，以及数据的大小，会使用不同空间大小的 prevlen 和 encoding 这两个元素里保存的信息，这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的。\n压缩列表的缺点是会发生连锁更新的问题，因此连锁更新一旦发生，就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能。\n所以说，虽然压缩列表紧凑型的内存布局能节省内存开销，但是如果保存的元素数量增加了，或是元素变大了，会导致内存重新分配，最糟糕的是会有「连锁更新」的问题。\n因此，压缩列表只会用于保存的节点数量不多的场景，只要节点数量足够小，即使发生连锁更新，也是能接受的。\n虽说如此，Redis 针对压缩列表在设计上的不足，在后来的版本中，新增设计了两种数据结构：quicklist（Redis 3.2 引入） 和 listpack（Redis 5.0 引入）。这两种数据结构的设计目标，就是尽可能地保持压缩列表节省内存的优势，同时解决压缩列表的「连锁更新」的问题。\n# 介绍一下 Redis 中的 listpackquicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。\n因为 quicklistNode 还是用了压缩列表来保存元素，压缩列表连锁更新的问题，来源于它的结构设计，所以要想彻底解决这个问题，需要设计一个新的数据结构。\n于是，Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。\nlistpack 采用了压缩列表的很多优秀的设计，比如还是用一块连续的内存空间来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。\n我们先看看 listpack 结构：\n\nlistpack 头包含两个属性，分别记录了 listpack 总字节数和元素数量，然后 listpack 末尾也有个结尾标识。图中的 listpack entry 就是 listpack 的节点了。\n每个 listpack 节点结构如下：\n\n主要包含三个方面内容：\n\nencoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；\ndata，实际存放的数据；\nlen，encoding+data的总长度；\n\n可以看到，listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题。\n# 哈希表是怎么扩容的？进行 rehash 的时候，需要用上 2 个哈希表了。\n\n在正常服务请求阶段，插入的数据，都会写入到「哈希表 1」，此时的「哈希表 2 」 并没有被分配空间。\n随着数据逐步增多，触发了 rehash 操作，这个过程分为三步：\n\n给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍；\n将「哈希表 1 」的数据迁移到「哈希表 2」 中；\n迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。\n\n为了方便你理解，我把 rehash 这三个过程画在了下面这张图：\n\n这个过程看起来简单，但是其实第二步很有问题，如果「哈希表 1 」的数据量非常大，那么在迁移至「哈希表 2 」的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求。\n为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了渐进式 rehash，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。\n渐进式 rehash 步骤如下：\n\n给「哈希表 2」 分配空间；\n在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上；\n随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。\n\n这样就巧妙地把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中，避免了一次性 rehash 的耗时操作。\n在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。\n另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。\n# 哈希表扩容的时候，有读请求怎么查？查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。\n# String 是使用什么存储的?为什么不用 c 语言中的字符串?Redis 的 String 字符串是用 SDS 数据结构存储的。\n下图就是 Redis 5.0 的 SDS 的数据结构：\n\n结构中的每个成员变量分别介绍下：\n\nlen，记录了字符串长度。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O（1）。\nalloc，分配给字符数组的空间长度。这样在修改字符串的时候，可以通过 alloc - len 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。\nflags，用来表示不同类型的 SDS。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，后面在说明区别之处。\nbuf[]，字符数组，用来保存实际数据。不仅可以保存字符串，也可以保存二进制数据。\n\n总的来说，Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据：len、alloc、flags，用来解决 C 语言字符串的缺陷。\n\n\n\n\n\n\n\n\n\nO（1）复杂度获取字符串长度\nC 语言的字符串长度获取 strlen 函数，需要通过遍历的方式来统计字符串长度，时间复杂度是 O（N）。\n而 Redis 的 SDS 结构因为加入了 len 成员变量，那么获取字符串长度的时候，直接返回这个成员变量的值就行，所以复杂度只有 O（1）。\n\n\n\n\n\n\n\n\n\n二进制安全\n因为 SDS 不需要用 “\\0” 字符来标识字符串结尾了，而是有个专门的 len 成员变量来记录长度，所以可存储包含 “\\0” 的数据。但是 SDS 为了兼容部分 C 语言标准库的函数， SDS 字符串结尾还是会加上 “\\0” 字符。\n因此， SDS 的 API 都是以处理二进制的方式来处理 SDS 存放在 buf[] 里的数据，程序不会对其中的数据做任何限制，数据写入的时候时什么样的，它被读取时就是什么样的。\n通过使用二进制安全的 SDS，而不是 C 字符串，使得 Redis 不仅可以保存文本数据，也可以保存任意格式的二进制数据。\n\n\n\n\n\n\n\n\n\n不会发生缓冲区溢出\nC 语言的字符串标准库提供的字符串操作函数，大多数（比如 strcat 追加字符串函数）都是不安全的，因为这些函数把缓冲区大小是否满足操作需求的工作交由开发者来保证，程序内部并不会判断缓冲区大小是否足够用，当发生了缓冲区溢出就有可能造成程序异常结束。\n所以，Redis 的 SDS 结构里引入了 alloc 和 len 成员变量，这样 SDS API 通过 alloc - len 计算，可以算出剩余可用的空间大小，这样在对字符串做修改操作的时候，就可以由程序内部判断缓冲区大小是否足够用。\n而且，当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小，以满足修改所需的大小。\n# 线程模型# Redis为什么快？官方使用基准测试的结果是，单线程的 Redis 吞吐量可以达到 10W&#x2F;每秒，如下图所示：\n\n之所以 Redis 采用单线程（网络 I&#x2F;O 和执行命令）那么快，有如下几个原因：\n\nRedis 的大部分操作都在内存中完成，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；\nRedis 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。\nRedis 采用了 I&#x2F;O 多路复用机制处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select&#x2F;epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。\n\n# Redis哪些地方使用了多线程?Redis 单线程指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」这个过程是由一个线程（主线程）来完成的，这也是我们常说 Redis 是单线程的原因。\n但是，Redis 程序并不是单线程的，Redis 在启动的时候，是会启动后台线程（BIO）的：\n\nRedis 在 2.6 版本，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；\nRedis 在 4.0 版本之后，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。例如执行 unlink key &#x2F; flushdb async &#x2F; flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，因此我们应该使用 unlink 命令来异步删除大key。\n\n之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。\n后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。\n\n虽然 Redis 的主要工作（网络 I&#x2F;O 和执行命令）一直是单线程模型，但是在 Redis 6.0 版本之后，也采用了多个 I&#x2F;O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I&#x2F;O 的处理上。\n所以为了提高网络 I&#x2F;O 的并行度，Redis 6.0 对于网络 I&#x2F;O 采用多线程来处理。但是对于命令的执行，Redis 仍然使用单线程来处理，所以大家不要误解Redis 有多线程同时执行命令。\nRedis 官方表示，Redis 6.0 版本引入的多线程 I&#x2F;O 特性对性能提升至少是一倍以上。\nRedis 6.0 版本支持的 I&#x2F;O 多线程特性，默认情况下 I&#x2F;O 多线程只针对发送响应数据（write client socket），并不会以多线程的方式处理读请求（read client socket）。要想开启多线程处理客户端读请求，就需要把 Redis.conf 配置文件中的 io-threads-do-reads 配置项设为 yes。\n12//读请求也使用io多线程io-threads-do-reads yes\n\n同时， Redis.conf 配置文件中提供了 IO 多线程个数的配置项。\n12// io-threads N，表示启用 N-1 个 I/O 多线程（主线程也算一个 I/O 线程）io-threads 4\n\n关于线程数的设置，官方的建议是如果为 4 核的 CPU，建议线程数设置为 2 或 3，如果为 8 核 CPU 建议线程数设置为 6，线程数一定要小于机器核数，线程数并不是越大越好。\n因此， Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会额外创建 6 个线程（这里的线程数不包括主线程）：\n\nRedis-server ： Redis的主线程，主要负责执行命令；\nbio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；\nio_thd_1、io_thd_2、io_thd_3：三个 I&#x2F;O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I&#x2F;O 多线程，用来分担 Redis 网络 I&#x2F;O 的压力。\n\n# Redis怎么实现的io多路复用？为什么 Redis 中要使用 I&#x2F;O 多路复用这种技术呢？\n因为 Redis 是跑在「单线程」中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入 或 输出都是阻塞的，所以 I&#x2F;O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I&#x2F;O 阻塞导，致整个进程无法对其它客户提供服务。而 I&#x2F;O 多路复用就是为了解决这个问题而出现的。为了让单线程(进程)的服务端应用同时处理多个客户端的事件，Redis 采用了 IO 多路复用机制。\n这里“多路”指的是多个网络连接客户端，“复用”指的是复用同一个线程(单进程)。I&#x2F;O 多路复用其实是使用一个线程来检查多个 Socket 的就绪状态，在单个线程中通过记录跟踪每一个 socket（I&#x2F;O流）的状态来管理处理多个 I&#x2F;O 流。如下图是 Redis 的 I&#x2F;O 多路复用模型：\n\n如上图对 Redis 的 I&#x2F;O 多路复用模型进行一下描述说明：\n\n一个 socket 客户端与服务端连接时，会生成对应一个套接字描述符(套接字描述符是文件描述符的一种)，每一个 socket 网络连接其实都对应一个文件描述符。\n多个客户端与服务端连接时，Redis 使用 I&#x2F;O 多路复用程序 将客户端 socket 对应的 FD 注册到监听列表(一个队列)中。当客服端执行 read、write 等操作命令时，I&#x2F;O 多路复用程序会将命令封装成一个事件，并绑定到对应的 FD 上。\n文件事件处理器使用 I&#x2F;O 多路复用模块同时监控多个文件描述符（fd）的读写情况，当 accept、read、write 和 close 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器进行处理相关命令操作。\n\n例如：以 Redis 的 I&#x2F;O 多路复用程序 epoll 函数为例。多个客户端连接服务端时，Redis 会将客户端 socket 对应的 fd 注册进 epoll，然后 epoll 同时监听多个文件描述符(FD)是否有数据到来，如果有数据来了就通知事件处理器赶紧处理，这样就不会存在服务端一直等待某个客户端给数据的情形。\n整个文件事件处理器是在单线程上运行的，但是通过 I&#x2F;O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，当其中一个 client 端达到写或读的状态，文件事件处理器就马上执行，从而就不会出现 I&#x2F;O 堵塞的问题，提高了网络通信的性能。\nRedis 的 I&#x2F;O 多路复用模式使用的是 Reactor 设置模式的方式来实现。\n# Redis的网络模型是怎样的？Redis 6.0 版本之前，是用的是单Reactor单线程的模式\n\n单 Reactor 单进程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。\n但是，这种方案存在 2 个缺点：\n\n第一个缺点，因为只有一个进程，无法充分利用 多核 CPU 的性能；\n第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟；\n\n所以，单 Reactor 单进程的方案不适用计算机密集型的场景，只适用于业务处理非常快速的场景。\nRedis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。\n到 Redis 6.0 之后，就将网络IO的处理改成多线程的方式了，目的是为了这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I&#x2F;O 的处理上。\n所以为了提高网络 I&#x2F;O 的并行度，Redis 6.0 对于网络 I&#x2F;O 采用多线程来处理。但是对于命令的执行，Redis 仍然使用单线程来处理，所以大家不要误解 Redis 有多线程同时执行命令。\n# 事务# 如何实现redis 原子性？redis 执行一条命令的时候是具备原子性的，因为 redis 执行命令的时候是单线程来处理的，不存在多线程安全的问题。\n如果要保证 2 条命令的原子性的话，可以考虑用 lua 脚本，将多个操作写到一个 Lua 脚本中，Redis 会把整个 Lua 脚本作为一个整体执行，在执行的过程中不会被其他命令打断，从而保证了 Lua 脚本中操作的原子性。\n比如说，在用 redis 实现分布式锁的场景下，解锁期间涉及 2 个操作，分别是先判断锁是不是自己的，是自己的才能删除锁，为了保证这 2 个操作的原子性，会通过 lua 脚本来保证原子性。\n123456// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then    return redis.call(&quot;del&quot;,KEYS[1])else    return 0end\n\n# 除了lua有没有什么也能保证redis的原子性？redis 事务也可以保证多个操作的原子性。\n如果 redis 事务正常执行，没有发生任何错误，那么使用 MULTI 和 EXEC 配合使用，就可以保证多个操作都完成。\n但是，如果事务执行发生错误了，就没办法保证原子性了。比如说 2 个操作，第一个操作执行成果了，但是第二个操作执行的时候，命令出错了，那事务并不会回滚，因为Redis 中并没有提供回滚机制。\n举个小例子。事务中的 LPOP 命令对 String 类型数据进行操作，入队时没有报错，但是，在 EXEC 执行时报错了。LPOP 命令本身没有执行成功，但是事务中的 DECR 命令却成功执行了。\n12345678910111213#开启事务127.0.0.1:6379&gt; MULTIOK#发送事务中的第一个操作，LPOP命令操作的数据类型不匹配，此时并不报错127.0.0.1:6379&gt; LPOP a:stockQUEUED#发送事务中的第二个操作127.0.0.1:6379&gt; DECR b:stockQUEUED#实际执行事务，事务第一个操作执行报错127.0.0.1:6379&gt; EXEC1) (error) WRONGTYPE Operation against a key holding the wrong kind of value2) (integer) 8\n\n因此，Redis 对事务原子性属性的保证情况：\n\nRedis 事务正常执行，可以保证原子性；\nRedis 事务执行中某一个操作执行失败，不保证原子性；\n\n# 日志# Redis有哪2种持久化方式？分别的优缺点是什么？Redis 的读写操作都是在内存中，所以 Redis 性能才会高，但是当 Redis 重启后，内存中的数据就会丢失，那为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。Redis 共有三种数据持久化的方式：\n\nAOF 日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；\nRDB 快照：将某一时刻的内存数据，以二进制的方式写入磁盘；\n\n\n\n\n\n\n\n\n\n\nAOF 日志是如何实现的？\nRedis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。\n我这里以「set name xiaolin」命令作为例子，Redis 执行了这条命令后，记录在 AOF 日志里的内容如下图：\nRedis 提供了 3 种写回硬盘的策略， 在 Redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填：\n\nAlways，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；\nEverysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；\nNo，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。\n\n我也把这 3 个写回策略的优缺点总结成了一张表格：\n\n\n\n\n\n\n\n\n\n\nRDB 快照是如何实现的呢？\n因为 AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢。为了解决这个问题，Redis 增加了 RDB 快照。\n所谓的快照，就是记录某一个瞬间东西，比如当我们给风景拍照时，那一个瞬间的画面和信息就记录到了一张照片。所以，RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。\nRedis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：\n\n执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，会阻塞主线程；\n执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以避免主线程的阻塞；\n\n\n\n\n\n\n\n\n\n\nAOF和RDB优缺点\nAOF：\n\n**优点：**首先，AOF提供了更好的数据安全性，因为它默认每接收到一个写命令就会追加到文件末尾。即使Redis服务器宕机，也只会丢失最后一次写入前的数据。其次，AOF支持多种同步策略（如everysec、always等），可以根据需要调整数据安全性和性能之间的平衡。同时，AOF文件在Redis启动时可以通过重写机制优化，减少文件体积，加快恢复速度。并且，即使文件发生损坏，AOF还提供了redis-check-aof工具来修复损坏的文件。\n缺点:因为记录了每一个写操作，所以AOF文件通常比RDB文件更大，消耗更多的磁盘空间。并且，频繁的磁盘IO操作（尤其是同步策略设置为always时）可能会对Redis的写入性能造成一定影响。而且，当问个文件体积过大时，AOF会进行重写操作，AOF如果没有开启AOF重写或者重写频率较低，恢复过程可能较慢，因为它需要重放所有的操作命令。\n\nRDB：\n\n优点: RDB通过快照的形式保存某一时刻的数据状态，文件体积小，备份和恢复的速度非常快。并且，RDB是在主线程之外通过fork子进程来进行的，不会阻塞服务器处理命令请求，对Redis服务的性能影响较小。最后，由于是定期快照，RDB文件通常比AOF文件小得多。\n缺点: RDB方式在两次快照之间，如果Redis服务器发生故障，这段时间的数据将会丢失。并且，如果在RDB创建快照到恢复期间有写操作，恢复后的数据可能与故障前的数据不完全一致\n\n# 缓存淘汰和过期删除# 过期删除策略和内存淘汰策略有什么区别？区别：\n\n内存淘汰策略是在内存满了的时候，redis 会触发内存淘汰策略，来淘汰一些不必要的内存资源，以腾出空间，来保存新的内容\n过期键删除策略是将已过期的键值对进行删除，Redis 采用的删除策略是惰性删除+定期删除。\n\n# 介绍一下Redis 内存淘汰策略在 32 位操作系统中，maxmemory 的默认值是 3G，因为 32 位的机器最大只支持 4GB 的内存，而系统本身就需要一定的内存资源来支持运行，所以 32 位操作系统限制最大 3 GB 的可用内存是非常合理的，这样可以避免因为内存不足而导致 Redis 实例崩溃。\nRedis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。\n\n1、不进行数据淘汰的策略：\n\nnoeviction（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，会报错通知禁止写入，不淘汰任何数据，但是如果没用数据写入的话，只是单纯的查询或者删除操作的话，还是可以正常工作。\n\n2、进行数据淘汰的策略：\n针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。\n\n在设置了过期时间的数据中进行淘汰：\n\nvolatile-random：随机淘汰设置了过期时间的任意键值；\n\nvolatile-ttl：优先淘汰更早过期的键值。\n\nvolatile-lru（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；\n\nvolatile-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；\n\n在所有数据范围内进行淘汰：\n\nallkeys-random：随机淘汰任意键值;\n\nallkeys-lru：淘汰整个键值中最久未使用的键值；\n\nallkeys-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。\n\n\n# 介绍一下Redis过期删除策略Redis 选择「惰性删除+定期删除」这两种策略配和使用，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。\nRedis 的惰性删除策略由 db.c 文件中的 expireIfNeeded 函数实现，代码如下：\n12345678910int expireIfNeeded(redisDb *db, robj *key) &#123;    // 判断 key 是否过期    if (!keyIsExpired(db,key)) return 0;    ....    /* 删除过期键 */    ....    // 如果 server.lazyfree_lazy_expire 为 1 表示异步删除，反之同步删除；    return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) :                                         dbSyncDelete(db,key);&#125;\n\nRedis 在访问或者修改 key 之前，都会调用 expireIfNeeded 函数对其进行检查，检查 key 是否过期：\n\n如果过期，则删除该 key，至于选择异步删除，还是选择同步删除，根据 lazyfree_lazy_expire 参数配置决定（Redis 4.0版本开始提供参数），然后返回 null 客户端；\n如果没有过期，不做任何处理，然后返回正常的键值对给客户端；\n\n惰性删除的流程图如下：\n\nRedis 的定期删除是****每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。\n1、这个间隔检查的时间是多长呢？\n在 Redis 中，默认每秒进行 10 次过期检查一次数据库，此配置可通过 Redis 的配置文件 redis.conf 进行配置，配置键为 hz 它的默认值是 hz 10。特别强调下，每次检查数据库并不是遍历过期字典中的所有 key，而是从数据库中随机抽取一定数量的 key 进行过期检查。\n2、随机抽查的数量是多少呢？\n我查了下源码，定期删除的实现在 expire.c 文件下的 activeExpireCycle 函数中，其中随机抽查的数量由 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 定义的，它是写死在代码中的，数值是 20。也就是说，数据库每轮抽查时，会随机选择 20 个 key 判断是否过期。接下来，详细说说 Redis 的定期删除的流程：\n\n从过期字典中随机抽取 20 个 key；\n检查这 20 个 key 是否过期，并删除已过期的 key；\n如果本轮检查的已过期 key 的数量，超过 5 个（20&#x2F;4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。\n\n可以看到，定期删除是一个循环的流程。那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。针对定期删除的流程，我写了个伪代码：\n123456789101112131415do &#123;    //已过期的数量    expired = 0；    //随机抽取的数量    num = 20;    while (num--) &#123;        //1. 从过期字典中随机抽取 1 个 key        //2. 判断该 key 是否过期，如果已过期则进行删除，同时对 expired++    &#125;        // 超过时间限制则退出    if (timelimit_exit) return;  /* 如果本轮检查的已过期 key 的数量，超过 25%，则继续随机抽查，否则退出本轮检查 */&#125; while (expired &gt; 20/4);\n\n定期删除的流程如下：\n# Redis的缓存失效会不会立即删除？不会，Redis 的过期删除策略是选择「惰性删除+定期删除」这两种策略配和使用。\n\n惰性删除策略的做法是，不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。\n定期删除策略的做法是，每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。\n\n# 那为什么我不过期立即删除？在过期 key 比较多的情况下，删除过期 key 可能会占用相当一部分 CPU 时间，在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。\n# 集群# Redis主从同步中的增量和完全同步怎么实现？\n\n\n\n\n\n\n\n\n完全同步\n完全同步发生在以下几种情况：\n\n初次同步：当一个从服务器（slave）首次连接到主服务器（master）时，会进行一次完全同步。\n从服务器数据丢失：如果从服务器数据由于某种原因（如断电）丢失，它会请求进行完全同步。\n主服务器数据发生变化：如果从服务器长时间未与主服务器同步，导致数据差异太大，也可能触发完全同步。\n\n主从服务器间的第一次同步的过程可分为三个阶段：\n\n第一阶段是建立链接、协商同步；\n第二阶段是主服务器同步数据给从服务器；\n第三阶段是主服务器发送新写操作命令给从服务器。\n\n\n实现过程：\n\n从服务器发送SYNC命令：从服务器向主服务器发送SYNC命令，请求开始同步。\n主服务器生成RDB快照：接收到SYNC命令后，主服务器会保存当前数据集的状态到一个临时文件，这个过程称为RDB（Redis Database）快照。\n传输RDB文件：主服务器将生成的RDB文件发送给从服务器。\n从服务器接收并应用RDB文件：从服务器接收RDB文件后，会清空当前的数据集，并载入RDB文件中的数据。\n主服务器记录写命令：在RDB文件生成和传输期间，主服务器会记录所有接收到的写命令到replication backlog buffer。\n传输写命令：一旦RDB文件传输完成，主服务器会将replication backlog buffer中的命令发送给从服务器，从服务器会执行这些命令，以保证数据的一致性。\n\n\n\n\n\n\n\n\n\n\n增量同步\n增量同步允许从服务器从断点处继续同步，而不是每次都进行完全同步。它基于PSYNC命令，使用了运行ID（run ID）和复制偏移量（offset）的概念。\n\n主要有三个步骤：\n\n从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；\n主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；\n然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。\n\n那么关键的问题来了，主服务器怎么知道要将哪些增量数据发送给从服务器呢？\n答案藏在这两个东西里：\n\nrepl_backlog_buffer，是一个「环形」缓冲区，用于主从服务器断连后，从中找到差异的数据；\nreplication offset，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master_repl_offset 来记录自己「写」到的位置，从服务器使用 slave_repl_offset 来记录自己「读」到的位置。\n\n那 repl_backlog_buffer 缓冲区是什么时候写入的呢？\n在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。\n网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：\n\n如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用增量同步的方式；\n相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用全量同步的方式。\n\n当主服务器在 repl_backlog_buffer 中找到主从服务器差异（增量）的数据后，就会将增量的数据写入到 replication buffer 缓冲区，这个缓冲区我们前面也提到过，它是缓存将要传播给从服务器的命令。\n\nrepl_backlog_buffer 缓行缓冲区的默认大小是 1M，并且由于它是一个环形缓冲区，所以当缓冲区写满后，主服务器继续写入的话，就会覆盖之前的数据。因此，当主服务器的写入速度远超于从服务器的读取速度，缓冲区的数据一下就会被覆盖。\n那么在网络恢复时，如果从服务器想读的数据已经被覆盖了，主服务器就会采用全量同步，这个方式比增量同步的性能损耗要大很多。\n因此，为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该调整下 repl_backlog_buffer 缓冲区大小，尽可能的大一些，减少出现从服务器要读取的数据被覆盖的概率，从而使得主服务器采用增量同步的方式。\n# redis主从和集群可以保证数据一致性吗 ？redis 主从和集群在CAP理论都属于AP模型，即在面临网络分区时选择保证可用性和分区容忍性，而牺牲了强一致性。这意味着在网络分区的情况下，Redis主从复制和集群可以继续提供服务并保持可用，但可能会出现部分节点之间的数据不一致。\n# 哨兵机制原理是什么？在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。\n\n这时如果要恢复服务的话，需要人工介入，选择一个「从节点」切换为「主节点」，然后让其他从节点指向新的主节点，同时还需要通知上游那些连接 Redis 主节点的客户端，将其配置中的主节点 IP 地址更新为「新主节点」的 IP 地址。\n这样也不太“智能”了，要是有一个节点能监控「主节点」的状态，当发现主节点挂了，它自动将一个「从节点」切换为「主节点」的话，那么可以节省我们很多事情啊！\nRedis 在 2.8 版本以后提供的哨兵（Sentinel）机制，它的作用是实现主从节点故障转移。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。\n哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。从“哨兵”这个名字也可以看得出来，它相当于是“观察者节点”，观察的对象是主从节点。\n当然，它不仅仅是观察那么简单，在它观察到有异常的状况下，会做出一些“动作”，来修复异常状态。\n哨兵节点主要负责三件事情：监控、选主、通知。\n\n# 哨兵机制的选主节点的算法介绍一下当redis集群的主节点故障时，Sentinel集群将从剩余的从节点中选举一个新的主节点，有以下步骤：\n\n故障节点主观下线\n故障节点客观下线\nSentinel集群选举Leader\nSentinel Leader决定新主节点\n\n\n\n\n\n\n\n\n\n\n\n故障节点主观下线\n\nSentinel集群的每一个Sentinel节点会定时对redis集群的所有节点发心跳包检测节点是否正常。如果一个节点在down-after-milliseconds时间内没有回复Sentinel节点的心跳包，则该redis节点被该Sentinel节点主观下线。\n\n\n\n\n\n\n\n\n\n\n\n故障节点客观下线\n\n当节点被一个Sentinel节点记为主观下线时，并不意味着该节点肯定故障了，还需要Sentinel集群的其他Sentinel节点共同判断为主观下线才行。\n该Sentinel节点会询问其他Sentinel节点，如果Sentinel集群中超过quorum数量的Sentinel节点认为该redis节点主观下线，则该redis客观下线。\n\n如果客观下线的redis节点是从节点或者是Sentinel节点，则操作到此为止，没有后续的操作了；如果客观下线的redis节点为主节点，则开始故障转移，从从节点中选举一个节点升级为主节点。\n\n\n\n\n\n\n\n\n\n\nSentinel集群选举Leader\n\n如果需要从redis集群选举一个节点为主节点，首先需要从Sentinel集群中选举一个Sentinel节点作为Leader。\n\n每一个Sentinel节点都可以成为Leader，当一个Sentinel节点确认redis集群的主节点主观下线后，会请求其他Sentinel节点要求将自己选举为Leader。被请求的Sentinel节点如果没有同意过其他Sentinel节点的选举请求，则同意该请求(选举票数+1)，否则不同意。\n如果一个Sentinel节点获得的选举票数达到Leader最低票数(quorum和Sentinel节点数&#x2F;2+1的最大值)，则该Sentinel节点选举为Leader；否则重新进行选举。\n\n举个例子，假设哨兵节点有 3 个，quorum 设置为 2，那么任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以选举成功了。如果没有满足条件，就需要重新进行选举。\n\n\n\n\n\n\n\n\n\n\nSentinel Leader决定新主节点\n\n当Sentinel集群选举出Sentinel Leader后，由Sentinel Leader从redis从节点中选择一个redis节点作为主节点：\n\n过滤故障的节点\n选择优先级slave-priority最大的从节点作为主节点，如不存在则继续\n选择复制偏移量（数据写入量的字节，记录写了多少数据。主服务器会把偏移量同步给从服务器，当主从的偏移量一致，则数据是完全同步）最大的从节点作为主节点，如不存在则继续\n选择runid（redis每次启动的时候生成随机的runid作为redis的标识）最小的从节点作为主节点\n\n\n# Redis集群的模式了解吗 优缺点了解吗当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 Redis 切片集群（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。\nRedis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：\n\n根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值。\n再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。\n\n接下来的问题就是，这些哈希槽怎么被映射到具体的 Redis 节点上的呢？有两种方案：\n\n平均分配： 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384&#x2F;9 个。\n手动分配： 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。\n\n为了方便你的理解，我通过一张图来解释数据、哈希槽，以及节点三者的映射分布关系。\n\n上图中的切片集群一共有 2 个节点，假设有 4 个哈希槽（Slot 0～Slot 3）时，我们就可以通过命令手动分配哈希槽，比如节点 1 保存哈希槽 0 和 1，节点 2 保存哈希槽 2 和 3。\n12redis-cli -h 192.168.1.10 –p 6379 cluster addslots 0,1redis-cli -h 192.168.1.11 –p 6379 cluster addslots 2,3\n\n然后在集群运行的过程中，key1 和 key2 计算完 CRC16 值后，对哈希槽总个数 4 进行取模，再根据各自的模数结果，就可以被映射到哈希槽 1（对应节点1） 和 哈希槽 2（对应节点2）。\n需要注意的是，在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。\n\n\n\n\n\n\n\n\n\nRedis集群模式优点&#x2F;缺点\n优点：\n\n高可用性：Redis集群最主要的优点是提供了高可用性，节点之间采用主从复制机制，可以保证数据的持久性和容错能力，哪怕其中一个节点挂掉，整个集群还可以继续工作。\n**高性能：**Redis集群采用分片技术，将数据分散到多个节点，从而提高读写性能。当业务访问量大到单机Redis无法满足时，可以通过添加节点来增加集群的吞吐量。\n**扩展性好：**Redis集群的扩展性非常好，可以根据实际需求动态增加或减少节点，从而实现可扩展性。集群模式中的某些节点还可以作为代理节点，自动转发请求，增加数据模式的灵活度和可定制性。\n\n缺点：\n\n**部署和维护较复杂：**Redis集群的部署和维护需要考虑到分片规则、节点的布置、主从配置以及故障处理等多个方面，需要较强的技术支持，增加了节点异常处理的复杂性和成本。\n**集群同步问题：**当某些节点失败或者网络出故障，集群中数据同步的问题也会出现。数据同步的复杂度和工作量随着节点的增加而增加，同步时间也较长，导致一定的读写延迟。\n**数据分片限制：**Redis集群的数据分片也限制了一些功能的实现，如在一个key上修改多次，可能会因为该key所在的节点位置变化而失败。此外，由于将数据分散存储到各个节点，某些操作不能跨节点实现，不同节点之间的一些操作需要额外注意。\n\n# 场景# 为什么使用redis？主要是因为 Redis 具备「高性能」和「高并发」两种特性。\n\n\n\n\n\n\n\n\n\n1、Redis 具备高性能\n假如用户第一次访问 MySQL 中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据缓存在 Redis 中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，操作 Redis 缓存就是直接操作内存，所以速度相当快。\n\n如果 MySQL 中的对应数据改变的之后，同步改变 Redis 缓存中相应的数据即可，不过这里会有 Redis 和 MySQL 双写一致性的问题。\n\n\n\n\n\n\n\n\n\n2、 Redis 具备高并发\n单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。\n所以，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。\n# 为什么redis比mysql要快？\n内存存储：Redis 是基于内存存储的 NoSQL 数据库，而 MySQL 是基于磁盘存储的关系型数据库。由于内存存储速度快，Redis 能够更快地读取和写入数据，而无需像 MySQL 那样频繁进行磁盘 I&#x2F;O 操作。\n简单数据结构：Redis 是基于键值对存储数据的，支持简单的数据结构（字符串、哈希、列表、集合、有序集合）。相比之下，MySQL 需要定义表结构、索引等复杂的关系型数据结构，因此在某些场景下 Redis 的数据操作更为简单高效，比如 Redis 用哈希表查询， 只需要O1 时间复杂度，而MySQL引擎的底层实现是B+Tree，时间复杂度是O(logn)\n线程模型：Redis 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。\n\n# 本地缓存和Redis缓存的区别?本地缓存是指将数据存储在本地应用程序或服务器上，通常用于加速数据访问和提高响应速度。本地缓存通常使用内存作为存储介质，利用内存的高速读写特性来提高数据访问速度。\n本地缓存的优势：\n\n访问速度快：由于本地缓存存储在本地内存中，因此访问速度非常快，能够满足频繁访问和即时响应的需求。\n减轻网络压力：本地缓存能够降低对远程服务器的访问次数，从而减轻网络压力，提高系统的可用性和稳定性。\n低延迟：由于本地缓存位于本地设备上，因此能够提供低延迟的访问速度，适用于对实时性要求较高的应用场景。\n\n本地缓存的不足：\n\n可扩展性有限：本地缓存的可扩展性受到硬件资源的限制，无法支持大规模的数据存储和访问。\n\n**分布式缓存（Redis）**是指将数据存储在多个分布式节点上，通过协同工作来提供高性能的数据访问服务。分布式缓存通常使用集群方式进行部署，利用多台服务器来分担数据存储和访问的压力。\n分布式缓存的优势：\n\n可扩展性强：分布式缓存的节点可以动态扩展，能够支持大规模的数据存储和访问需求。\n数据一致性高：通过分布式一致性协议，分布式缓存能够保证数据在多个节点之间的一致性，减少数据不一致的问题。\n易于维护：分布式缓存通常采用自动化管理方式，能够降低维护成本和管理的复杂性。\n\n分布式缓存的不足：\n\n访问速度相对较慢：相对于本地缓存，分布式缓存的访问速度相对较慢，因为数据需要从多个节点进行访问和协同。\n网络开销大：由于分布式缓存需要通过网络进行数据传输和协同操作，因此相对于本地缓存来说，网络开销较大。\n\n在选择使用本地缓存还是分布式缓存时，我们需要根据具体的应用场景和需求进行权衡。以下是一些考虑因素：\n\n数据大小：如果数据量较小，且对实时性要求较高，本地缓存更适合；如果数据量较大，且需要支持大规模的并发访问，分布式缓存更具优势。\n网络状况：如果网络状况良好且稳定，分布式缓存能够更好地发挥其优势；如果网络状况较差或不稳定，本地缓存的访问速度和稳定性可能更有优势。\n业务特点：对于实时性要求较\n\n# 高并发场景，Redis单节点+MySQL单节点能有多大的并发量？\n如果缓存命中的话，4 核心 8g 内存的配置，redis 可以支撑 10w 的 qps\n如果缓存没有命中的话，4 核心 8g 内存的配置，mysql 只能支持 5000 左右的 qps\n\n# redis应用场景是什么？Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此读写速度非常快，常用于缓存，消息队列、分布式锁等场景。\n\n缓存: Redis最常见的用途就是作为缓存系统。通过将热门数据存储在内存中，可以极大地提高访问速度，减轻数据库负载，这对于需要快速响应时间的应用程序非常重要。\n排行榜: Redis的有序集合结构非常适合用于实现排行榜和排名系统，可以方便地进行数据排序和排名。\n分布式锁: Redis的特性可以用来实现分布式锁，确保多个进程或服务之间的数据操作的原子性和一致性。\n计数器 由于Redis的原子操作和高性能，它非常适合用于实现计数器和统计数据的存储，如网站访问量统计、点赞数统计等。\n消息队列: Redis的发布订阅功能使其成为一个轻量级的消息队列，它可以用来实现发布和订阅模式，以便实时处理消息。\n\n# Redis除了缓存，还有哪些应用?Redis实现消息队列\n\n**使用Pub&#x2F;Sub模式：**Redis的Pub&#x2F;Sub是一种基于发布&#x2F;订阅的消息模式，任何客户端都可以订阅一个或多个频道，发布者可以向特定频道发送消息，所有订阅该频道的客户端都会收到此消息。该方式实现起来比较简单，发布者和订阅者完全解耦，支持模式匹配订阅。但是这种方式不支持消息持久化，消息发布后若无订阅者在线则会被丢弃；不保证消息的顺序和可靠性传输。\n使用List结构：使用List的方式通常是使用LPUSH命令将消息推入一个列表，消费者使用BLPOP或BRPOP阻塞地从列表中取出消息（先进先出FIFO）。这种方式可以实现简单的任务队列。这种方式可以结合Redis的过期时间特性实现消息的TTL；通过Redis事务可以保证操作的原子性。但是需要客户端自己实现消息确认、重试等机制，相比专门的消息队列系统功能较弱。\n\nRedis实现分布式锁\n\nset nx方式：Redis提供了几种方式来实现分布式锁，最常用的是基于SET命令的争抢锁机制。客户端可以使用SET resource_name lock_value NX PX milliseconds命令设置锁，其中NX表示只有当键不存在时才设置，PX指定锁的有效时间（毫秒）。如果设置成功，则认为客户端获得锁。客户端完成操作后，解锁的还需要先判断锁是不是自己，再进行删除，这里涉及到 2 个操作，为了保证这两个操作的原子性，可以用 lua 脚本来实现。\n**RedLock算法：**为了提高分布式锁的可靠性，Redis作者Antirez提出了RedLock算法，它基于多个独立的Redis实例来实现一个更安全的分布式锁。它的基本原理是客户端尝试在多数（大于半数）Redis实例上同时加锁，只有当在大多数实例上加锁成功时才认为获取锁成功。锁的超时时间应该远小于单个实例的超时时间，以避免死锁。该方式可以通过跨多个节点减少单点故障的影响，提高了锁的可用性和安全性。\n\n# Redis支持并发操作吗？\n单个 Redis 命令的原子性：Redis 的单个命令是原子性的，这意味着一个命令要么完全执行成功，要么完全不执行，确保操作的一致性。这对于并发操作非常重要。\n多个操作的事务：Redis 支持事务，可以将一系列的操作放在一个事务中执行，使用 MULTI、EXEC、DISCARD 和 WATCH 等命令来管理事务。这样可以确保一系列操作的原子性。\n\n# Redis分布式锁的实现原理？什么场景下用到分布式锁？分布式锁是用于分布式环境下并发控制的一种机制，用于控制某个资源在同一时刻只能被一个应用所使用。如下图所示：Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：\n\n如果 key 不存在，则显示插入成功，可以用来表示加锁成功；\n如果 key 存在，则会显示插入失败，可以用来表示加锁失败。\n\n基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。\n\n加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；\n锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX&#x2F;PX 选项，设置其过期时间；\n锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；\n\n满足这三个条件的分布式命令如下：\n1SET lock_key unique_value NX PX 10000\n\n\nlock_key 就是 key 键；\nunique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；\nNX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；\nPX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。\n\n而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。\n可以看到，解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。\n123456// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then  return redis.call(&quot;del&quot;,KEYS[1])else  return 0end\n\n这样一来，就通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。\n# Redis的大Key问题是什么？Redis大key问题指的是某个key对应的value值所占的内存空间比较大，导致Redis的性能下降、内存不足、数据不均衡以及主从同步延迟等问题。\n到底多大的数据量才算是大key？\n没有固定的判别标准，通常认为字符串类型的key对应的value值占用空间大于1M，或者集合类型的k元素数量超过1万个，就算是大key。\nRedis大key问题的定义及评判准则并非一成不变，而应根据Redis的实际运用以及业务需求来综合评估。\n例如，在高并发且低延迟的场景中，仅10kb可能就已构成大key；然而在低并发、高容量的环境下，大key的界限可能在100kb。因此，在设计与运用Redis时，要依据业务需求与性能指标来确立合理的大key阈值。\n# 大Key问题的缺点？\n内存占用过高。大Key占用过多的内存空间，可能导致可用内存不足，从而触发内存淘汰策略。在极端情况下，可能导致内存耗尽，Redis实例崩溃，影响系统的稳定性。\n性能下降。大Key会占用大量内存空间，导致内存碎片增加，进而影响Redis的性能。对于大Key的操作，如读取、写入、删除等，都会消耗更多的CPU时间和内存资源，进一步降低系统性能。\n阻塞其他操作。某些对大Key的操作可能会导致Redis实例阻塞。例如，使用DEL命令删除一个大Key时，可能会导致Redis实例在一段时间内无法响应其他客户端请求，从而影响系统的响应时间和吞吐量。\n网络拥塞。每次获取大key产生的网络流量较大，可能造成机器或局域网的带宽被打满，同时波及其他服务。例如：一个大key占用空间是1MB，每秒访问1000次，就有1000MB的流量。\n主从同步延迟。当Redis实例配置了主从同步时，大Key可能导致主从同步延迟。由于大Key占用较多内存，同步过程中需要传输大量数据，这会导致主从之间的网络传输延迟增加，进而影响数据一致性。\n数据倾斜。在Redis集群模式中，某个数据分片的内存使用率远超其他数据分片，无法使数据分片的内存资源达到均衡。另外也可能造成Redis内存达到maxmemory参数定义的上限导致重要的key被逐出，甚至引发内存溢出。\n\n# Redis大key如何解决？\n对大Key进行拆分。例如将含有数万成员的一个HASH Key拆分为多个HASH Key，并确保每个Key的成员数量在合理范围。在Redis集群架构中，拆分大Key能对数据分片间的内存平衡起到显著作用。\n对大Key进行清理。将不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。注意，要使用异步删除。\n监控Redis的内存水位。可以通过监控系统设置合理的Redis内存报警阈值进行提醒，例如Redis内存使用率超过70%、Redis的内存在1小时内增长率超过20%等。\n对过期数据进行定期清。堆积大量过期数据会造成大Key的产生，例如在HASH数据类型中以增量的形式不断写入大量数据而忽略了数据的时效性。可以通过定时任务的方式对失效数据进行清理。\n\n# 什么是热key？通常以其接收到的Key被请求频率来判定，例如：\n\nQPS集中在特定的Key：Redis实例的总QPS（每秒查询率）为10,000，而其中一个Key的每秒访问量达到了7,000。\n带宽使用率集中在特定的Key：对一个拥有上千个成员且总大小为1 MB的HASH Key每秒发送大量的HGETALL操作请求。\nCPU使用时间占比集中在特定的Key：对一个拥有数万个成员的Key（ZSET类型）每秒发送大量的ZRANGE操作请求。\n\n# 如何解决热key问题？\n在Redis集群架构中对热Key进行复制。在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。此时，可以将对应热Key进行复制并迁移至其他数据分片，例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力。\n使用读写分离架构。如果热Key的产生来自于读请求，您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力，甚至可以不断地增加从节点。但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。不仅要为多个从节点提供转发层（如Proxy，LVS等）来实现负载均衡，还要考虑从节点数量显著增加后带来故障率增加的问题。Redis集群架构变更会为监控、运维、故障处理带来了更大的挑战。\n\n# 如何保证 redis 和 mysql 数据缓存一致性问题？对于读数据，我会选择旁路缓存策略，如果 cache 不命中，会从 db 加载数据到 cache。对于写数据，我会选择更新 db 后，再删除缓存。\n\n缓存是通过牺牲强一致性来提高性能的。这是由CAP理论决定的。缓存系统适用的场景就是非强一致性的场景，它属于CAP中的AP。所以，如果需要数据库和缓存数据保持强一致，就不适合使用缓存。\n所以使用缓存提升性能，就是会有数据更新的延迟。这需要我们在设计时结合业务仔细思考是否适合用缓存。然后缓存一定要设置过期时间，这个时间太短、或者太长都不好：\n\n太短的话请求可能会比较多的落到数据库上，这也意味着失去了缓存的优势。\n太长的话缓存中的脏数据会使系统长时间处于一个延迟的状态，而且系统中长时间没有人访问的数据一直存在内存中不过期，浪费内存。\n\n但是，通过一些方案优化处理，是可以最终一致性的。\n针对删除缓存异常的情况，可以使用 2 个方案避免：\n\n删除缓存重试策略（消息队列）\n订阅 binlog，再删除缓存（Canal+消息队列）\n\n\n\n\n\n\n\n\n\n\n消息队列方案\n我们可以引入消息队列，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。\n\n如果应用删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。\n如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。\n\n举个例子，来说明重试机制的过程。\n\n重试删除缓存机制还可以，就是会造成好多业务代码入侵。\n\n\n\n\n\n\n\n\n\n订阅 MySQL binlog，再操作缓存\n「先更新数据库，再删缓存」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。\n于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。\nCanal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。\n下图是 Canal 的工作原理：\n\n将binlog日志采集发送到MQ队列里面，然后编写一个简单的缓存删除消息者订阅binlog日志，根据更新log删除缓存，并且通过ACK机制确认处理这条更新log，保证数据缓存一致性\n# 缓存雪崩、击穿、穿透是什么？怎么解决？\n缓存雪崩：当大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩的问题。\n\n\n\n缓存击穿：如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是缓存击穿的问题。\n\n\n\n缓存穿透：当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。\n\n\n缓存雪崩解决方案：\n\n均匀设置过期时间：如果要给缓存数据设置过期时间，应该避免将大量的数据设置成同一个过期时间。我们可以在对缓存数据设置过期时间时，给这些数据的过期时间加上一个随机数，这样就保证数据不会在同一时间过期。\n互斥锁：当业务线程在处理用户请求时，如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存（从数据库读取数据，再将数据更新到 Redis 里），当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。实现互斥锁的时候，最好设置超时时间，不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。\n后台更新缓存：业务线程不再负责更新缓存，缓存也不设置有效期，而是让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新。\n\n缓存击穿解决方案：\n\n互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。\n不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；\n\n缓存穿透解决方案：\n\n非法请求的限制：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。\n缓存空值或者默认值：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。\n布隆过滤器：我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在。即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。\n\n# 布隆过滤器原理介绍一下布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。\n布隆过滤器会通过 3 个操作完成标记：\n\n第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；\n第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。\n第三步，将每个哈希值在位图数组的对应位置的值设置为 1；\n\n举个例子，假设有一个位图数组长度为 8，哈希函数 3 个的布隆过滤器。\n\n在数据库写入数据 x 后，把数据 x 标记在布隆过滤器时，数据 x 会被 3 个哈希函数分别计算出 3 个哈希值，然后在对这 3 个哈希值对 8 取模，假设取模的结果为 1、4、6，然后把位图数组的第 1、4、6 位置的值设置为 1。当应用要查询数据 x 是否数据库时，通过布隆过滤器只要查到位图数组的第 1、4、6 位置的值是否全为 1，只要有一个为 0，就认为数据 x 不在数据库中。\n布隆过滤器由于是基于哈希函数实现查找的，高效查找的同时存在哈希冲突的可能性，比如数据 x 和数据 y 可能都落在第 1、4、6 位置，而事实上，可能数据库中并不存在数据 y，存在误判的情况。\n所以，查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据。\n# 如何设计秒杀场景处理高并发以及超卖现象？\n\n\n\n\n\n\n\n\n在数据库层面解决\n\n在查询商品库存时加排他锁，执行如下语句：\n\n1select * from goods for where goods_id=?  for update\n\n在事务中线程A通过select * from goods for where goods_id&#x3D;#{id} for update语句给goods_id为#{id}的数据行上了锁。那么其他线程此时可以使用select语句读取数据，但是如果也使用select for update语句加锁，或者使用update，delete都会阻塞，直到线程A将事务提交（或者回滚），其他线程中的某个线程排在线程A后的线程才能获取到锁。\n\n更新数据库减库存的时候，进行库存限制条件\n\n1update goods set stock = stock - 1 where goods_id = ？ and stock &gt;0\n\n这种通过数据库加锁来解决的方案，性能不是很好，在高并发的情况下，还可能存在因为获取不到数据库连接或者因为超时等待而报错。\n\n\n\n\n\n\n\n\n\n利用分布式锁\n同一个锁key，同一时间只能有一个客户端拿到锁，其他客户端会陷入无限的等待来尝试获取那个锁，只有获取到锁的客户端才能执行下面的业务逻辑。\n这种方案的缺点是同一个商品在多用户同时下单的情况下，会基于分布式锁串行化处理，导致没法同时处理同一个商品的大量下单的请求。\n\n\n\n\n\n\n\n\n\n利用分布式锁+分段缓存\n把数据分成很多个段，每个段是一个单独的锁，所以多个线程过来并发修改数据的时候，可以并发的修改不同段的数据\n假设场景：假如你现在商品有100个库存，在redis存放5个库存key，形如:\n123key1=goods-01,value=20;key2=goods-02,value=20;key3=goods-03，value=20\n\n用户下单时对用户id进行%5计算，看落在哪个redis的key上，就去取哪个，这样每次就能够处理5个进程请求\n这种方案可以解决同一个商品在多用户同时下单的情况，但有个坑需要解决：当某段锁的库存不足，一定要实现自动释放锁然后换下一个分段库存再次尝试加锁处理，此种方案复杂比较高。\n\n\n\n\n\n\n\n\n\n利用redis的incr、decr的原子性 + 异步队列\n实现思路\n\n1、在系统初始化时，将商品的库存数量加载到redis缓存中\n2、接收到秒杀请求时，在redis中进行预减库存（利用redis decr的原子性），当redis中的库存不足时，直接返回秒杀失败，否则继续进行第3步；\n3、将请求放入异步队列中，返回正在排队中；\n4、服务端异步队列将请求出队（哪些请求可以出队，可以根据业务来判定，比如：判断对应用户是否已经秒杀过对应商品，防止重复秒杀），出队成功的请求可以生成秒杀订单，减少数据库库存（在扣减库存的sql如下，返回秒杀订单详情）\n\n1update goods set stock = stock - 1 where goods_id = ? and stock &gt;0\n\n\n5、用户在客户端申请秒杀请求后，进行轮询，查看是否秒杀成功，秒杀成功则进入秒杀订单详情，否则秒杀失败\n\n这种方案的缺点：由于是通过异步队列写入数据库中，可能存在数据不一致，其次引用多个组件复杂度比较高\n\n","slug":"框架/Redis面试题","date":"2024-12-03T18:27:11.000Z","categories_index":"八股","tags_index":"精选,Redis","author_index":"Ivan"},{"id":"723f0bc187c0d9e9f528c9cd6627a1c3","title":"mysql","content":"# MySQL# SQL基础# NOSQL和SQL的区别？SQL数据库，指关系型数据库 - 主要代表：SQL Server，Oracle，MySQL(开源)，PostgreSQL(开源)。\n关系型数据库存储结构化数据。这些数据逻辑上以行列二维表的形式存在，每一列代表数据的一种属性，每一行代表一个数据实体。\n\nNoSQL指非关系型数据库 ，主要代表：MongoDB，Redis。NoSQL 数据库逻辑上提供了不同于二维表的存储方式，存储方式可以是JSON文档、哈希表或者其他方式。\n\n选择 SQL vs NoSQL，考虑以下因素。\n\n\n\n\n\n\n\n\n\nACID vs BASE\n关系型数据库支持 ACID 即原子性，一致性，隔离性和持续性。相对而言，NoSQL 采用更宽松的模型 BASE ， 即基本可用，软状态和最终一致性。\n从实用的角度出发，我们需要考虑对于面对的应用场景，ACID 是否是必须的。比如银行应用就必须保证 ACID，否则一笔钱可能被使用两次；又比如社交软件不必保证 ACID，因为一条状态的更新对于所有用户读取先后时间有数秒不同并不影响使用。\n对于需要保证 ACID 的应用，我们可以优先考虑 SQL。反之则可以优先考虑 NoSQL。\n\n\n\n\n\n\n\n\n\n扩展性对比\nNoSQL数据之间无关系，这样就非常容易扩展，也无形之间，在架构的层面上带来了可扩展的能力。比如 redis 自带主从复制模式、哨兵模式、切片集群模式。\n相反关系型数据库的数据之间存在关联性，水平扩展较难 ，需要解决跨服务器 JOIN，分布式事务等问题。\n# 数据库三大范式是什么？第一范式（1NF）：要求数据库表的每一列都是不可分割的原子数据项。\n举例说明：\n\n在上面的表中，“家庭信息”和“学校信息”列均不满足原子性的要求，故不满足第一范式，调整如下：\n\n可见，调整后的每一列都是不可再分的，因此满足第一范式（1NF）；\n第二范式（2NF）：在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖）\n第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。\n举例说明：\n\n在上图所示的情况中，同一个订单中可能包含不同的产品，因此主键必须是“订单号”和“产品号”联合组成，\n但可以发现，产品数量、产品折扣、产品价格与“订单号”和“产品号”都相关，但是订单金额和订单时间仅与“订单号”相关，与“产品号”无关，\n这样就不满足第二范式的要求，调整如下，需分成两个表：\n\n\n第三范式（3NF）：在2NF基础上，任何非主属性 (opens new window)不依赖于其它非主属性（在2NF基础上消除传递依赖）\n第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。\n举例说明：\n\n上表中，所有属性都完全依赖于学号，所以满足第二范式，但是“班主任性别”和“班主任年龄”直接依赖的是“班主任姓名”，\n而不是主键“学号”，所以需做如下调整：\n\n\n这样以来，就满足了第三范式的要求。\n# MySQL 怎么连表查询？数据库有以下几种联表查询类型：\n\n内连接 (INNER JOIN)\n左外连接 (LEFT JOIN)\n右外连接 (RIGHT JOIN)\n全外连接 (FULL JOIN)\n\n\n1. 内连接 (INNER JOIN)\n内连接返回两个表中有匹配关系的行。示例:\n1234SELECT employees.name, departments.nameFROM employeesINNER JOIN departmentsON employees.department_id = departments.id;\n\n这个查询返回每个员工及其所在的部门名称。\n2. 左外连接 (LEFT JOIN)\n左外连接返回左表中的所有行，即使在右表中没有匹配的行。未匹配的右表列会包含NULL。示例:\n1234SELECT employees.name, departments.nameFROM employeesLEFT JOIN departmentsON employees.department_id = departments.id;\n\n这个查询返回所有员工及其部门名称，包括那些没有分配部门的员工。\n3. 右外连接 (RIGHT JOIN)\n右外连接返回右表中的所有行，即使左表中没有匹配的行。未匹配的左表列会包含NULL。示例:\n1234SELECT employees.name, departments.nameFROM employeesRIGHT JOIN departmentsON employees.department_id = departments.id;\n\n这个查询返回所有部门及其员工，包括那些没有分配员工的部门。\n4. 全外连接 (FULL JOIN)\n全外连接返回两个表中所有行，包括非匹配行，在MySQL中，FULL JOIN 需要使用 UNION 来实现，因为 MySQL 不直接支持 FULL JOIN。示例:\n1234567891011SELECT employees.name, departments.nameFROM employeesLEFT JOIN departmentsON employees.department_id = departments.idUNIONSELECT employees.name, departments.nameFROM employeesRIGHT JOIN departmentsON employees.department_id = departments.id;\n\n这个查询返回所有员工和所有部门，包括没有匹配行的记录。\n# MySQL如何避免重复插入数据？方式一：使用UNIQUE约束\n在表的相关列上添加UNIQUE约束，确保每个值在该列中唯一。例如：\n12345CREATE TABLE users (    id INT PRIMARY KEY AUTO_INCREMENT,    email VARCHAR(255) UNIQUE,    name VARCHAR(255));\n\n如果尝试插入重复的email，MySQL会返回错误。\n方式二：使用INSERT … ON DUPLICATE KEY UPDATE\n这种语句允许在插入记录时处理重复键的情况。如果插入的记录与现有记录冲突，可以选择更新现有记录：\n123INSERT INTO users (email, name) VALUES (&#x27;example@example.com&#x27;, &#x27;John Doe&#x27;)ON DUPLICATE KEY UPDATE name = VALUES(name);\n\n方式三：使用INSERT IGNORE： 该语句会在插入记录时忽略那些因重复键而导致的插入错误。例如：\n12INSERT IGNORE INTO users (email, name) VALUES (&#x27;example@example.com&#x27;, &#x27;John Doe&#x27;);\n\n如果email已经存在，这条插入语句将被忽略而不会返回错误。\n选择哪种方法取决于具体的需求：\n\n如果需要保证全局唯一性，使用UNIQUE约束是最佳做法。\n如果需要插入和更新结合可以使用ON DUPLICATE KEY UPDATE。\n对于快速忽略重复插入，INSERT IGNORE是合适的选择。\n\n# CHAR 和 VARCHAR有什么区别？\nCHAR是固定长度的字符串类型，定义时需要指定固定长度，存储时会在末尾补足空格。CHAR适合存储长度固定的数据，如固定长度的代码、状态等，存储空间固定，对于短字符串效率较高。\nVARCHAR是可变长度的字符串类型，定义时需要指定最大长度，实际存储时根据实际长度占用存储空间。VARCHAR适合存储长度可变的数据，如用户输入的文本、备注等，节约存储空间。\n\n# Text数据类型可以无限大吗？MySQL 3 种text类型的最大长度如下：\n\nTEXT：65,535 bytes ~64kb\nMEDIUMTEXT：16,777,215 bytes ~16Mb\nLONGTEXT：4,294,967,295 bytes ~4Gb\n\n# 说一下外键约束外键约束的作用是维护表与表之间的关系，确保数据的完整性和一致性。让我们举一个简单的例子：\n假设你有两个表，一个是学生表，另一个是课程表，这两个表之间有一个关系，即一个学生可以选修多门课程，而一门课程也可以被多个学生选修。在这种情况下，我们可以在学生表中定义一个指向课程表的外键，如下所示：\n123456CREATE TABLE students (  id INT PRIMARY KEY,  name VARCHAR(50),  course_id INT,  FOREIGN KEY (course_id) REFERENCES courses(id));\n\n这里，students表中的course_id字段是一个外键，它指向courses表中的id字段。这个外键约束确保了每个学生所选的课程在courses表中都存在，从而维护了数据的完整性和一致性。\n如果没有定义外键约束，那么就有可能出现学生选了不存在的课程或者删除了一个课程而忘记从学生表中删除选修该课程的学生的情况，这会破坏数据的完整性和一致性。因此，使用外键约束可以帮助我们避免这些问题。\n# MySQL的关键字in和exist在MySQL中，IN 和 EXISTS 都是用来处理子查询的关键词，但它们在功能、性能和使用场景上有各自的特点和区别。\n\n\n\n\n\n\n\n\n\nIN关键字\nIN 用于检查左边的表达式是否存在于右边的列表或子查询的结果集中。如果存在，则IN 返回TRUE，否则返回FALSE。\n语法结构：\n123SELECT column_name(s)FROM table_nameWHERE column_name IN (value1, value2, ...);\n\n或\n123SELECT column_name(s)FROM table_nameWHERE column_name IN (SELECT column_name FROM another_table WHERE condition);\n\n例子：\n12SELECT * FROM CustomersWHERE Country IN (&#x27;Germany&#x27;, &#x27;France&#x27;);\n\n\n\n\n\n\n\n\n\n\nEXISTS关键字\nEXISTS 用于判断子查询是否至少能返回一行数据。它不关心子查询返回什么数据，只关心是否有结果。如果子查询有结果，则EXISTS 返回TRUE，否则返回FALSE。\n语法结构：\n123SELECT column_name(s)FROM table_nameWHERE EXISTS (SELECT column_name FROM another_table WHERE condition);\n\n例子：\n12SELECT * FROM CustomersWHERE EXISTS (SELECT 1 FROM Orders WHERE Orders.CustomerID = Customers.CustomerID);\n\n区别与选择：\n\n性能差异：在很多情况下，EXISTS 的性能优于 IN，特别是当子查询的表很大时。这是因为EXISTS 一旦找到匹配项就会立即停止查询，而IN可能会扫描整个子查询结果集。\n使用场景：如果子查询结果集较小且不频繁变动，IN 可能更直观易懂。而当子查询涉及外部查询的每一行判断，并且子查询的效率较高时，EXISTS 更为合适。\nNULL值处理：IN 能够正确处理子查询中包含NULL值的情况，而EXISTS 不受子查询结果中NULL值的影响，因为它关注的是行的存在性，而不是具体值。\n\n# mysql中的一些基本函数，你知道哪些？\n\n\n\n\n\n\n\n\n一、字符串函数\n**CONCAT(str1, str2, …)**：连接多个字符串，返回一个合并后的字符串。\n1SELECT CONCAT(&#x27;Hello&#x27;, &#x27; &#x27;, &#x27;World&#x27;) AS Greeting;\n\n**LENGTH(str)**：返回字符串的长度（字符数）。\n1SELECT LENGTH(&#x27;Hello&#x27;) AS StringLength;\n\n**SUBSTRING(str, pos, len)**：从指定位置开始，截取指定长度的子字符串。\n1SELECT SUBSTRING(&#x27;Hello World&#x27;, 1, 5) AS SubStr;\n\n**REPLACE(str, from_str, to_str)**：将字符串中的某部分替换为另一个字符串。\n1SELECT REPLACE(&#x27;Hello World&#x27;, &#x27;World&#x27;, &#x27;MySQL&#x27;) AS ReplacedStr;\n\n\n\n\n\n\n\n\n\n\n二、数值函数\n**ABS(num)**：返回数字的绝对值。\n1SELECT ABS(-10) AS AbsoluteValue;\n\n**POWER(num, exponent)**：返回指定数字的指定幂次方。\n1SELECT POWER(2, 3) AS PowerValue;\n\n\n\n\n\n\n\n\n\n\n三、日期和时间函数\n**NOW()**：返回当前日期和时间。\n1SELECT NOW() AS CurrentDateTime;\n\n**CURDATE()**：返回当前日期。\n1SELECT CURDATE() AS CurrentDate;\n\n\n\n\n\n\n\n\n\n\n四、聚合函数\n**COUNT(column)**：计算指定列中的非NULL值的个数。\n1SELECT COUNT(*) AS RowCount FROM my_table;\n\n**SUM(column)**：计算指定列的总和。\n1SELECT SUM(price) AS TotalPrice FROM orders;\n\n**AVG(column)**：计算指定列的平均值。\n1SELECT AVG(price) AS AveragePrice FROM orders;\n\n**MAX(column)**：返回指定列的最大值。\n1SELECT MAX(price) AS MaxPrice FROM orders;\n\n**MIN(column)**：返回指定列的最小值。\n1SELECT MIN(price) AS MinPrice FROM orders;\n\n# SQL查询语句的执行顺序是怎么样的？\n所有的查询语句都是从FROM开始执行，在执行过程中，每个步骤都会生成一个虚拟表，这个虚拟表将作为下一个执行步骤的输入，最后一个步骤产生的虚拟表即为输出结果。\n123456789101112(9) SELECT (10) DISTINCT &lt;column&gt;,(6) AGG_FUNC &lt;column&gt; or &lt;expression&gt;, ...(1) FROM &lt;left_table&gt;     (3) &lt;join_type&gt;JOIN&lt;right_table&gt;    (2) ON&lt;join_condition&gt;(4) WHERE &lt;where_condition&gt;(5) GROUP BY &lt;group_by_list&gt;(7) WITH &#123;CUBE|ROLLUP&#125;(8) HAVING &lt;having_condtion&gt;(11) ORDER BY &lt;order_by_list&gt;(12) LIMIT &lt;limit_number&gt;;\n\n# sql题：给学生表、课程成绩表，求不存在01课程但存在02课程的学生的成绩可以使用SQL的子查询和LEFT JOIN或者EXISTS关键字来实现，这里我将展示两种不同的方法来完成这个查询。\n假设我们有以下两张表：\n\nStudent 表，其中包含学生的sid（学生编号）和其他相关信息。\nScore 表，其中包含sid（学生编号），cid（课程编号）和score（分数）。\n\n方法1：使用LEFT JOIN 和 IS NULL\n12345SELECT s.sid, s.sname, sc2.cid, sc2.scoreFROM Student sLEFT JOIN Score AS sc1 ON s.sid = sc1.sid AND sc1.cid = &#x27;01&#x27;LEFT JOIN Score AS sc2 ON s.sid = sc2.sid AND sc2.cid = &#x27;02&#x27;WHERE sc1.cid IS NULL AND sc2.cid IS NOT NULL;\n\n方法2：使用NOT EXISTS\n123456SELECT s.sid, s.sname, sc.cid, sc.scoreFROM Student sJOIN Score sc ON s.sid = sc.sid AND sc.cid = &#x27;02&#x27;WHERE NOT EXISTS (    SELECT 1 FROM Score sc1 WHERE sc1.sid = s.sid AND sc1.cid = &#x27;01&#x27;);\n\n# 给定一个学生表 student_score（stu_id，subject_id，score），查询总分排名在5-10名的学生id及对应的总分可以使用以下 SQL 查询来检索总分排名在 5 到 10 名的学生 ID 及对应的总分。其中我们先计算每个学生的总分，然后为其分配一个排名，最后检索排名在 5 到 10 之间的记录。\n123456789101112131415161718192021222324WITH StudentTotalScores AS (    SELECT         stu_id,        SUM(score) AS total_score    FROM         student_score    GROUP BY         stu_id),RankedStudents AS (    SELECT        stu_id,        total_score,        RANK() OVER (ORDER BY total_score DESC) AS ranking    FROM        StudentTotalScores)SELECT    stu_id,    total_scoreFROM    RankedStudentsWHERE    ranking BETWEEN 5 AND 10;\n\n解释：\n\n子查询 StudentTotalScores 中，我们通过对 student_score 表中的 stu_id 分组来计算每个学生的总分。\n子查询 RankedStudents 中，我们使用 RANK() 函数为每个学生分配一个排名，按总分从高到低排序。\n最后，我们在主查询中选择排名在 5 到 10 之间的学生。\n\n# 存储引擎# 执行一条SQL请求的过程是什么？先来一个上帝视角图，下面就是 MySQL 执行一条 SQL 查询语句的流程，也从图中可以看到 MySQL 内部架构里的各个功能模块。\n\n\n连接器：建立连接，管理连接、校验用户身份；\n\n查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；\n\n解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；\n\n执行 SQL：执行 SQL 共有三个阶段：\n\n预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。\n\n优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；\n\n执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；\n\n\n\n\n# 讲一讲mysql的引擎吧，你有什么了解？\nInnoDB：InnoDB是MySQL的默认存储引擎，具有ACID事务支持、行级锁、外键约束等特性。它适用于高并发的读写操作，支持较好的数据完整性和并发控制。\nMyISAM：MyISAM是MySQL的另一种常见的存储引擎，具有较低的存储空间和内存消耗，适用于大量读操作的场景。然而，MyISAM不支持事务、行级锁和外键约束，因此在并发写入和数据完整性方面有一定的限制。\nMemory：Memory引擎将数据存储在内存中，适用于对性能要求较高的读操作，但是在服务器重启或崩溃时数据会丢失。它不支持事务、行级锁和外键约束。\n\n# MySQL为什么InnoDB是默认引擎？InnoDB引擎在事务支持、并发性能、崩溃恢复等方面具有优势，因此被MySQL选择为默认的存储引擎。\n\n事务支持：InnoDB引擎提供了对事务的支持，可以进行ACID（原子性、一致性、隔离性、持久性）属性的操作。Myisam存储引擎是不支持事务的。\n并发性能：InnoDB引擎采用了行级锁定的机制，可以提供更好的并发性能，Myisam存储引擎只支持表锁，锁的粒度比较大。\n崩溃恢复：InnoDB引引擎通过 redolog 日志实现了崩溃恢复，可以在数据库发生异常情况（如断电）时，通过日志文件进行恢复，保证数据的持久性和一致性。Myisam是不支持崩溃恢复的。\n\n# 说一下mysql的innodb与MyISAM的区别？\n事务：InnoDB 支持事务，MyISAM 不支持事务，这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一。\n索引结构：InnoDB 是聚簇索引，MyISAM 是非聚簇索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚簇索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。\n锁粒度：InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。\ncount 的效率：InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快。\n\n# 数据管理里，数据文件大体分成哪几种数据文件？我们每创建一个 database（数据库） 都会在 &#x2F;var&#x2F;lib&#x2F;mysql&#x2F; 目录里面创建一个以 database 为名的目录，然后保存表结构和表数据的文件都会存放在这个目录里。\n比如，我这里有一个名为 my_test 的 database，该 database 里有一张名为 t_order 数据库表。\n\n然后，我们进入 &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;my_test 目录，看看里面有什么文件？\n1234[root@xiaolin ~]#ls /var/lib/mysql/my_testdb.opt  t_order.frm  t_order.ibd\n\n可以看到，共有三个文件，这三个文件分别代表着：\n\ndb.opt，用来存储当前数据库的默认字符集和字符校验规则。\nt_order.frm ，t_order 的表结构会保存在这个文件。在 MySQL 中建立一张表都会生成一个.frm 文件，该文件是用来保存每个表的元数据信息的，主要包含表结构定义。\nt_order.ibd，t_order 的表数据会保存在这个文件。表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.ibd）。这个行为是由参数 innodb_file_per_table 控制的，若设置了参数 innodb_file_per_table 为 1，则会将存储的数据、索引等信息单独存储在一个独占表空间，从 MySQL 5.6.6 版本开始，它的默认值就是 1 了，因此从这个版本之后， MySQL 中每一张表的数据都存放在一个独立的 .ibd 文件。\n\n# 索引# 索引是什么？有什么好处？索引类似于书籍的目录，可以减少扫描的数据量，提高查询效率。\n\n如果查询的时候，没有用到索引就会全表扫描，这时候查询的时间复杂度是On\n如果用到了索引，那么查询的时候，可以基于二分查找算法，通过索引快速定位到目标数据， mysql 索引的数据结构一般是 b+树，其搜索复杂度为O(logdN)，其中 d 表示节点允许的最大子节点个数为 d 个。\n\n# 讲讲索引的分类是什么？MySQL可以按照四个角度来分类索引。\n\n按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。\n按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）。\n按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。\n按「字段个数」分类：单列索引、联合索引。\n\n接下来，按照这些角度来说说各类索引的特点。\n\n\n\n\n\n\n\n\n\n按数据结构分类\n从数据结构的角度来看，MySQL 常见索引有 B+Tree 索引、HASH 索引、Full-Text 索引。\n每一种存储引擎支持的索引类型不一定相同，我在表中总结了 MySQL 常见的存储引擎 InnoDB、MyISAM 和 Memory 分别支持的索引类型。\n\nInnoDB 是在 MySQL 5.5 之后成为默认的 MySQL 存储引擎，B+Tree 索引类型也是 MySQL 存储引擎采用最多的索引类型。\n在创建表时，InnoDB 存储引擎会根据不同的场景选择不同的列作为索引：\n\n如果有主键，默认会使用主键作为聚簇索引的索引键（key）；\n如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）；\n在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）；\n\n其它索引都属于辅助索引（Secondary Index），也被称为二级索引或非聚簇索引。创建的主键索引和二级索引默认使用的是 B+Tree 索引。\n\n\n\n\n\n\n\n\n\n按物理存储分类\n从物理存储的角度来看，索引分为聚簇索引（主键索引）、二级索引（辅助索引）。\n这两个区别在前面也提到了：\n\n主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；\n二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。\n\n所以，在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是覆盖索引。如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是回表。\n\n\n\n\n\n\n\n\n\n按字段特性分类\n从字段特性的角度来看，索引分为主键索引、唯一索引、普通索引、前缀索引。\n\n主键索引\n\n主键索引就是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。\n在创建表时，创建主键索引的方式如下：\n1234CREATE TABLE table_name  (  ....  PRIMARY KEY (index_column_1) USING BTREE);\n\n\n唯一索引\n\n唯一索引建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。\n在创建表时，创建唯一索引的方式如下：\n1234CREATE TABLE table_name  (  ....  UNIQUE KEY(index_column_1,index_column_2,...) );\n\n建表后，如果要创建唯一索引，可以使用这面这条命令：\n12CREATE UNIQUE INDEX index_nameON table_name(index_column_1,index_column_2,...);\n\n\n普通索引\n\n普通索引就是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE。\n在创建表时，创建普通索引的方式如下：\n1234CREATE TABLE table_name  (  ....  INDEX(index_column_1,index_column_2,...) );\n\n建表后，如果要创建普通索引，可以使用这面这条命令：\n12CREATE INDEX index_nameON table_name(index_column_1,index_column_2,...);\n\n\n前缀索引\n\n前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。\n使用前缀索引的目的是为了减少索引占用的存储空间，提升查询效率。\n在创建表时，创建前缀索引的方式如下：\n1234CREATE TABLE table_name(    column_list,    INDEX(column_name(length)));\n\n建表后，如果要创建前缀索引，可以使用这面这条命令：\n12CREATE INDEX index_nameON table_name(column_name(length));\n\n\n\n\n\n\n\n\n\n\n按字段个数分类\n从字段个数的角度来看，索引分为单列索引、联合索引（复合索引）。\n\n建立在单列上的索引称为单列索引，比如主键索引；\n建立在多列上的索引称为联合索引；\n\n通过将多个字段组合成一个索引，该索引就被称为联合索引。\n比如，将商品表中的 product_no 和 name 字段组合成联合索引(product_no, name)，创建联合索引的方式如下：\n1CREATE INDEX index_product_no_name ON product(product_no, name);\n\n联合索引(product_no, name) 的 B+Tree 示意图如下（图中叶子节点之间我画了单向链表，但是实际上是双向链表，原图我找不到了，修改不了，偷个懒我不重画了，大家脑补成双向链表就行）。\n\n可以看到，联合索引的非叶子节点用两个字段的值作为 B+Tree 的 key 值。当在联合索引查询数据时，先按 product_no 字段比较，在 product_no 相同的情况下再按 name 字段比较。\n也就是说，联合索引查询的 B+Tree 是先按 product_no 进行排序，然后再 product_no 相同的情况再按 name 字段排序。\n因此，使用联合索引时，存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。在使用联合索引进行查询的时候，如果不遵循「最左匹配原则」，联合索引会失效，这样就无法利用到索引快速查询的特性了。\n比如，如果创建了一个 (a, b, c) 联合索引，如果查询条件是以下这几种，就可以匹配上联合索引：\n\nwhere a&#x3D;1；\nwhere a&#x3D;1 and b&#x3D;2 and c&#x3D;3；\nwhere a&#x3D;1 and b&#x3D;2；\n\n需要注意的是，因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要。\n但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效:\n\nwhere b&#x3D;2；\nwhere c&#x3D;3；\nwhere b&#x3D;2 and c&#x3D;3；\n\n上面这些查询条件之所以会失效，是因为(a, b, c) 联合索引，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，b 和 c 是全局无序，局部相对有序的，这样在没有遵循最左匹配原则的情况下，是无法利用到索引的。\n联合索引有一些特殊情况，并不是查询过程使用了联合索引查询，就代表联合索引中的所有字段都用到了联合索引进行索引查询，也就是可能存在部分字段用到联合索引的 B+Tree，部分字段没有用到联合索引的 B+Tree 的情况。\n这种特殊情况就发生在范围查询。联合索引的最左匹配原则会一直向右匹配直到遇到「范围查询」就会停止匹配。也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。\n# MySQL聚簇索引和非聚簇索引的区别是什么？\n\n数据存储：在聚簇索引中，数据行按照索引键值的顺序存储，也就是说，索引的叶子节点包含了实际的数据行。这意味着索引结构本身就是数据的物理存储结构。非聚簇索引的叶子节点不包含完整的数据行，而是包含指向数据行的指针或主键值。数据行本身存储在聚簇索引中。\n索引与数据关系：由于数据与索引紧密相连，当通过聚簇索引查找数据时，可以直接从索引中获得数据行，而不需要额外的步骤去查找数据所在的位置。当通过非聚簇索引查找数据时，首先在非聚簇索引中找到对应的主键值，然后通过这个主键值回溯到聚簇索引中查找实际的数据行，这个过程称为“回表”。\n唯一性：聚簇索引通常是基于主键构建的，因此每个表只能有一个聚簇索引，因为数据只能有一种物理排序方式。一个表可以有多个非聚簇索引，因为它们不直接影响数据的物理存储位置。\n效率：对于范围查询和排序查询，聚簇索引通常更有效率，因为它避免了额外的寻址开销。非聚簇索引在使用覆盖索引进行查询时效率更高，因为它不需要读取完整的数据行。但是需要进行回表的操作，使用非聚簇索引效率比较低，因为需要进行额外的回表操作。\n\n# 如果聚簇索引的数据更新，它的存储要不要变化？\n如果更新的数据是非索引数据，也就是普通的用户记录，那么存储结构是不会发生变化\n如果更新的数据是索引数据，那么存储结构是有变化的，因为要维护 b+树的有序性\n\n# MySQL主键是聚簇索引吗？在MySQL的InnoDB存储引擎中，主键确实是以聚簇索引的形式存储的。\nInnoDB将数据存储在B+树的结构中，其中主键索引的B+树就是所谓的聚簇索引。这意味着表中的数据行在物理上是按照主键的顺序排列的，聚簇索引的叶节点包含了实际的数据行。\n\nInnoDB 在创建聚簇索引时，会根据不同的场景选择不同的列作为索引：\n\n如果有主键，默认会使用主键作为聚簇索引的索引键；\n如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键；\n在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键；\n\n一张表只能有一个聚簇索引，那为了实现非主键字段的快速搜索，就引出了二级索引（非聚簇索引&#x2F;辅助索引），它也是利用了 B+ 树的数据结构，但是二级索引的叶子节点存放的是主键值，不是实际数据。\n# 什么字段适合当做主键？\n字段具有唯一性，且不能为空的特性\n字段最好的是有递增的趋势的，如果字段的值是随机无序的，可能会引发页分裂的问题，造型性能影响。\n不建议用业务数据作为主键，比如会员卡号、订单号、学生号之类的，因为我们无法预测未来会不会因为业务需要，而出现业务字段重复或者重用的情况。\n通常情况下会用自增字段来做主键，对于单机系统来说是没问题的。但是，如果有多台服务器，各自都可以录入数据，那就不一定适用了。因为如果每台机器各自产生的数据需要合并，就可能会出现主键重复的问题，这时候就需要考虑分布式 id 的方案了。\n\n# 性别字段能加索引么？为啥？不建议针对性别字段加索引。\n实际上与索引创建规则之一区分度有关，性别字段假设有100w数据，50w男、50w女，区别度几乎等于 0 。\n区分度的计算方式 ：select count(DISTINCT sex)&#x2F;count(*) from sys_user\n实际上对于性别字段不适合创建索引，是因为select * 操作，还得进行50w次回表操作，根据主键从聚簇索引中找到其他字段 ，这一部分开销从上面的测试来说还是比较大的，所以从性能角度来看不建议性别字段加索引，加上索引并不是索引失效，而是回表操作使得变慢的。\n既然走索引的查询的成本比全表扫描高，优化器就会选择全表扫描的方向进行查询，这时候建立的性别字段索引就没有启到加快查询的作用，反而还因为创建了索引占用了空间。\n# 表中十个字段，你主键用自增ID还是UUID，为什么？用的是自增 id。\n因为 uuid 相对顺序的自增 id 来说是毫无规律可言的，新行的值不一定要比之前的主键的值要大，所以 innodb 无法做到总是把新行插入到索引的最后，而是需要为新行寻找新的合适的位置从而来分配新的空间。\n这个过程需要做很多额外的操作，数据的毫无顺序会导致数据分布散乱，将会导致以下的问题：\n\n写入的目标页很可能已经刷新到磁盘上并且从缓存上移除，或者还没有被加载到缓存中，innodb 在插入之前不得不先找到并从磁盘读取目标页到内存中，这将导致大量的随机 IO。\n因为写入是乱序的，innodb 不得不频繁的做页分裂操作，以便为新的行分配空间，页分裂导致移动大量的数据，影响性能。\n由于频繁的页分裂，页会变得稀疏并被不规则的填充，最终会导致数据会有碎片。\n\n结论：使用 InnoDB 应该尽可能的按主键的自增顺序插入，并且尽可能使用单调的增加的聚簇键的值来插入新行。\n# 什么自增ID更快一些，UUID不快吗，它在B+树里面存储是有序的吗?自增的主键的值是顺序的，所以 Innodb 把每一条记录都存储在一条记录的后面，所以自增 id 更快的原因：\n\n下一条记录就会写入新的页中，一旦数据按照这种顺序的方式加载，主键页就会近乎于顺序的记录填满，提升了页面的最大填充率，不会有页的浪费\n新插入的行一定会在原有的最大数据行下一行，mysql定位和寻址很快，不会为计算新行的位置而做出额外的消耗\n减少了页分裂和碎片的产生\n\n但是 UUID 不是递增的，MySQL 中索引的数据结构是 B+Tree，这种数据结构的特点是索引树上的节点的数据是有序的，而如果使用 UUID 作为主键，那么每次插入数据时，因为无法保证每次产生的 UUID 有序，所以就会出现新的 UUID 需要插入到索引树的中间去，这样可能会频繁地导致页分裂，使性能下降。\n而且，UUID 太占用内存。每个 UUID 由 36 个字符组成，在字符串进行比较时，需要从前往后比较，字符串越长，性能越差。另外字符串越长，占用的内存越大，由于页的大小是固定的，这样一个页上能存放的关键字数量就会越少，这样最终就会导致索引树的高度越大，在索引搜索的时候，发生的磁盘 IO 次数越多，性能越差。\n# Mysql中的索引是怎么实现的 ？MySQL InnoDB 引擎是用了B+树作为了索引的数据结构。\nB+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，而且每个节点里的数据是按主键顺序存放的。每一层父节点的索引值都会出现在下层子节点的索引值中，因此在叶子节点中，包括了所有的索引值信息，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个双向链表。\n主键索引的 B+Tree 如图所示：\n\n比如，我们执行了下面这条查询语句：\n1select * from product where id= 5;\n\n这条语句使用了主键索引查询 id 号为 5 的商品。查询过程是这样的，B+Tree 会自顶向下逐层进行查找：\n\n将 5 与根节点的索引数据 (1，10，20) 比较，5 在 1 和 10 之间，所以根据 B+Tree的搜索逻辑，找到第二层的索引数据 (1，4，7)；\n在第二层的索引数据 (1，4，7)中进行查找，因为 5 在 4 和 7 之间，所以找到第三层的索引数据（4，5，6）；\n在叶子节点的索引数据（4，5，6）中进行查找，然后我们找到了索引值为 5 的行数据。\n\n数据库的索引和数据都是存储在硬盘的，我们可以把读取一个节点当作一次磁盘 I&#x2F;O 操作。那么上面的整个查询过程一共经历了 3 个节点，也就是进行了 3 次 I&#x2F;O 操作。\nB+Tree 存储千万级的数据只需要 3-4 层高度就可以满足，这意味着从千万级的表查询目标数据最多需要 3-4 次磁盘 I&#x2F;O，所以B+Tree 相比于 B 树和二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘 I&#x2F;O 依然维持在 3-4次。\n# 查询数据时，到了B+树的叶子节点，之后的查找数据是如何做？数据页中的记录按照「主键」顺序组成单向链表，单向链表的特点就是插入、删除非常方便，但是检索效率不高，最差的情况下需要遍历链表上的所有节点才能完成检索。\n因此，数据页中有一个页目录，起到记录的索引作用，就像我们书那样，针对书中内容的每个章节设立了一个目录，想看某个章节的时候，可以查看目录，快速找到对应的章节的页数，而数据页中的页目录就是为了能快速找到记录。那 InnoDB 是如何给记录创建页目录的呢？\n页目录与记录的关系如下图：页目录创建的过程如下：\n\n将所有的记录划分成几个组，这些记录包括最小记录和最大记录，但不包括标记为“已删除”的记录；\n每个记录组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录，作为 n_owned 字段（上图中粉红色字段）\n页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），每个槽相当于指针指向了不同组的最后一个记录。\n\n从图可以看到，页目录就是由多个槽组成的，槽相当于分组记录的索引。然后，因为记录是按照「主键值」从小到大排序的，所以我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录，无需从最小记录开始遍历整个页中的记录链表。以上面那张图举个例子，5 个槽的编号分别为 0，1，2，3，4，我想查找主键为 11 的用户记录：\n\n先二分得出槽中间位是 (0+4)&#x2F;2&#x3D;2 ，2号槽里最大的记录为 8。因为 11 &gt; 8，所以需要从 2 号槽后继续搜索记录；\n再使用二分搜索出 2 号和 4 槽的中间位是 (2+4)&#x2F;2&#x3D; 3，3 号槽里最大的记录为 12。因为 11 &lt; 12，所以主键为 11 的记录在 3 号槽里；\n再从 3 号槽指向的主键值为 9 记录开始向下搜索 2 次，定位到主键为 11 的记录，取出该条记录的信息即为我们想要查找的内容。\n\n## B+树的特性是什么？\n所有叶子节点都在同一层：这是B+树的一个重要特性，确保了所有数据项的检索都具有相同的I&#x2F;O延迟，提高了搜索效率。每个叶子节点都包含指向相邻叶子节点的指针，形成一个链表，由于叶子节点之间的链接，B+树非常适合进行范围查询和排序扫描。可以沿着叶子节点的链表顺序访问数据，而无需进行多次随机访问。\n非叶子节点存储键值：非叶子节点仅存储键值和指向子节点的指针，不包含数据记录。这些键值用于指导搜索路径，帮助快速定位到正确的叶子节点。并且，由于非叶子节点只存放键值，当数据量比较大时，相对于B树，B+树的层高更少，查找效率也就更高。\n叶子节点存储数据记录：与B树不同，B+树的叶子节点存储实际的数据记录或指向数据记录的指针。这意味着每次搜索都会到达叶子节点，才能找到所需数据。\n自平衡：B+树在插入、删除和更新操作后会自动重新平衡，确保树的高度保持相对稳定，从而保持良好的搜索性能。每个节点最多可以有M个子节点，最少可以有ceil(M&#x2F;2)个子节点（除了根节点），这里的M是树的阶数。\n\n# 说说B+树和B树的区别\n在B+树中，数据都存储在叶子节点上，而非叶子节点只存储索引信息；而B树的非叶子节点既存储索引信息也存储部分数据。\nB+树的叶子节点使用链表相连，便于范围查询和顺序访问；B树的叶子节点没有链表连接。\nB+树的查找性能更稳定，每次查找都需要查找到叶子节点；而B树的查找可能会在非叶子节点找到数据，性能相对不稳定。\n\n# B+树的好处是什么？B 树和 B+ 都是通过多叉树的方式，会将树的高度变矮，所以这两个数据结构非常适合检索存于磁盘中的数据。\n但是 MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构，原因有：\n\n\nB+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I&#x2F;O次数会更少。\nB+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；\nB+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I&#x2F;O 操作，范围查询效率不如 B+ 树。\n\n# B+树的叶子节点链表是单向还是双向？双向的，为了实现倒序遍历或者排序。\n\nInnodb 使用的 B+ 树有一些特别的点，比如：\n\nB+ 树的叶子节点之间是用「双向链表」进行连接，这样的好处是既能向右遍历，也能向左遍历。\nB+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB。\n\nInnodb 根据索引类型不同，分为聚集和二级索引。他们区别在于，聚集索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚集索引的叶子节点，而二级索引的叶子节点存放的是主键值，而不是实际数据。\n因为表的数据都是存放在聚集索引的叶子节点里，所以 InnoDB 存储引擎一定会为表创建一个聚集索引，且由于数据在物理上只会保存一份，所以聚簇索引只能有一个，而二级索引可以创建多个。\n# MySQL为什么用B+树结构？和其他结构比的优点？\n**B+Tree vs B Tree：**B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I&#x2F;O 次数下，就能查询更多的节点。另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。\n**B+Tree vs 二叉树：**对于有 N 个叶子节点的 B+Tree，其搜索复杂度为O(logdN)，其中 d 表示节点允许的最大子节点个数为 d 个。在实际的应用当中， d 值是大于100的，这样就保证了，即使数据达到千万级别时，B+Tree 的高度依然维持在 34 层左右，也就是说一次数据查询操作只需要做 34 次的磁盘 I&#x2F;O 操作就能查询到目标数据。而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 O(logN)，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I&#x2F;O 次数要更多。\n**B+Tree vs Hash：**Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。但是 Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因\n\n# 为什么 MysSQL 不用 跳表？B+树的高度在3层时存储的数据可能已达千万级别，但对于跳表而言同样去维护千万的数据量那么所造成的跳表层数过高而导致的磁盘io次数增多，也就是使用B+树在存储同样的数据下磁盘io次数更少。\n# 联合索引的实现原理？将将多个字段组合成一个索引，该索引就被称为联合索引。\n比如，将商品表中的 product_no 和 name 字段组合成联合索引(product_no, name)，创建联合索引的方式如下：\n1CREATE INDEX index_product_no_name ON product(product_no, name);\n\n联合索引(product_no, name) 的 B+Tree 示意图如下：\n\n可以看到，联合索引的非叶子节点用两个字段的值作为 B+Tree 的 key 值。当在联合索引查询数据时，先按 product_no 字段比较，在 product_no 相同的情况下再按 name 字段比较。\n也就是说，联合索引查询的 B+Tree 是先按 product_no 进行排序，然后再 product_no 相同的情况再按 name 字段排序。\n因此，使用联合索引时，存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。在使用联合索引进行查询的时候，如果不遵循「最左匹配原则」，联合索引会失效，这样就无法利用到索引快速查询的特性了。\n比如，如果创建了一个 (a, b, c) 联合索引，如果查询条件是以下这几种，就可以匹配上联合索引：\n\nwhere a&#x3D;1；\nwhere a&#x3D;1 and b&#x3D;2 and c&#x3D;3；\nwhere a&#x3D;1 and b&#x3D;2；\n\n需要注意的是，因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要。\n但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效:\n\nwhere b&#x3D;2；\nwhere c&#x3D;3；\nwhere b&#x3D;2 and c&#x3D;3；\n\n上面这些查询条件之所以会失效，是因为(a, b, c) 联合索引，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，b 和 c 是全局无序，局部相对有序的，这样在没有遵循最左匹配原则的情况下，是无法利用到索引的。\n我这里举联合索引（a，b）的例子，该联合索引的 B+ Tree 如下：\n\n可以看到，a 是全局有序的（1, 2, 2, 3, 4, 5, 6, 7 ,8），而 b 是全局是无序的（12，7，8，2，3，8，10，5，2）。因此，直接执行where b &#x3D; 2这种查询条件没有办法利用联合索引的，利用索引的前提是索引里的 key 是有序的。\n只有在 a 相同的情况才，b 才是有序的，比如 a 等于 2 的时候，b 的值为（7，8），这时就是有序的，这个有序状态是局部的，因此，执行where a &#x3D; 2 and b &#x3D; 7是 a 和 b 字段能用到联合索引的，也就是联合索引生效了。\n# 创建联合索引时需要注意什么？建立联合索引时的字段顺序，对索引效率也有很大影响。越靠前的字段被用于索引过滤的概率越高，实际开发工作中建立联合索引时，要把区分度大的字段排在前面，这样区分度大的字段越有可能被更多的 SQL 使用到。\n区分度就是某个字段 column 不同值的个数「除以」表的总行数，计算公式如下：\n\n比如，性别的区分度就很小，不适合建立索引或不适合排在联合索引列的靠前的位置，而 UUID 这类字段就比较适合做索引或排在联合索引列的靠前的位置。\n因为如果索引的区分度很小，假设字段的值分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比（惯用的百分比界线是”30%”）很高的时候，它一般会忽略索引，进行全表扫描。\n# 联合索引ABC，现在有个执行语句是A &#x3D; XXX and C &lt; XXX，索引怎么走根据最左匹配原则，A可以走联合索引，C不会走联合索引，但是C可以走索引下推\n# 联合索引(a,b,c) ，查询条件 where b &gt; xxx and a &#x3D; x 会生效吗索引会生效，a 和 b 字段都能利用联合索引，符合联合索引最左匹配原则。\n# 联合索引 (a, b，c)，where条件是 a&#x3D;2 and c &#x3D; 1，能用到联合索引吗？会用到联合索引，但是只有 a 才能走索引，c 无法走索引，因为不符合最左匹配原则。虽然 c 无法走索引， 但是 c 字段在 5.6 版本之后，会有索引下推的优化，能减少回表查询的次数。\n# 索引失效有哪些？6 种会发生索引失效的情况：\n\n当我们使用左或者左右模糊匹配的时候，也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效；\n当我们在查询条件中对索引列使用函数，就会导致索引失效。\n当我们在查询条件中对索引列进行表达式计算，也是无法走索引的。\nMySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。\n联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。\n在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。\n\n# 什么情况下会回表查询从物理存储的角度来看，索引分为聚簇索引（主键索引）、二级索引（辅助索引）。\n它们的主要区别如下：\n\n主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；\n二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。\n\n所以，在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是覆盖索引。\n如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是回表。\n# 什么是覆盖索引？覆盖索引是指一个索引包含了查询所需的所有列，因此不需要访问表中的数据行就能完成查询。\n换句话说，查询所需的所有数据都能从索引中直接获取，而不需要进行回表查询。覆盖索引能够显著提高查询性能，因为减少了访问数据页的次数，从而减少了I&#x2F;O操作。\n假设有一张表 employees，表结构如下：\n123456789CREATE TABLE employees (  id INT PRIMARY KEY,  name VARCHAR(100),  age INT,  department VARCHAR(100),  salary DECIMAL(10, 2));CREATE INDEX idx_name_age_department ON employees(name, age, department);\n\n如果我们有以下查询：\n1SELECT name, age, department FROM employees WHERE name = &#x27;John&#x27;;\n\n在这种情况下，idx_name_age_department 是一个覆盖索引，因为它包含了查询所需的所有列：name、age 和 department。查询可以完全在索引层完成，而不需要访问表中的数据行。\n# 如果一个列即使单列索引，又是联合索引，单独查它的话先走哪个？mysql 优化器会分析每个索引的查询成本，然后选择成本最低的方案来执行 sql。\n如果单列索引是 a，联合索引是（a ，b），那么针对下面这个查询：\n1select a, b from table where a = ? and b =?\n\n优化器会选择联合索引，因为查询成本更低，查询也不需要回表，直接索引覆盖了。\n# 索引已经建好了，那我再插入一条数据，索引会有哪些变化？插入新数据可能导致B+树结构的调整和索引信息的更新，以保持B+树的平衡性和正确性，这些变化通常由数据库系统自动处理，确保数据的一致性和索引的有效性。\n如果插入的数据导致叶子节点已满，可能会触发叶子节点的分裂操作，以保持B+树的平衡性。\n# 索引字段是不是建的越多越好？不是，建的的越多会占用越多的空间，而且在写入频繁的场景下，对于B+树的维护所付出的性能消耗也会越大\n# 如果有一个字段是status值为0或者1，适合建索引吗不适合，区分度低的字段不适合建立索引。\n# 索引的优缺点？索引最大的好处是提高查询速度，但是索引也是有缺点的，比如：\n\n需要占用物理空间，数量越大，占用空间越大；\n创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大；\n会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。\n\n所以，索引不是万能钥匙，它也是根据场景来使用的。\n# 怎么决定建立哪些索引?\n\n\n\n\n\n\n\n\n什么时候适用索引？\n\n字段有唯一性限制的，比如商品编码；\n经常用于 WHERE 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。\n经常用于 GROUP BY 和 ORDER BY 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。\n\n\n\n\n\n\n\n\n\n\n什么时候不需要创建索引？\n\nWHERE 条件，GROUP BY，ORDER BY 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。\n字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。\n表数据太少的时候，不需要创建索引；\n经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由\n\n# 索引优化详细讲讲常见优化索引的方法：\n\n前缀索引优化：使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。\n覆盖索引优化：覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。\n主键索引最好是自增的：\n如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。\n如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。\n\n\n防止索引失效：\n当我们使用左或者左右模糊匹配的时候，也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效；\n当我们在查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效；\n联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。\n在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。\n\n\n\n# 了解过前缀索引吗？使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。\n# 事务# 事务的特性是什么？如何实现的？\n原子性（Atomicity）：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样，就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。\n一致性（Consistency）：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。\n隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。\n持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。\n\nMySQL InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？\n\n持久性是通过 redo log （重做日志）来保证的；\n原子性是通过 undo log（回滚日志） 来保证的；\n隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；\n一致性则是通过持久性+原子性+隔离性来保证；\n\n# mysql可能出现什么和并发相关问题？MySQL 服务端是允许多个客户端连接的，这意味着 MySQL 会出现同时处理多个事务的情况。\n那么在同时处理多个事务的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题。\n接下来，通过举例子给大家说明，这些问题是如何发生的。\n\n\n\n\n\n\n\n\n\n脏读\n如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。\n举个栗子。\n假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后再执行更新操作，如果此时事务 A 还没有提交事务，而此时正好事务 B 也从数据库中读取小林的余额数据，那么事务 B 读取到的余额数据是刚才事务 A 更新后的数据，即使没有提交事务。\n\n因为事务 A 是还没提交事务的，也就是它随时可能发生回滚操作，如果在上面这种情况事务 A 发生了回滚，那么事务 B 刚才得到的数据就是过期的数据，这种现象就被称为脏读。\n\n\n\n\n\n\n\n\n\n不可重复读\n在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。\n举个栗子。\n假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后继续执行代码逻辑处理，**在这过程中如果事务 B 更新了这条数据，并提交了事务，那么当事务 A 再次读取该数据时，就会发现前后两次读到的数据是不一致的，这种现象就被称为不可重复读。\n**\n\n\n\n\n\n\n\n\n\n\n幻读\n在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。\n举个栗子。\n假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库查询账户余额大于 100 万的记录，发现共有 5 条，然后事务 B 也按相同的搜索条件也是查询出了 5 条记录。\n\n接下来，事务 A 插入了一条余额超过 100 万的账号，并提交了事务，此时数据库超过 100 万余额的账号个数就变为 6。\n然后事务 B 再次查询账户余额大于 100 万的记录，此时查询到的记录数量有 6 条，发现和前一次读到的记录数量不一样了，就感觉发生了幻觉一样，这种现象就被称为幻读。\n# 哪些场景不适合脏读，举个例子？脏读是指一个事务在读取到另一个事务未提交的数据时发生。脏读可能会导致不一致的数据被读取，并可能引起问题。以下是一些不适合脏读的场景：\n\n银行系统：在银行系统中，如果一个账户的余额正在被调整但尚未提交，另一个事务读取了这个临时的余额，可能会导致客户看到不正确的余额。\n库存管理系统：在一个库存管理系统中，如果一个商品的数量正在被更新但尚未提交，另一个事务读取了这个临时的数量，可能会导致库存管理错误。\n在线订单系统：在一个在线订单系统中，如果一个订单正在被修改但尚未提交，另一个事务读取了这个临时的订单状态，可能导致订单状态显示错误，客户收到不准确的信息。\n\n在以上这些场景中，脏读可能导致严重的问题，因此应该避免发生脏读，保证数据的一致性和准确性。\n# mysql的是怎么解决并发问题的？\n锁机制：Mysql提供了多种锁机制来保证数据的一致性，包括行级锁、表级锁、页级锁等。通过锁机制，可以在读写操作时对数据进行加锁，确保同时只有一个操作能够访问或修改数据。\n事务隔离级别：Mysql提供了多种事务隔离级别，包括读未提交、读已提交、可重复读和串行化。通过设置合适的事务隔离级别，可以在多个事务并发执行时，控制事务之间的隔离程度，以避免数据不一致的问题。\nMVCC（多版本并发控制）：Mysql使用MVCC来管理并发访问，它通过在数据库中保存不同版本的数据来实现不同事务之间的隔离。在读取数据时，Mysql会根据事务的隔离级别来选择合适的数据版本，从而保证数据的一致性。\n\n# 事务的隔离级别有哪些？\n读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到；\n读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到；\n可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；\n串行化（serializable）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；\n\n按隔离水平高低排序如下：\n\n针对不同的隔离级别，并发事务时可能发生的现象也会不同。\n也就是说：\n\n在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；\n在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；\n在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象；\n在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。\n\n接下来，举个具体的例子来说明这四种隔离级别，有一张账户余额表，里面有一条账户余额为 100 万的记录。然后有两个并发的事务，事务 A 只负责查询余额，事务 B 则会将我的余额改成 200 万，下面是按照时间顺序执行两个事务的行为：\n\n在不同隔离级别下，事务 A 执行过程中查询到的余额可能会不同：\n\n在「读未提交」隔离级别下，事务 B 修改余额后，虽然没有提交事务，但是此时的余额已经可以被事务 A 看见了，于是事务 A 中余额 V1 查询的值是 200 万，余额 V2、V3 自然也是 200 万了；\n在「读提交」隔离级别下，事务 B 修改余额后，因为没有提交事务，所以事务 A 中余额 V1 的值还是 100 万，等事务 B 提交完后，最新的余额数据才能被事务 A 看见，因此额 V2、V3 都是 200 万；\n在「可重复读」隔离级别下，事务 A 只能看见启动事务时的数据，所以余额 V1、余额 V2 的值都是 100 万，当事务 A 提交事务后，就能看见最新的余额数据了，所以余额 V3 的值是 200 万；\n在「串行化」隔离级别下，事务 B 在执行将余额 100 万修改为 200 万时，由于此前事务 A 执行了读操作，这样就发生了读写冲突，于是就会被锁住，直到事务 A 提交后，事务 B 才可以继续执行，所以从 A 的角度看，余额 V1、V2 的值是 100 万，余额 V3 的值是 200万。\n\n这四种隔离级别具体是如何实现的呢？\n\n对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；\n对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；\n对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View来实现的，它们的区别在于创建 Read View 的时机不同，「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。\n\n# mysql默认级别是什么？可重复读隔离级别\n# 可重复读隔离级别下，A事务提交的数据，在B事务能看见吗？可重复读隔离级是由 MVCC（多版本并发控制）实现的，实现的方式是开始事务后（执行 begin 语句后），在执行第一个查询语句后，会创建一个 Read View，后续的查询语句利用这个 Read View，通过这个 Read View 就可以在 undo log 版本链找到事务开始时的数据，所以事务过程中每次查询的数据都是一样的，即使中途有其他事务插入了新纪录，是查询不出来这条数据的。\n# 举个例子说可重复读下的幻读问题可重复读隔离级别下虽然很大程度上避免了幻读，但是还是没有能完全解决幻读。\n我举例一个可重复读隔离级别发生幻读现象的场景。以这张表作为例子：\n\n事务 A 执行查询 id &#x3D; 5 的记录，此时表中是没有该记录的，所以查询不出来。\n123456# 事务 Amysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from t_stu where id = 5;Empty set (0.01 sec)\n\n然后事务 B 插入一条 id &#x3D; 5 的记录，并且提交了事务。\n123456789# 事务 Bmysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into t_stu values(5, &#x27;小美&#x27;, 18);Query OK, 1 row affected (0.00 sec)mysql&gt; commit;Query OK, 0 rows affected (0.00 sec)\n\n此时，事务 A 更新 id &#x3D; 5 这条记录，对没错，事务 A 看不到 id &#x3D; 5 这条记录，但是他去更新了这条记录，这场景确实很违和，然后再次查询 id &#x3D; 5 的记录，事务 A 就能看到事务 B 插入的纪录了，幻读就是发生在这种违和的场景。\n123456789101112# 事务 Amysql&gt; update t_stu set name = &#x27;小林coding&#x27; where id = 5;Query OK, 1 row affected (0.01 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from t_stu where id = 5;+----+--------------+------+| id | name         | age  |+----+--------------+------+|  5 | 小林coding   |   18 |+----+--------------+------+1 row in set (0.00 sec)\n\n整个发生幻读的时序图如下：\n在可重复读隔离级别下，事务 A 第一次执行普通的 select 语句时生成了一个 ReadView，之后事务 B 向表中新插入了一条 id &#x3D; 5 的记录并提交。接着，事务 A 对 id &#x3D; 5 这条记录进行了更新操作，在这个时刻，这条新记录的 trx_id 隐藏列的值就变成了事务 A 的事务 id，之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。\n因为这种特殊现象的存在，所以我们认为 MySQL Innodb 中的 MVCC 并不能完全避免幻读现象。\n# Mysql 设置了可重读隔离级后，怎么保证不发生幻读？尽量在开启事务之后，马上执行 select … for update 这类锁定读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录，就避免了幻读的问题。\n# 串行化隔离级别是通过什么实现的？是通过行级锁来实现的，序列化隔离级别下，普通的 select 查询是会对记录加 S 型的 next-key 锁，其他事务就没没办法对这些已经加锁的记录进行增删改操作了，从而避免了脏读、不可重复读和幻读现象。\n# 介绍MVCC实现原理MVCC允许多个事务同时读取同一行数据，而不会彼此阻塞，每个事务看到的数据版本是该事务开始时的数据版本。这意味着，如果其他事务在此期间修改了数据，正在运行的事务仍然看到的是它开始时的数据状态，从而实现了非阻塞读操作。\n对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。\n\n「读提交」隔离级别是在「每个select语句执行前」都会重新生成一个 Read View；\n「可重复读」隔离级别是执行第一条select时，生成一个 Read View，然后整个事务期间都在用这个 Read View。\n\nRead View 有四个重要的字段：\n\n\nm_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表，注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。\nmin_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值。\nmax_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1；\ncreator_trx_id ：指的是创建该 Read View 的事务的事务 id。\n\n对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列：\n\n\ntrx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里；\nroll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。\n\n在创建 Read View 后，我们可以将记录中的 trx_id 划分这三种情况：\n\n一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：\n\n如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。\n\n如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。\n\n如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中：\n\n如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。\n\n如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。\n\n\n这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。\n# 一条update是不是原子性的？为什么？是原子性，主要通过锁+undolog 日志保证原子性的\n\n执行 update 的时候，会加行级别锁，保证了一个事务更新一条记录的时候，不会被其他事务干扰。\n事务执行过程中，会生成 undolog，如果事务执行失败，就可以通过 undolog 日志进行回滚。\n\n# 滥用事务，或者一个事务里有特别多sql的弊端？事务的资源在事务提交之后才会释放的，比如存储资源、锁。\n如果一个事务特别多 sql，那么会带来这些问题：\n\n如果一个事务特别多 sql，锁定的数据太多，容易造成大量的死锁和锁超时。\n回滚记录会占用大量存储空间，事务回滚时间长。在MySQL (opens new window)中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值，sql 越多，所需要保存的回滚数据就越多。\n执行时间长，容易造成主从延迟，主库上必须等事务执行完成才会写入binlog，再传给备库。所以，如果一个主库上的语句执行10分钟，那这个事务很可能就会导致从库延迟10分钟\n\n# 锁# 讲一下mysql里有哪些锁？在 MySQL 里，根据加锁的范围，可以分为全局锁、表级锁和行锁三类。\n\n\n全局锁：通过flush tables with read lock 语句会将整个数据库就处于只读状态了，这时其他线程执行以下操作，增删改或者表结构修改都会阻塞。全局锁主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。\n\n表级锁：MySQL 里面表级别的锁有这几种：\n\n表锁：通过lock tables 语句可以对表加表锁，表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。\n\n元数据锁：当我们对数据库表进行操作时，会自动给这个表加上 MDL，对一张表进行 CRUD 操作时，加的是 MDL 读锁；对一张表做结构变更操作的时候，加的是 MDL 写锁；MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。\n\n意向锁：当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。意向锁的目的是为了快速判断表里是否有记录被加锁。\n\n\n\n行级锁：InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。\n\n记录锁，锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的，满足读写互斥，写写互斥\n\n间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。\n\nNext-Key Lock 称为临键锁，是 Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。\n\n\n# 数据库的表锁和行锁有什么作用？表锁的作用：\n\n整体控制：表锁可以用来控制整个表的并发访问，当一个事务获取了表锁时，其他事务无法对该表进行任何读写操作，从而确保数据的完整性和一致性。\n粒度大：表锁的粒度比较大，在锁定表的情况下，可能会影响到整个表的其他操作，可能会引起锁竞争和性能问题。\n适用于大批量操作：表锁适合于需要大批量操作表中数据的场景，例如表的重建、大量数据的加载等。\n\n行锁的作用：\n\n细粒度控制：行锁可以精确控制对表中某行数据的访问，使得其他事务可以同时访问表中的其他行数据，在并发量大的系统中能够提高并发性能。\n减少锁冲突：行锁不会像表锁那样造成整个表的锁冲突，减少了锁竞争的可能性，提高了并发访问的效率。\n适用于频繁单行操作：行锁适合于需要频繁对表中单独行进行操作的场景，例如订单系统中的订单修改、删除等操作。\n\n# MySQL两个线程的update语句同时处理一条数据，会不会有阻塞？如果是两个事务同时更新了 id &#x3D; 1，比如 update … where id &#x3D; 1，那么是会阻塞的。因为 InnoDB 存储引擎实现了行级锁。\n当A事务对 id &#x3D;1 这行记录进行更新时，会对主键 id 为 1 的记录加X类型的记录锁，这样第二事务对 id &#x3D; 1 进行更新时，发现已经有记录锁了，就会陷入阻塞状态。\n# 两条update语句处理一张表的不同的主键范围的记录，一个&lt;10，一个&gt;15，会不会遇到阻塞？底层是为什么的？不会，因为锁住的范围不一样，不会形成冲突。\n\n第一条 update sql 的话（ id&lt;10），锁住的范围是（-♾️，10）\n第二条 update sql 的话（id &gt;15），锁住的范围是（15，+♾️）\n\n# 如果2个范围不是主键或索引？还会阻塞吗？如果2个范围查询的字段不是索引的话，那就代表 update 没有用到索引，这时候触发了全表扫描，全部索引都会加行级锁，这时候第二条 update 执行的时候，就会阻塞了。\n因为如果 update 没有用到索引，在扫描过程中会对索引加锁，所以全表扫描的场景下，所有记录都会被加锁，也就是这条 update 语句产生了 4 个记录锁和 5 个间隙锁，相当于锁住了全表。\n\n# 日志# 日志文件是分成了哪几种？\nredo log 重做日志，是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复；\nundo log 回滚日志，是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。\nbin log 二进制日志，是 Server 层生成的日志，主要用于数据备份和主从复制；\nrelay log 中继日志，用于主从复制场景下，slave通过io线程拷贝master的bin log后本地生成的日志\n慢查询日志，用于记录执行时间过长的sql，需要设置阈值后手动开启\n\n# 讲一下binlogMySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件，binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用。\nbinlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志，用于备份恢复、主从复制；\nbinlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。\nbinlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：\n\nSTATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；\nROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；\nMIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；\n\n# UndoLog日志的作用是什么？undo log 是一种用于撤销回退的日志，它保证了事务的 ACID 特性中的原子性（Atomicity）。\n在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。如下图：\n\n每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里，比如：\n\n在插入一条记录时，要把这条记录的主键值记下来，这样之后回滚时只需要把这个主键值对应的记录删掉就好了；\n在删除一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录插入到表中就好了；\n在更新一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列更新为旧值就好了。\n\n在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作。比如当 delete 一条记录时，undo log 中会把记录中的内容都记下来，然后执行回滚操作的时候，就读取 undo log 里的数据，然后进行 insert 操作。\n# 有了undolog为啥还需要redolog呢？Buffer Pool 是提高了读写效率没错，但是问题来了，Buffer Pool 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。\n为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，这个时候更新就算完成了。\n后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 WAL （Write-Ahead Logging）技术。\nWAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。\n过程如下图：\n\nredo log 是物理日志，记录了某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新，每当执行一个事务就会产生这样的一条或者多条物理日志。\n在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。\n当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。\nredo log 和 undo log 这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于：\n\nredo log 记录了此次事务「完成后」的数据状态，记录的是更新之后的值；\nundo log 记录了此次事务「开始前」的数据状态，记录的是更新之前的值；\n\n事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务，如下图：\n\n所以有了 redo log，再通过 WAL 技术，InnoDB 就可以保证即使数据库发生异常重启，之前已提交的记录都不会丢失，这个能力称为 crash-safe（崩溃恢复）。可以看出来， redo log 保证了事务四大特性中的持久性。\n写入 redo log 的方式使用了追加操作， 所以磁盘操作是顺序写，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是随机写。\n磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。\n针对「顺序写」为什么比「随机写」更快这个问题，可以比喻为你有一个本子，按照顺序一页一页写肯定比写一个字都要找到对应页写快得多。\n可以说这是 WAL 技术的另外一个优点：MySQL 的写操作从磁盘的「随机写」变成了「顺序写」，提升语句的执行性能。这是因为 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上 。\n至此， 针对为什么需要 redo log 这个问题我们有两个答案：\n\n实现事务的持久性，让 MySQL 有 crash-safe 的能力，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；\n将写操作从「随机写」变成了「顺序写」，提升 MySQL 写入磁盘的性能。\n\n# redo log怎么保证持久性的？Redo log是MySQL中用于保证持久性的重要机制之一。它通过以下方式来保证持久性：\n\nWrite-ahead logging（WAL）：在事务提交之前，将事务所做的修改操作记录到redo log中，然后再将数据写入磁盘。这样即使在数据写入磁盘之前发生了宕机，系统可以通过redo log中的记录来恢复数据。\nRedo log的顺序写入：redo log采用追加写入的方式，将redo日志记录追加到文件末尾，而不是随机写入。这样可以减少磁盘的随机I&#x2F;O操作，提高写入性能。\nCheckpoint机制：MySQL会定期将内存中的数据刷新到磁盘，同时将最新的LSN（Log Sequence Number）记录到磁盘中，这个LSN可以确保redo log中的操作是按顺序执行的。在恢复数据时，系统会根据LSN来确定从哪个位置开始应用redo log。\n\n# 能不能只用binlog不用relo log？不行，binlog是 server 层的日志，没办法记录哪些脏页还没有刷盘，redolog 是存储引擎层的日志，可以记录哪些脏页还没有刷盘，这样崩溃恢复的时候，就能恢复那些还没有被刷盘的脏页数据。\n# binlog 两阶段提交过程是怎么样的？事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。\n在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log，为了保证这两个日志的一致性，MySQL 使用了内部 XA 事务（是的，也有外部 XA 事务，跟本文不太相关，我就不介绍了），内部 XA 事务由 binlog 作为协调者，存储引擎是参与者。\n当客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，分两阶段来完成 XA 事务的提交，如下图：\n\n从图中可看出，事务的提交过程有两个阶段，就是将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog，具体如下：\n\nprepare 阶段：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit &#x3D; 1 的作用）；\ncommit 阶段：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog &#x3D; 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；\n\n我们来看看在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象？下图中有时刻 A 和时刻 B 都有可能发生崩溃：\n\n不管是时刻 A（redo log 已经写入磁盘， binlog 还没写入磁盘），还是时刻 B （redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识）崩溃，此时的 redo log 都处于 prepare 状态。\n在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：\n\n如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务。对应时刻 A 崩溃恢复的情况。\n如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务。对应时刻 B 崩溃恢复的情况。\n\n可以看到，对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID，如果有就提交事务，如果没有就回滚事务。这样就可以保证 redo log 和 binlog 这两份日志的一致性了。\n所以说，两阶段提交是以 binlog 写成功为事务提交成功的标识，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。\n# update语句的具体执行过程是怎样的？具体更新一条记录 UPDATE t_user SET name = &#39;xiaolin&#39; WHERE id = 1; 的流程如下:\n\n执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id &#x3D; 1 这一行记录：\n如果 id&#x3D;1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；\n如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。\n\n\n执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：\n如果一样的话就不进行后续更新流程；\n如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；\n\n\n开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。\nInnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I&#x2F;O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 WAL 技术，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。\n至此，一条记录更新完了。\n在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。\n事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）：\nprepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；\ncommit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；\n\n\n至此，一条更新语句执行完成。\n\n# 性能调优# mysql的explain有什么作用？explain 是查看 sql 的执行计划，主要用来分析 sql 语句的执行过程，比如有没有走索引，有没有外部排序，有没有索引覆盖等等。\n如下图，就是一个没有使用索引，并且是一个全表扫描的查询语句。\n\n对于执行计划，参数有：\n\npossible_keys 字段表示可能用到的索引；\nkey 字段表示实际用的索引，如果这一项为 NULL，说明没有使用索引；\nkey_len 表示索引的长度；\nrows 表示扫描的数据行数。\ntype 表示数据扫描类型，我们需要重点看这个。\n\ntype 字段就是描述了找到所需数据时使用的扫描方式是什么，常见扫描类型的执行效率从低到高的顺序为：\n\nAll（全表扫描）：在这些情况里，all 是最坏的情况，因为采用了全表扫描的方式。\nindex（全索引扫描）：index 和 all 差不多，只不过 index 对索引表进行全扫描，这样做的好处是不再需要对数据进行排序，但是开销依然很大。所以，要尽量避免全表扫描和全索引扫描。\nrange（索引范围扫描）：range 表示采用了索引范围扫描，一般在 where 子句中使用 &lt; 、&gt;、in、between 等关键词，只检索给定范围的行，属于范围查找。从这一级别开始，索引的作用会越来越明显，因此我们需要尽量让 SQL 查询可以使用到 range 这一级别及以上的 type 访问方式。\nref（非唯一索引扫描）：ref 类型表示采用了非唯一索引，或者是唯一索引的非唯一性前缀，返回数据返回可能是多条。因为虽然使用了索引，但该索引列的值并不唯一，有重复。这样即使使用索引快速查找到了第一条数据，仍然不能停止，要进行目标值附近的小范围扫描。但它的好处是它并不需要扫全表，因为索引是有序的，即便有重复值，也是在一个非常小的范围内扫描。\neq_ref（唯一索引扫描）：eq_ref 类型是使用主键或唯一索引时产生的访问方式，通常使用在多表联查中。比如，对两张表进行联查，关联条件是两张表的 user_id 相等，且 user_id 是唯一索引，那么使用 EXPLAIN 进行执行计划查看的时候，type 就会显示 eq_ref。\nconst（结果只有一条的主键或唯一索引扫描）：const 类型表示使用了主键或者唯一索引与常量值进行比较，比如 select name from product where id&#x3D;1。需要说明的是 const 类型和 eq_ref 都使用了主键或唯一索引，不过这两个类型有所区别，const 是与常量进行比较，查询效率会更快，而 eq_ref 通常用于多表联查中。\n\nextra 显示的结果，这里说几个重要的参考指标：\n\nUsing filesort ：当查询语句中包含 group by 操作，而且无法利用索引完成排序操作的时候， 这时不得不选择相应的排序算法进行，甚至可能会通过文件排序，效率是很低的，所以要避免这种问题的出现。\nUsing temporary：使了用临时表保存中间结果，MySQL 在对查询结果排序时使用临时表，常见于排序 order by 和分组查询 group by。效率低，要避免这种问题的出现。\nUsing index：所需数据只需在索引即可全部获得，不须要再到表中取数据，也就是使用了覆盖索引，避免了回表操作，效率不错。\n\n# 给你张表，发现查询速度很慢，你有那些解决方案\n分析查询语句：使用EXPLAIN命令分析SQL执行计划，找出慢查询的原因，比如是否使用了全表扫描，是否存在索引未被利用的情况等，并根据相应情况对索引进行适当修改。\n创建或优化索引：根据查询条件创建合适的索引，特别是经常用于WHERE子句的字段、Orderby 排序的字段、Join 连表查询的字典、 group by的字段，并且如果查询中经常涉及多个字段，考虑创建联合索引，使用联合索引要符合最左匹配原则，不然会索引失效\n**避免索引失效：**比如不要用左模糊匹配、函数计算、表达式计算等等。\n查询优化：避免使用SELECT *，只查询真正需要的列；使用覆盖索引，即索引包含所有查询的字段；联表查询最好要以小表驱动大表，并且被驱动表的字段要有索引，当然最好通过冗余字段的设计，避免联表查询。\n**分页优化：**针对 limit n,y 深分页的查询优化，可以把Limit查询转换成某个位置的查询：select * from tb_sku where id&gt;20000 limit 10，该方案适用于主键自增的表，\n优化数据库表：如果单表的数据超过了千万级别，考虑是否需要将大表拆分为小表，减轻单个表的查询压力。也可以将字段多的表分解成多个表，有些字段使用频率高，有些低，数据量大时，会由于使用频率低的存在而变慢，可以考虑分开。\n使用缓存技术：引入缓存层，如Redis，存储热点数据和频繁查询的结果，但是要考虑缓存一致性的问题，对于读请求会选择旁路缓存策略，对于写请求会选择先更新 db，再删除缓存的策略。\n\n# 如果Explain用到的索引不正确的话，有什么办法干预吗？可以使用 force index，强制走索引。\n比如：\n12345678EXPLAIN SELECT     productName, buyPriceFROM    products FORCE INDEX (idx_buyprice)WHERE    buyPrice BETWEEN 10 AND 80ORDER BY buyPrice; \n\n输出：\n\n# 架构# MySQL主从复制了解吗MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。\n这个过程一般是异步的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。\n\nMySQL 集群的主从复制过程梳理成 3 个阶段：\n\n写入 Binlog：主库写 binlog 日志，提交事务，并更新本地存储数据。\n同步 Binlog：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。\n回放 Binlog：回放 binlog，并更新存储引擎中的数据。\n\n具体详细过程如下：\n\nMySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。\n从库会创建一个专门的 I&#x2F;O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。\n从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。\n\n在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。\n# 主从延迟都有什么处理方法？强制走主库方案：对于大事务或资源密集型操作，直接在主库上执行，避免从库的额外延迟。\n# 分表和分库是什么？有什么区别？\n\n分库是一种水平扩展数据库的技术，将数据根据一定规则划分到多个独立的数据库中。每个数据库只负责存储部分数据，实现了数据的拆分和分布式存储。分库主要是为了解决并发连接过多，单机 mysql扛不住的问题。\n分表指的是将单个数据库中的表拆分成多个表，每个表只负责存储一部分数据。这种数据的垂直划分能够提高查询效率，减轻单个表的压力。分表主要是为了解决单表数据量太大，导致查询性能下降的问题。\n\n分库与分表可以从：垂直（纵向）和 水平（横向）两种纬度进行拆分。下边我们以经典的订单业务举例，看看如何拆分。\n\n\n垂直分库：一般来说按照业务和功能的维度进行拆分，将不同业务数据分别放到不同的数据库中，核心理念 专库专用。按业务类型对数据分离，剥离为多个数据库，像订单、支付、会员、积分相关等表放在对应的订单库、支付库、会员库、积分库。垂直分库把一个库的压力分摊到多个库，提升了一些数据库性能，但并没有解决由于单表数据量过大导致的性能问题，所以就需要配合后边的分表来解决。\n垂直分表：针对业务上字段比较多的大表进行的，一般是把业务宽表中比较独立的字段，或者不常用的字段拆分到单独的数据表中，是一种大表拆小表的模式。数据库它是以行为单位将数据加载到内存中，这样拆分以后核心表大多是访问频率较高的字段，而且字段长度也都较短，因而可以加载更多数据到内存中，减少磁盘IO，增加索引查询的命中率，进一步提升数据库性能。\n水平分库：是把同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，以此实现水平扩展，是一种常见的提升数据库性能的方式。这种方案往往能解决单库存储量及性能瓶颈问题，但由于同一个表被分配在不同的数据库中，数据的访问需要额外的路由工作，因此系统的复杂度也被提升了。\n水平分表：是在同一个数据库内，把一张大数据量的表按一定规则，切分成多个结构完全相同表，而每个表只存原表的一部分数据。水平分表尽管拆分了表，但子表都还是在同一个数据库实例中，只是解决了单一表数据量过大的问题，并没有将拆分后的表分散到不同的机器上，还在竞争同一个物理机的CPU、内存、网络IO等。要想进一步提升性能，就需要将拆分后的表分散到不同的数据库中，达到分布式的效果。\n\n\n","slug":"mysql/mysql面试题","date":"2024-12-03T18:18:23.000Z","categories_index":"八股","tags_index":"精选,mysql","author_index":"Ivan"},{"id":"5cf82fc4574698c841009c5b69950563","title":"spring","content":"# Spring# Spring# 说一下你对 Spring 的理解\nSpring框架核心特性包括：\n\nIoC容器：Spring通过控制反转实现了对象的创建和对象间的依赖关系管理。开发者只需要定义好Bean及其依赖关系，Spring容器负责创建和组装这些对象。\nAOP：面向切面编程，允许开发者定义横切关注点，例如事务管理、安全控制等，独立于业务逻辑的代码。通过AOP，可以将这些关注点模块化，提高代码的可维护性和可重用性。\n事务管理：Spring提供了一致的事务管理接口，支持声明式和编程式事务。开发者可以轻松地进行事务管理，而无需关心具体的事务API。\nMVC框架：Spring MVC是一个基于Servlet API构建的Web框架，采用了模型-视图-控制器（MVC）架构。它支持灵活的URL到页面控制器的映射，以及多种视图技术。\n\n# Spring IoC和AOP 介绍一下Spring IoC和AOP 区别：\n\nIoC：即控制反转的意思，它是一种创建和获取对象的技术思想，依赖注入(DI)是实现这种技术的一种方式。传统开发过程中，我们需要通过new关键字来创建对象。使用IoC思想开发方式的话，我们不通过new关键字创建对象，而是通过IoC容器来帮我们实例化对象。 通过IoC的方式，可以大大降低对象之间的耦合度。\nAOP：是面向切面编程，能够将那些与业务无关，却为业务模块所共同调用的逻辑封装起来，以减少系统的重复代码，降低模块间的耦合度。Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 Cglib 生成一个被代理对象的子类来作为代理。\n\n在 Spring 框架中，IOC 和 AOP 结合使用，可以更好地实现代码的模块化和分层管理。例如：\n\n通过 IOC 容器管理对象的依赖关系，然后通过 AOP 将横切关注点统一切入到需要的业务逻辑中。\n使用 IOC 容器管理 Service 层和 DAO 层的依赖关系，然后通过 AOP 在 Service 层实现事务管理、日志记录等横切功能，使得业务逻辑更加清晰和可维护。\n\n# Spring的aop介绍一下Spring AOP是Spring框架中的一个重要模块，用于实现面向切面编程。\n我们知道，Java 就是一门面向对象编程的语言，在 OOP 中最小的单元就是“Class 对象”，但是在 AOP 中最小的单元是“切面”。一个“切面”可以包含很多种类型和对象，对它们进行模块化管理，例如事务管理。\n在面向切面编程的思想里面，把功能分为两种\n\n核心业务：登陆、注册、增、删、改、查、都叫核心业务\n周边功能：日志、事务管理这些次要的为周边业务\n\n在面向切面编程中，核心业务功能和周边功能是分别独立进行开发，两者不是耦合的，然后把切面功能和核心业务功能 “编织” 在一起，这就叫AOP。\nAOP能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。\n在 AOP 中有以下几个概念：\n\nAspectJ：切面，只是一个概念，没有具体的接口或类与之对应，是 Join point，Advice 和 Pointcut 的一个统称。\nJoin point：连接点，指程序执行过程中的一个点，例如方法调用、异常处理等。在 Spring AOP 中，仅支持方法级别的连接点。\nAdvice：通知，即我们定义的一个切面中的横切逻辑，有“around”，“before”和“after”三种类型。在很多的 AOP 实现框架中，Advice 通常作为一个拦截器，也可以包含许多个拦截器作为一条链路围绕着 Join point 进行处理。\nPointcut：切点，用于匹配连接点，一个 AspectJ 中包含哪些 Join point 需要由 Pointcut 进行筛选。\nIntroduction：引介，让一个切面可以声明被通知的对象实现任何他们没有真正实现的额外的接口。例如可以让一个代理对象代理两个目标类。\nWeaving：织入，在有了连接点、切点、通知以及切面，如何将它们应用到程序中呢？没错，就是织入，在切点的引导下，将通知逻辑插入到目标方法上，使得我们的通知逻辑在方法调用时得以执行。\nAOP proxy：AOP 代理，指在 AOP 实现框架中实现切面协议的对象。在 Spring AOP 中有两种代理，分别是 JDK 动态代理和 CGLIB 动态代理。\nTarget object：目标对象，就是被代理的对象。\n\nSpring AOP 是基于 JDK 动态代理和 Cglib 提升实现的，两种代理方式都属于运行时的一个方式，所以它没有编译时的一个处理，那么因此 Spring 是通过 Java 代码实现的。\n# IOC和AOP是通过什么机制来实现的?\n\n\n\n\n\n\n\n\nSpring IOC 实现机制\n\n反射：Spring IOC容器利用Java的反射机制动态地加载类、创建对象实例及调用对象方法，反射允许在运行时检查类、方法、属性等信息，从而实现灵活的对象实例化和管理。\n依赖注入：IOC的核心概念是依赖注入，即容器负责管理应用程序组件之间的依赖关系。Spring通过构造函数注入、属性注入或方法注入，将组件之间的依赖关系描述在配置文件中或使用注解。\n设计模式 - 工厂模式：Spring IOC容器通常采用工厂模式来管理对象的创建和生命周期。容器作为工厂负责实例化Bean并管理它们的生命周期，将Bean的实例化过程交给容器来管理。\n容器实现：Spring IOC容器是实现IOC的核心，通常使用BeanFactory或ApplicationContext来管理Bean。BeanFactory是IOC容器的基本形式，提供基本的IOC功能；ApplicationContext是BeanFactory的扩展，并提供更多企业级功能。\n\n\n\n\n\n\n\n\n\n\nSpring AOP 实现机制\nSpring AOP的实现依赖于动态代理技术。动态代理是在运行时动态生成代理对象，而不是在编译时。它允许开发者在运行时指定要代理的接口和行为，从而实现在不修改源码的情况下增强方法的功能。\nSpring AOP支持两种动态代理：\n\n基于JDK的动态代理：使用java.lang.reflect.Proxy类和java.lang.reflect.InvocationHandler接口实现。这种方式需要代理的类实现一个或多个接口。\n基于CGLIB的动态代理：当被代理的类没有实现接口时，Spring会使用CGLIB库生成一个被代理类的子类作为代理。CGLIB（Code Generation Library）是一个第三方代码生成库，通过继承方式实现代理。\n\n# 怎么理解SpringIoc？IOC：Inversion Of Control，即控制反转，是一种设计思想。在传统的 Java SE 程序设计中，我们直接在对象内部通过 new 的方式来创建对象，是程序主动创建依赖对象；\n\n而在Spring程序设计中，IOC 是有专门的容器去控制对象。\n\n所谓控制就是对象的创建、初始化、销毁。\n\n创建对象：原来是 new 一个，现在是由 Spring 容器创建。\n初始化对象：原来是对象自己通过构造器或者 setter 方法给依赖的对象赋值，现在是由 Spring 容器自动注入。\n销毁对象：原来是直接给对象赋值 null 或做一些销毁操作，现在是 Spring 容器管理生命周期负责销毁对象。\n\n总结：IOC 解决了繁琐的对象生命周期的操作，解耦了我们的代码。所谓反转：其实是反转的控制权，前面提到是由 Spring 来控制对象的生命周期，那么对象的控制就完全脱离了我们的控制，控制权交给了 Spring 。这个反转是指：我们由对象的控制者变成了 IOC 的被动控制者。\n# 依赖倒置，依赖注入，控制反转分别是什么？\n控制反转：“控制”指的是对程序执行流程的控制，而“反转”指的是在没有使用框架之前，程序员自己控制整个程序的执行。在使用框架之后，整个程序的执行流程通过框架来控制。流程的控制权从程序员“反转”给了框架。\n依赖注入：依赖注入和控制反转恰恰相反，它是一种具体的编码技巧。我们不通过 new 的方式在类内部创建依赖类的对象，而是将依赖的类对象在外部创建好之后，通过构造函数、函数参数等方式传递（或注入）给类来使用。\n依赖倒置：这条原则跟控制反转有点类似，主要用来指导框架层面的设计。高层模块不依赖低层模块，它们共同依赖同一个抽象。抽象不要依赖具体实现细节，具体实现细节依赖抽象。\n\n# 如果让你设计一个SpringIoc，你觉得会从哪些方面考虑这个设计？\nBean的生命周期管理：需要设计Bean的创建、初始化、销毁等生命周期管理机制，可以考虑使用工厂模式和单例模式来实现。\n依赖注入：需要实现依赖注入的功能，包括属性注入、构造函数注入、方法注入等，可以考虑使用反射机制和XML配置文件来实现。\nBean的作用域：需要支持多种Bean作用域，比如单例、原型、会话、请求等，可以考虑使用Map来存储不同作用域的Bean实例。\nAOP功能的支持：需要支持AOP功能，可以考虑使用动态代理机制和切面编程来实现。\n异常处理：需要考虑异常处理机制，包括Bean创建异常、依赖注入异常等，可以考虑使用try-catch机制来处理异常。\n配置文件加载：需要支持从不同的配置文件中加载Bean的相关信息，可以考虑使用XML、注解或者Java配置类来实现。\n\n# SpringAOP主要想解决什么问题它的目的是对于面向对象思维的一种补充，而不是像引入命令式、函数式编程思维让他顺应另一种开发场景。在我个人的理解下AOP更像是一种对于不支持多继承的弥补，除开对象的主要特征（我更喜欢叫“强共性”）被抽象为了一条继承链路，对于一些“弱共性”，AOP可以统一对他们进行抽象和集中处理。\n举一个简单的例子，打印日志。需要打印日志可能是许多对象的一个共性，这在企业级开发中十分常见，但是日志的打印并不反应这个对象的主要共性。而日志的打印又是一个具体的内容，它并不抽象，所以它的工作也不可以用接口来完成。而如果利用继承，打印日志的工作又横跨继承树下面的多个同级子节点，强行侵入到继承树内进行归纳会干扰这些强共性的区分。\n这时候，我们就需要AOP了。AOP首先在一个Aspect（切面）里定义了一些Advice（增强），其中包含具体实现的代码，同时整理了切入点，切入点的粒度是方法。最后，我们将这些Advice织入到对象的方法上，形成了最后执行方法时面对的完整方法。\n\n# SpringAOP的原理了解吗Spring AOP的实现依赖于动态代理技术。动态代理是在运行时动态生成代理对象，而不是在编译时。它允许开发者在运行时指定要代理的接口和行为，从而实现在不修改源码的情况下增强方法的功能。\nSpring AOP支持两种动态代理：\n\n基于JDK的动态代理：使用java.lang.reflect.Proxy类和java.lang.reflect.InvocationHandler接口实现。这种方式需要代理的类实现一个或多个接口。\n基于CGLIB的动态代理：当被代理的类没有实现接口时，Spring会使用CGLIB库生成一个被代理类的子类作为代理。CGLIB（Code Generation Library）是一个第三方代码生成库，通过继承方式实现代理。\n\n# 动态代理是什么？Java的动态代理是一种在运行时动态创建代理对象的机制，主要用于在不修改原始类的情况下对方法调用进行拦截和增强。\nJava动态代理主要分为两种类型：\n\n基于接口的代理（JDK动态代理）： 这种类型的代理要求目标对象必须实现至少一个接口。Java动态代理会创建一个实现了相同接口的代理类，然后在运行时动态生成该类的实例。这种代理的实现核心是java.lang.reflect.Proxy类和java.lang.reflect.InvocationHandler接口。每一个动态代理类都必须实现InvocationHandler接口，并且每个代理类的实例都关联到一个handler。当通过代理对象调用一个方法时，这个方法的调用会被转发为由InvocationHandler接口的invoke()方法来进行调用。\n\n基于类的代理（CGLIB动态代理）： CGLIB（Code Generation Library）是一个强大的高性能的代码生成库，它可以在运行时动态生成一个目标类的子类。CGLIB代理不需要目标类实现接口，而是通过继承的方式创建代理类。因此，如果目标对象没有实现任何接口，可以使用CGLIB来创建动态代理。\n\n\n# 动态代理和静态代理的区别代理是一种常用的设计模式，目的是：为其他对象提供一个代理以控制对某个对象的访问，将两个类的关系解耦。代理类和委托类都要实现相同的接口，因为代理真正调用的是委托类的方法。\n区别：\n\n静态代理：由程序员创建或者是由特定工具创建，在代码编译时就确定了被代理的类是一个静态代理。静态代理通常只代理一个类；\n动态代理：在代码运行期间，运用反射机制动态创建生成。动态代理代理的是一个接口下的多个实现类。\n\n# AOP实现有哪些注解？常用的注解包括：\n\n@Aspect：用于定义切面，标注在切面类上。\n@Pointcut：定义切点，标注在方法上，用于指定连接点。\n@Before：在方法执行之前执行通知。\n@After：在方法执行之后执行通知。\n@Around：在方法执行前后都执行通知。\n@AfterReturning：在方法执行后返回结果后执行通知。\n@AfterThrowing：在方法抛出异常后执行通知。\n@Advice：通用的通知类型，可以替代@Before、@After等。\n\n# 什么是反射？有哪些使用场景？反射具有以下特性：\n\n运行时类信息访问：反射机制允许程序在运行时获取类的完整结构信息，包括类名、包名、父类、实现的接口、构造函数、方法和字段等。\n动态对象创建：可以使用反射API动态地创建对象实例，即使在编译时不知道具体的类名。这是通过Class类的newInstance()方法或Constructor对象的newInstance()方法实现的。\n动态方法调用：可以在运行时动态地调用对象的方法，包括私有方法。这通过Method类的invoke()方法实现，允许你传入对象实例和参数值来执行方法。\n访问和修改字段值：反射还允许程序在运行时访问和修改对象的字段值，即使是私有的。这是通过Field类的get()和set()方法完成的。\n\n\nJava反射机制在spring框架中，很多地方都用到了反射，让我们来看看Spring的IoC和AOP是如何使用反射技术的。\n\n\n\n\n\n\n\n\n\n1、Spring框架的依赖注入（DI）和控制反转（IoC）\nSpring 使用反射来实现其核心特性：依赖注入。\n在Spring中，开发者可以通过XML配置文件或者基于注解的方式声明组件之间的依赖关系。当应用程序启动时，Spring容器会扫描这些配置或注解，然后利用反射来实例化Bean（即Java对象），并根据配置自动装配它们的依赖。\n例如，当一个Service类需要依赖另一个DAO类时，开发者可以在Service类中使用@Autowired注解，而无需自己编写创建DAO实例的代码。Spring容器会在运行时解析这个注解，通过反射找到对应的DAO类，实例化它，并将其注入到Service类中。这样不仅降低了组件之间的耦合度，也极大地增强了代码的可维护性和可测试性。\n\n\n\n\n\n\n\n\n\n2、动态代理的实现\n在需要对现有类的方法调用进行拦截、记录日志、权限控制或是事务管理等场景中，反射结合动态代理技术被广泛应用。\n一个典型的例子是Spring AOP（面向切面编程）的实现。Spring AOP允许开发者定义切面（Aspect），这些切面可以横切关注点（如日志记录、事务管理），并将其插入到业务逻辑中，而不需要修改业务逻辑代码。\n例如，为了给所有的服务层方法添加日志记录功能，可以定义一个切面，在这个切面中，Spring会使用JDK动态代理或CGLIB（如果目标类没有实现接口）来创建目标类的代理对象。这个代理对象在调用任何方法前或后，都会执行切面中定义的代码逻辑（如记录日志），而这一切都是在运行时通过反射来动态构建和执行的，无需硬编码到每个方法调用中。\n这两个例子展示了反射机制如何在实际工程中促进松耦合、高内聚的设计，以及如何提供动态、灵活的编程能力，特别是在框架层面和解决跨切面问题时。\n# spring是如何解决循环依赖的？循环依赖指的是两个类中的属性相互依赖对方：例如 A 类中有 B 属性，B 类中有 A属性，从而形成了一个依赖闭环，如下图。\n\n循环依赖问题在Spring中主要有三种情况：\n\n第一种：通过构造方法进行依赖注入时产生的循环依赖问题。\n第二种：通过setter方法进行依赖注入且是在多例（原型）模式下产生的循环依赖问题。\n第三种：通过setter方法进行依赖注入且是在单例模式下产生的循环依赖问题。\n\n只有【第三种方式】的循环依赖问题被 Spring 解决了，其他两种方式在遇到循环依赖问题时，Spring都会产生异常。\nSpring 解决单例模式下的setter循环依赖问题的主要方式是通过三级缓存解决循环依赖。三级缓存指的是 Spring 在创建 Bean 的过程中，通过三级缓存来缓存正在创建的 Bean，以及已经创建完成的 Bean 实例。具体步骤如下：\n\n实例化 Bean：Spring 在实例化 Bean 时，会先创建一个空的 Bean 对象，并将其放入一级缓存中。\n属性赋值：Spring 开始对 Bean 进行属性赋值，如果发现循环依赖，会将当前 Bean 对象提前暴露给后续需要依赖的 Bean（通过提前暴露的方式解决循环依赖）。\n初始化 Bean：完成属性赋值后，Spring 将 Bean 进行初始化，并将其放入二级缓存中。\n注入依赖：Spring 继续对 Bean 进行依赖注入，如果发现循环依赖，会从二级缓存中获取已经完成初始化的 Bean 实例。\n\n通过三级缓存的机制，Spring 能够在处理循环依赖时，确保及时暴露正在创建的 Bean 对象，并能够正确地注入已经初始化的 Bean 实例，从而解决循环依赖问题，保证应用程序的正常运行。\n# spring三级缓存的数据结构是什么？都是 Map类型的缓存，比如Map {k:name; v:bean}。\n\n一级缓存（Singleton Objects）：这是一个Map类型的缓存，存储的是已经完全初始化好的bean，即完全准备好可以使用的bean实例。键是bean的名称，值是bean的实例。这个缓存在DefaultSingletonBeanRegistry类中的singletonObjects属性中。\n二级缓存（Early Singleton Objects）：这同样是一个Map类型的缓存，存储的是早期的bean引用，即已经实例化但还未完全初始化的bean。这些bean已经被实例化，但是可能还没有进行属性注入等操作。这个缓存在DefaultSingletonBeanRegistry类中的earlySingletonObjects属性中。\n三级缓存（Singleton Factories）：这也是一个Map类型的缓存，存储的是ObjectFactory对象，这些对象可以生成早期的bean引用。当一个bean正在创建过程中，如果它被其他bean依赖，那么这个正在创建的bean就会通过这个ObjectFactory来创建一个早期引用，从而解决循环依赖的问题。这个缓存在DefaultSingletonBeanRegistry类中的singletonFactories属性中。\n\n# spring框架中都用到了哪些设计模式\n工厂设计模式 : Spring使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。\n代理设计模式 : Spring AOP 功能的实现。\n单例设计模式 : Spring 中的 Bean 默认都是单例的。\n模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。\n包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。\n观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。\n适配器模式 :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。\n\n# spring 常用注解有什么？\n\n\n\n\n\n\n\n\n@Autowired 注解\n@Autowired：主要用于自动装配bean。当Spring容器 (opens new window)中存在与要注入的属性类型匹配的bean时，它会自动将bean注入到属性中。就跟我们new 对象一样。\n用法很简单，如下示例代码：\n1234567891011@Componentpublic class MyService &#123;&#125;@Componentpublic class MyController &#123;    @Autowired    private MyService myService;&#125;\n\n在上面的示例代码中，MyController类中的myService属性被@Autowired注解标记，Spring会自动将MyService类型的bean注入到myService属性中。\n\n\n\n\n\n\n\n\n\n@Component\n这个注解用于标记一个类作为Spring的bean。当一个类被@Component注解标记时，Spring会将其实例化为一个bean，并将其添加到Spring容器中。在上面讲解@Autowired的时候也看到了，示例代码：\n123@Componentpublic class MyComponent &#123;&#125;\n\n在上面的示例代码中，MyComponent类被@Component注解标记，Spring会将其实例化为一个bean，并将其添加到Spring容器中。\n\n\n\n\n\n\n\n\n\n@Configuration\n@Configuration，注解用于标记一个类作为Spring的配置类。配置类可以包含@Bean注解的方法，用于定义和配置bean，作为全局配置。示例代码：\n123456789@Configurationpublic class MyConfiguration &#123;    @Bean    public MyBean myBean() &#123;        return new MyBean();    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n@Bean\n@Bean注解用于标记一个方法作为Spring的bean工厂方法。当一个方法被@Bean注解标记时，Spring会将该方法的返回值作为一个bean，并将其添加到Spring容器中，如果自定义配置，经常用到这个注解。\n12345678910@Configurationpublic class MyConfiguration &#123;    @Bean    public MyBean myBean() &#123;        return new MyBean();    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n@Service\n@Service，这个注解用于标记一个类作为服务层的组件。它是@Component注解的特例，用于标记服务层的bean，一般标记在业务service的实现类。\n1234@Servicepublic class MyServiceImpl &#123;&#125;\n\n\n\n\n\n\n\n\n\n\n@Repository\n@Repository注解用于标记一个类作为数据访问层的组件。它也是@Component注解的特例，用于标记数据访问层的bean。这个注解很容易被忽略，导致数据库无法访问。\n1234@Repositorypublic class MyRepository &#123;&#125;\n\n在上面的示例代码中，MyRepository类被@Repository注解标记，Spring会将其实例化为一个bean，并将其添加到Spring容器中。\n\n\n\n\n\n\n\n\n\n@Controller\n@Controller注解用于标记一个类作为控制层的组件。它也是@Component注解的特例，用于标记控制层的bean。这是MVC结构的另一个部分，加在控制层\n1234@Controllerpublic class MyController &#123;&#125;\n\n在上面的示例代码中，MyController类被@Controller注解标记，Spring会将其实例化为一个bean，并将其添加到Spring容器中。\n# Spring的事务什么情况下会失效？Spring Boot通过Spring框架的事务管理模块来支持事务操作。事务管理在Spring Boot中通常是通过 @Transactional 注解来实现的。事务可能会失效的一些常见情况包括:\n\n未捕获异常: 如果一个事务方法中发生了未捕获的异常，并且异常未被处理或传播到事务边界之外，那么事务会失效，所有的数据库操作会回滚。\n非受检异常: 默认情况下，Spring对非受检异常（RuntimeException或其子类）进行回滚处理，这意味着当事务方法中抛出这些异常时，事务会回滚。\n事务传播属性设置不当: 如果在多个事务之间存在事务嵌套，且事务传播属性配置不正确，可能导致事务失效。特别是在方法内部调用有 @Transactional 注解的方法时要特别注意。\n多数据源的事务管理: 如果在使用多数据源时，事务管理没有正确配置或者存在多个 @Transactional 注解时，可能会导致事务失效。\n跨方法调用事务问题: 如果一个事务方法内部调用另一个方法，而这个被调用的方法没有 @Transactional 注解，这种情况下外层事务可能会失效。\n事务在非公开方法中失效: 如果 @Transactional 注解标注在私有方法上或者非 public 方法上，事务也会失效。\n\n# Spring的事务，使用this调用是否生效？不能生效。\n因为Spring事务是通过代理对象来控制的，只有通过代理对象的方法调用才会应用事务管理的相关规则。当使用this直接调用时，是绕过了Spring的代理机制，因此不会应用事务设置。\n# Bean的生命周期说一下？\n\nSpring启动，查找并加载需要被Spring管理的bean，进行Bean的实例化\nBean实例化后对将Bean的引入和值注入到Bean的属性中\n如果Bean实现了BeanNameAware接口的话，Spring将Bean的Id传递给setBeanName()方法\n如果Bean实现了BeanFactoryAware接口的话，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入\n如果Bean实现了ApplicationContextAware接口的话，Spring将调用Bean的setApplicationContext()方法，将bean所在应用上下文引用传入进来。\n如果Bean实现了BeanPostProcessor接口，Spring就将调用他们的postProcessBeforeInitialization()方法。\n如果Bean 实现了InitializingBean接口，Spring将调用他们的afterPropertiesSet()方法。类似的，如果bean使用init-method声明了初始化方法，该方法也会被调用\n如果Bean 实现了BeanPostProcessor接口，Spring就将调用他们的postProcessAfterInitialization()方法。\n此时，Bean已经准备就绪，可以被应用程序使用了。他们将一直驻留在应用上下文中，直到应用上下文被销毁。\n如果bean实现了DisposableBean接口，Spring将调用它的destory()接口方法，同样，如果bean使用了destory-method 声明销毁方法，该方法也会被调用。\n\n# Bean是否单例？Spring 中的 Bean 默认都是单例的。\n就是说，每个Bean的实例只会被创建一次，并且会被存储在Spring容器的缓存中，以便在后续的请求中重复使用。这种单例模式可以提高应用程序的性能和内存效率。\n但是，Spring也支持将Bean设置为多例模式，即每次请求都会创建一个新的Bean实例。要将Bean设置为多例模式，可以在Bean定义中通过设置scope属性为”prototype”来实现。\n需要注意的是，虽然Spring的默认行为是将Bean设置为单例模式，但在一些情况下，使用多例模式是更为合适的，例如在创建状态不可变的Bean或有状态Bean时。此外，需要注意的是，如果Bean单例是有状态的，那么在使用时需要考虑线程安全性问题。\n# Bean的单例和非单例，生命周期是否一样不一样的，Spring Bean 的生命周期完全由 IoC 容器控制。Spring 只帮我们管理单例模式 Bean 的完整生命周期，对于 prototype 的 Bean，Spring 在创建好交给使用者之后，则不会再管理后续的生命周期。\n# Spring bean的作用域有哪些？Spring框架中的Bean作用域（Scope）定义了Bean的生命周期和可见性。不同的作用域影响着Spring容器如何管理这些Bean的实例，包括它们如何被创建、如何被销毁以及它们是否可以被多个用户共享。\nSpring支持几种不同的作用域，以满足不同的应用场景需求。以下是一些主要的Bean作用域：\n\nSingleton（单例）：在整个应用程序中只存在一个 Bean 实例。默认作用域，Spring 容器中只会创建一个 Bean 实例，并在容器的整个生命周期中共享该实例。\nPrototype（原型）：每次请求时都会创建一个新的 Bean 实例。次从容器中获取该 Bean 时都会创建一个新实例，适用于状态非常瞬时的 Bean。\nRequest（请求）：每个 HTTP 请求都会创建一个新的 Bean 实例。仅在 Spring Web 应用程序中有效，每个 HTTP 请求都会创建一个新的 Bean 实例，适用于 Web 应用中需求局部性的 Bean。\nSession（会话）：Session 范围内只会创建一个 Bean 实例。该 Bean 实例在用户会话范围内共享，仅在 Spring Web 应用程序中有效，适用于与用户会话相关的 Bean。\nApplication：当前 ServletContext 中只存在一个 Bean 实例。仅在 Spring Web 应用程序中有效，该 Bean 实例在整个 ServletContext 范围内共享，适用于应用程序范围内共享的 Bean。\nWebSocket（Web套接字）：在 WebSocket 范围内只存在一个 Bean 实例。仅在支持 WebSocket 的应用程序中有效，该 Bean 实例在 WebSocket 会话范围内共享，适用于 WebSocket 会话范围内共享的 Bean。\nCustom scopes（自定义作用域）：Spring 允许开发者定义自定义的作用域，通过实现 Scope 接口来创建新的 Bean 作用域。\n\n在Spring配置文件中，可以通过标签的scope属性来指定Bean的作用域。例如：\n1&lt;bean id=&quot;myBean&quot; class=&quot;com.example.MyBeanClass&quot; scope=&quot;singleton&quot;/&gt;\n\n在Spring Boot或基于Java的配置中，可以通过@Scope注解来指定Bean的作用域。例如：\n12345@Bean  @Scope(&quot;prototype&quot;)  public MyBeanClass myBean() &#123;      return new MyBeanClass();  &#125;\n\n# Spring容器里存的是什么？在Spring容器中，存储的主要是Bean对象。\nBean是Spring框架中的基本组件，用于表示应用程序中的各种对象。当应用程序启动时，Spring容器会根据配置文件或注解的方式创建和管理这些Bean对象。Spring容器会负责创建、初始化、注入依赖以及销毁Bean对象。\n# 在Spring中，在bean加载&#x2F;销毁前后，如果想实现某些逻辑，可以怎么做在Spring框架中，如果你希望在Bean加载（即实例化、属性赋值、初始化等过程完成后）或销毁前后执行某些逻辑，你可以使用Spring的生命周期回调接口或注解。这些接口和注解允许你定义在Bean生命周期的关键点执行的代码。\n\n\n\n\n\n\n\n\n\n使用init-method和destroy-method\n在XML配置中，你可以通过init-method和destroy-method属性来指定Bean初始化后和销毁前需要调用的方法。\n12&lt;bean id=&quot;myBean&quot; class=&quot;com.example.MyBeanClass&quot;        init-method=&quot;init&quot; destroy-method=&quot;destroy&quot;/&gt;\n\n然后，在你的Bean类中实现这些方法：\n12345678910public class MyBeanClass &#123;        public void init() &#123;          // 初始化逻辑      &#125;        public void destroy() &#123;          // 销毁逻辑      &#125;  &#125;\n\n\n\n\n\n\n\n\n\n\n实现InitializingBean和DisposableBean接口\n你的Bean类可以实现org.springframework.beans.factory.InitializingBean和org.springframework.beans.factory.DisposableBean接口，并分别实现afterPropertiesSet和destroy方法。\n123456789101112131415import org.springframework.beans.factory.DisposableBean;  import org.springframework.beans.factory.InitializingBean;    public class MyBeanClass implements InitializingBean, DisposableBean &#123;        @Override      public void afterPropertiesSet() throws Exception &#123;          // 初始化逻辑      &#125;        @Override      public void destroy() throws Exception &#123;          // 销毁逻辑      &#125;  &#125;\n\n\n\n\n\n\n\n\n\n\n使用@PostConstruct和@PreDestroy注解\n123456789101112131415import javax.annotation.PostConstruct;  import javax.annotation.PreDestroy;    public class MyBeanClass &#123;        @PostConstruct      public void init() &#123;          // 初始化逻辑      &#125;        @PreDestroy      public void destroy() &#123;          // 销毁逻辑      &#125;  &#125;\n\n\n\n\n\n\n\n\n\n\n使用@Bean注解的initMethod和destroyMethod属性\n在基于Java的配置中，你还可以在@Bean注解中指定initMethod和destroyMethod属性。\n12345678@Configuration  public class AppConfig &#123;        @Bean(initMethod = &quot;init&quot;, destroyMethod = &quot;destroy&quot;)      public MyBeanClass myBean() &#123;          return new MyBeanClass();      &#125;  &#125;\n\n# Bean注入和xml注入最终得到了相同的效果，它们在底层是怎样做的\n\n\n\n\n\n\n\n\nXML 注入\n使用 XML 文件进行 Bean 注入时，Spring 在启动时会读取 XML 配置文件，以下是其底层步骤：\n\nBean 定义解析：Spring 容器通过 XmlBeanDefinitionReader 类解析 XML 配置文件，读取其中的 &lt;bean&gt; 标签以获取 Bean 的定义信息。\n注册 Bean 定义：解析后的 Bean 信息被注册到 BeanDefinitionRegistry（如 DefaultListableBeanFactory）中，包括 Bean 的类、作用域、依赖关系、初始化和销毁方法等。\n实例化和依赖注入：当应用程序请求某个 Bean 时，Spring 容器会根据已经注册的 Bean 定义：\n首先，使用反射机制创建该 Bean 的实例。\n然后，根据 Bean 定义中的配置，通过 setter 方法、构造函数或方法注入所需的依赖 Bean。\n\n\n\n\n\n\n\n\n\n\n\n\n注解注入\n使用注解进行 Bean 注入时，Spring 的处理过程如下：\n\n类路径扫描：当 Spring 容器启动时，它首先会进行类路径扫描，查找带有特定注解（如 @Component、@Service、@Repository 和 @Controller）的类。\n注册 Bean 定义：找到的类会被注册到 BeanDefinitionRegistry 中，Spring 容器将为其生成 Bean 定义信息。这通常通过 AnnotatedBeanDefinitionReader 类来实现。\n依赖注入：与 XML 注入类似，Spring 在实例化 Bean 时，也会检查字段上是否有 @Autowired、@Inject 或 @Resource 注解。如果有，Spring 会根据注解的信息进行依赖注入。\n\n尽管使用的方式不同，但 XML 注入和注解注入在底层的实现机制是相似的，主要体现在以下几个方面：\n\nBeanDefinition：无论是 XML 还是注解，最终都会生成 BeanDefinition 对象，并存储在同一个 BeanDefinitionRegistry 中。\n后处理器：\nSpring 提供了多个 Bean 后处理器（如 AutowiredAnnotationBeanPostProcessor），用于处理注解（如 @Autowired）的依赖注入。\n对于 XML，Spring 也有相应的后处理器来处理 XML 配置的依赖注入。\n\n\n依赖查找：在依赖注入时，Spring 容器会通过 ApplicationContext 中的 BeanFactory 方法来查找和注入依赖，无论是通过 XML 还是注解，都会调用类似的查找方法。\n\n# Spring给我们提供了很多扩展点，这些有了解吗？Spring框架提供了许多扩展点，使得开发者可以根据需求定制和扩展Spring的功能。以下是一些常用的扩展点：\n\nBeanFactoryPostProcessor：允许在Spring容器实例化bean之前修改bean的定义。常用于修改bean属性或改变bean的作用域。\nBeanPostProcessor：可以在bean实例化、配置以及初始化之后对其进行额外处理。常用于代理bean、修改bean属性等。\nPropertySource：用于定义不同的属性源，如文件、数据库等，以便在Spring应用中使用。\nImportSelector和ImportBeanDefinitionRegistrar：用于根据条件动态注册bean定义，实现配置类的模块化。\nSpring MVC中的HandlerInterceptor：用于拦截处理请求，可以在请求处理前、处理中和处理后执行特定逻辑。\nSpring MVC中的ControllerAdvice：用于全局处理控制器的异常、数据绑定和数据校验。\nSpring Boot的自动配置：通过创建自定义的自动配置类，可以实现对框架和第三方库的自动配置。\n自定义注解：创建自定义注解，用于实现特定功能或约定，如权限控制、日志记录等。\n\n# MVC分层介绍一下MVC全名是Model View Controller，是模型(model)－视图(view)－控制器(controller)的缩写，一种软件设计典范，用一种业务逻辑、数据、界面显示分离的方法组织代码，将业务逻辑聚集到一个部件里面，在改进和个性化定制界面及用户交互的同时，不需要重新编写业务逻辑。\n\n视图(view)： 为用户提供使用界面，与用户直接进行交互。\n模型(model)： 代表一个存取数据的对象或 JAVA POJO（Plain Old Java Object，简单java对象）。它也可以带有逻辑，主要用于承载数据，并对用户提交请求进行计算的模块。模型分为两类，一类称为数据承载 Bean，一类称为业务处理Bean。所谓数据承载 Bean 是指实体类（如：User类），专门为用户承载业务数据的；而业务处理 Bean 则是指Service 或 Dao 对象， 专门用于处理用户提交请求的。\n控制器(controller)： 用于将用户请求转发给相应的 Model 进行处理，并根据 Model 的计算结果向用户提供相应响应。它使视图与模型分离。\n\n\n流程步骤：\n\n用户通过View 页面向服务端提出请求，可以是表单请求、超链接请求、AJAX 请求等；\n服务端 Controller 控制器接收到请求后对请求进行解析，找到相应的Model，对用户请求进行处理Model 处理；\n将处理结果再交给 Controller（控制器其实只是起到了承上启下的作用）；\n根据处理结果找到要作为向客户端发回的响应View 页面，页面经渲染后发送给客户端。\n\n# 了解SpringMVC的处理流程吗？\nSpring MVC的工作流程如下：\n\n用户发送请求至前端控制器DispatcherServlet\nDispatcherServlet收到请求调用处理器映射器HandlerMapping。\n处理器映射器根据请求url找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。\nDispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作\n执行处理器Handler(Controller，也叫页面控制器)。\nHandler执行完成返回ModelAndView\nHandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet\nDispatcherServlet将ModelAndView传给ViewReslover视图解析器\nViewReslover解析后返回具体View\nDispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。\nDispatcherServlet响应用户。\n\n# Handlermapping 和 handleradapter有了解吗？HandlerMapping：\n\n作用：HandlerMapping负责将请求映射到处理器（Controller）。\n功能：根据请求的URL、请求参数等信息，找到处理请求的 Controller。\n类型：Spring提供了多种HandlerMapping实现，如BeanNameUrlHandlerMapping、RequestMappingHandlerMapping等。\n工作流程：根据请求信息确定要请求的处理器(Controller)。HandlerMapping可以根据URL、请求参数等规则确定对应的处理器。\n\nHandlerAdapter：\n\n作用：HandlerAdapter负责调用处理器(Controller)来处理请求。\n功能：处理器(Controller)可能有不同的接口类型（Controller接口、HttpRequestHandler接口等），HandlerAdapter根据处理器的类型来选择合适的方法来调用处理器。\n类型：Spring提供了多个HandlerAdapter实现，用于适配不同类型的处理器。\n工作流程：根据处理器的接口类型，选择相应的HandlerAdapter来调用处理器。\n\n工作流程：\n\n当客户端发送请求时，HandlerMapping根据请求信息找到对应的处理器(Controller)。\nHandlerAdapter根据处理器的类型选择合适的方法来调用处理器。\n处理器执行相应的业务逻辑，生成ModelAndView。\nHandlerAdapter将处理器的执行结果包装成ModelAndView。\n视图解析器根据ModelAndView找到对应的视图进行渲染。\n将渲染后的视图返回给客户端。\n\nHandlerMapping和HandlerAdapter协同工作，通过将请求映射到处理器，并调用处理器来处理请求，实现了请求处理的流程。它们的灵活性使得在Spring MVC中可以支持多种处理器和处理方式，提高了框架的扩展性和适应性。\n# SpringBoot# 为什么使用springboot\n简化开发：Spring Boot通过提供一系列的开箱即用的组件和自动配置，简化了项目的配置和开发过程，开发人员可以更专注于业务逻辑的实现，而不需要花费过多时间在繁琐的配置上。\n快速启动：Spring Boot提供了快速的应用程序启动方式，可通过内嵌的Tomcat、Jetty或Undertow等容器快速启动应用程序，无需额外的部署步骤，方便快捷。\n自动化配置：Spring Boot通过自动配置功能，根据项目中的依赖关系和约定俗成的规则来配置应用程序，减少了配置的复杂性，使开发者更容易实现应用的最佳实践。\n\n# SpringBoot比Spring好在哪里\nSpring Boot 提供了自动化配置，大大简化了项目的配置过程。通过约定优于配置的原则，很多常用的配置可以自动完成，开发者可以专注于业务逻辑的实现。\nSpring Boot 提供了快速的项目启动器，通过引入不同的 Starter，可以快速集成常用的框架和库（如数据库、消息队列、Web 开发等），极大地提高了开发效率。\nSpring Boot 默认集成了多种内嵌服务器（如Tomcat、Jetty、Undertow），无需额外配置，即可将应用打包成可执行的 JAR 文件，方便部署和运行。\n\n# SpringBoot用到哪些设计模式？\n代理模式：Spring 的 AOP 通过动态代理实现方法级别的切面增强，有静态和动态两种代理方式，采用动态代理方式。\n策略模式：Spring AOP 支持 JDK 和 Cglib 两种动态代理实现方式，通过策略接口和不同策略类，运行时动态选择，其创建一般通过工厂方法实现。\n装饰器模式：Spring 用 TransactionAwareCacheDecorator 解决缓存与数据库事务问题增加对事务的支持。\n单例模式：Spring Bean 默认是单例模式，通过单例注册表（如 HashMap）实现。\n简单工厂模式：Spring 中的 BeanFactory 是简单工厂模式的体现，通过工厂类方法获取 Bean 实例。\n工厂方法模式：Spring中的 FactoryBean 体现工厂方法模式，为不同产品提供不同工厂。\n观察者模式：Spring 观察者模式包含 Event 事件、Listener 监听者、Publisher 发送者，通过定义事件、监听器和发送者实现，观察者注册在 ApplicationContext 中，消息发送由 ApplicationEventMulticaster 完成。\n模板模式：Spring Bean 的创建过程涉及模板模式，体现扩展性，类似 Callback 回调实现方式。\n适配器模式：Spring MVC 中针对不同方式定义的 Controller，利用适配器模式统一函数定义，定义了统一接口 HandlerAdapter 及对应适配器类。\n\n# 怎么理解SpringBoot中的约定大于配置理解 Spring Boot 中的“约定大于配置”原则，可以从以下几个方面来解释：\n\n自动化配置：Spring Boot 提供了大量的自动化配置，通过分析项目的依赖和环境，自动配置应用程序的行为。开发者无需显式地配置每个细节，大部分常用的配置都已经预设好了。例如，Spring Boot 可以根据项目中引入的数据库依赖自动配置数据源。\n默认配置：Spring Boot 在没有明确配置的情况下，会使用合理的默认值来初始化应用程序。这种默认行为使得开发者可以专注于核心业务逻辑，而无需关心每个细节的配置。\n约定优于配置：Spring Boot 遵循了约定优于配置的设计哲学，即通过约定好的方式来提供默认行为，减少开发者需要做出的决策。例如，约定了项目结构、Bean 命名规范等，使得开发者可以更快地上手并保持团队间的一致性。\n\nSpring Boot 的“约定大于配置”原则是一种设计理念，通过减少配置和提供合理的默认值，使得开发者可以更快速地构建和部署应用程序，同时降低了入门门槛和维护成本。\nSpring Boot通过「自动化配置」和「起步依赖」实现了约定大于配置的特性。\n\n自动化配置：Spring Boot根据项目的依赖和环境自动配置应用程序，无需手动配置大量的XML或Java配置文件。例如，如果项目引入了Spring Web MVC依赖，Spring Boot会自动配置一个基本的Web应用程序上下文。\n起步依赖：Spring Boot提供了一系列起步依赖，这些依赖包含了常用的框架和功能，可以帮助开发者快速搭建项目。通过引入适合项目需求的起步依赖，开发者可以\n\n# SpringBoot的项目结构是怎么样的？一个正常的企业项目里一种通用的项目结构和代码层级划分的指导意见。按这《阿里巴巴Java开发手册》时本书上说的，一般分为如下几层：\n\n\n开放接口层：可直接封装 Service 接口暴露成 RPC 接口；通过 Web 封装成 http 接口；网关控制层等。\n\n终端显示层：各个端的模板渲染并执行显示的层。当前主要是 velocity 渲染，JS 渲染，JSP 渲染，移动端展示等。\n\nWeb 层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。\n\nService 层：相对具体的业务逻辑服务层。\n\nManager 层：通用业务处理层，它有如下特征\n\n1）对第三方平台封装的层，预处理返回结果及转化异常信息，适配上层接口。\n\n2）对 Service 层通用能力的下沉，如缓存方案、中间件通用处理。\n\n3）与 DAO 层交互，对多个 DAO 的组合复用。\n\nDAO 层：数据访问层，与底层 MySQL、Oracle、Hbase、OceanBase 等进行数据交互。\n\n第三方服务：包括其它部门 RPC 服务接口，基础平台，其它公司的 HTTP 接口，如淘宝开放平台、支付宝付款服务、高德地图服务等。\n\n外部接口：外部（应用）数据存储服务提供的接口，多见于数据迁移场景中。\n\n\n如果从一个用户访问一个网站的情况来看，对应着上面的项目代码结构来分析，可以贯穿整个代码分层：\n\n对应代码目录的流转逻辑就是：\n\n所以，以后每当我们拿到一个新的项目到手时，只要按照这个思路去看别人项目的代码，应该基本都是能理得顺的。\n# SpringBoot自动装配原理是什么？\n\n\n\n\n\n\n\n\n什么是自动装配？\nSpringBoot 的自动装配原理是基于Spring Framework的条件化配置和@EnableAutoConfiguration注解实现的。这种机制允许开发者在项目中引入相关的依赖，SpringBoot 将根据这些依赖自动配置应用程序的上下文和功能。\nSpringBoot 定义了一套接口规范，这套规范规定：SpringBoot 在启动时会扫描外部引用 jar 包中的META-INF&#x2F;spring.factories文件，将文件中配置的类型信息加载到 Spring 容器（此处涉及到 JVM 类加载机制与 Spring 的容器知识），并执行类中定义的各种操作。对于外部 jar 来说，只需要按照 SpringBoot 定义的标准，就能将自己的功能装置进 SpringBoot。\n通俗来讲，自动装配就是通过注解或一些简单的配置就可以在SpringBoot的帮助下开启和配置各种功能，比如数据库访问、Web开发。\n\n\n\n\n\n\n\n\n\nSpringBoot自动装配原理\n首先点进 @SpringBootApplication 注解的内部\n\n接下来将逐个解释这些注解的作用：\n\n@Target(&#123;ElementType.TYPE&#125;): 该注解指定了这个注解可以用来标记在类上。在这个特定的例子中，这表示该注解用于标记配置类。\n@Retention(RetentionPolicy.RUNTIME): 这个注解指定了注解的生命周期，即在运行时保留。这是因为 Spring Boot 在运行时扫描类路径上的注解来实现自动配置，所以这里使用了 RUNTIME 保留策略。\n@Documented: 该注解表示这个注解应该被包含在 Java 文档中。它是用于生成文档的标记，使开发者能够看到这个注解的相关信息。\n@Inherited: 这个注解指示一个被标注的类型是被继承的。在这个例子中，它表明这个注解可以被继承，如果一个类继承了带有这个注解的类，它也会继承这个注解。\n@SpringBootConfiguration: 这个注解表明这是一个 Spring Boot 配置类。如果点进这个注解内部会发现与标准的 @Configuration 没啥区别，只是为了表明这是一个专门用于 SpringBoot 的配置。\n@EnableAutoConfiguration: 这个注解是 Spring Boot 自动装配的核心。它告诉 Spring oot 启用自动配置机制，根据项目的依赖和配置自动配置应用程序的上下文。通过这个注解，SpringBoot 将尝试根据类路径上的依赖自动配置应用程序。\n@ComponentScan: 这个注解用于配置组件扫描的规则。在这里，它告诉 SpringBoot 在指定的包及其子包中查找组件，这些组件包括被注解的类、@Component 注解的类等。其中的 excludeFilters 参数用于指定排除哪些组件，这里使用了两个自定义的过滤器，分别是 TypeExcludeFilter 和 AutoConfigurationExcludeFilter。\n\n@EnableAutoConfiguration 这个注解是实现自动装配的核心注解\n\n\n@AutoConfigurationPackage，将项目src中main包下的所有组件注册到容器中，例如标注了Component注解的类等\n@Import({AutoConfigurationImportSelector.class})，是自动装配的核心，接下来分析一下这个注解\n\nAutoConfigurationImportSelector 是 Spring Boot 中一个重要的类，它实现了 ImportSelector 接口，用于实现自动配置的选择和导入。具体来说，它通过分析项目的类路径和条件来决定应该导入哪些自动配置类。\n代码太多，选取部分主要功能的代码：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware,\t\tResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered &#123;        // ... （其他方法和属性）  // 获取所有符合条件的类的全限定类名，例如RedisTemplate的全限定类名(org.springframework.data.redis.core.RedisTemplate;)，这些类需要被加载到 IoC 容器中。\t@Override\tpublic String[] selectImports(AnnotationMetadata annotationMetadata) &#123;\t\t// 扫描类路径上的 META-INF/spring.factories 文件，获取所有实现了 AutoConfiguration 接口的自动配置类\t\tList&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes);\t\t// 过滤掉不满足条件的自动配置类，比如一些自动装配类\t\tconfigurations = filter(configurations, annotationMetadata, attributes);\t\t// 排序自动配置类，根据 @AutoConfigureOrder 和 @AutoConfigureAfter/@AutoConfigureBefore 注解指定的顺序\t\tsort(configurations, annotationMetadata, attributes);\t\t// 将满足条件的自动配置类的类名数组返回，这些类将被导入到应用程序上下文中\t\treturn StringUtils.toStringArray(configurations);\t&#125;\t// ... （其他方法）\tprotected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123;\t\t// 获取自动配置类的候选列表，从 META-INF/spring.factories 文件中读取\t\t// 通过类加载器加载所有候选类\t\tList&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(),\t\t\t\tgetBeanClassLoader());\t\t// 过滤出实现了 AutoConfiguration 接口的自动配置类\t\tconfigurations = configurations.stream()\t\t\t\t.filter(this::isEnabled)\t\t\t\t.collect(Collectors.toList());\t\t// 对于 Spring Boot 1.x 版本，还需要添加 spring-boot-autoconfigure 包中的自动配置类\t\t// configurations.addAll(getAutoConfigEntry(getAutoConfigurationEntry(metadata)));\t\treturn configurations;\t&#125;\t// ... （其他方法）\tprotected List&lt;String&gt; filter(List&lt;String&gt; configurations, AnnotationMetadata metadata,\t\t\tAnnotationAttributes attributes) &#123;\t\t// 使用条件判断机制，过滤掉不满足条件的自动配置类\t\tconfigurations = configurations.stream()\t\t\t\t.filter(configuration -&gt; isConfigurationCandidate(configuration, metadata, attributes))\t\t\t\t.collect(Collectors.toList());\t\treturn configurations;\t&#125;\t// ... （其他方法）\tprotected void sort(List&lt;String&gt; configurations, AnnotationMetadata metadata,\t\t\tAnnotationAttributes attributes) &#123;\t\t// 根据 @AutoConfigureOrder 和 @AutoConfigureAfter/@AutoConfigureBefore 注解指定的顺序对自动配置类进行排序\t\tconfigurations.sort((o1, o2) -&gt; &#123;\t\t\tint i1 = getAutoConfigurationOrder(o1, metadata, attributes);\t\t\tint i2 = getAutoConfigurationOrder(o2, metadata, attributes);\t\t\treturn Integer.compare(i1, i2);\t\t&#125;);\t&#125;    \t// ... （其他方法）&#125;\n\n梳理一下，以下是AutoConfigurationImportSelector的主要工作：\n\n扫描类路径: 在应用程序启动时，AutoConfigurationImportSelector 会扫描类路径上的 META-INF/spring.factories 文件，这个文件中包含了各种 Spring 配置和扩展的定义。在这里，它会查找所有实现了 AutoConfiguration 接口的类,具体的实现为getCandidateConfigurations方法。\n\n条件判断: 对于每一个发现的自动配置类，AutoConfigurationImportSelector 会使用条件判断机制（通常是通过 @ConditionalOnXxx注解）来确定是否满足导入条件。这些条件可以是配置属性、类是否存在、Bean是否存在等等。\n\n根据条件导入自动配置类: 满足条件的自动配置类将被导入到应用程序的上下文中。这意味着它们会被实例化并应用于应用程序的配置。\n\n\n# 说几个启动器（starter)？\nspring-boot-starter-web：这是最常用的起步依赖之一，它包含了Spring MVC和Tomcat嵌入式服务器，用于快速构建Web应用程序。\nspring-boot-starter-security：提供了Spring Security的基本配置，帮助开发者快速实现应用的安全性，包括认证和授权功能。\nmybatis-spring-boot-starter：这个Starter是由MyBatis团队提供的，用于简化在Spring Boot应用中集成MyBatis的过程。它自动配置了MyBatis的相关组件，包括SqlSessionFactory、MapperScannerConfigurer等，使得开发者能够快速地开始使用MyBatis进行数据库操作。\nspring-boot-starter-data-jpa 或 spring-boot-starter-jdbc：如果使用的是Java Persistence API (JPA)进行数据库操作，那么应该使用spring-boot-starter-data-jpa。这个Starter包含了Hibernate等JPA实现以及数据库连接池等必要的库，可以让你轻松地与MySQL数据库进行交互。你需要在application.properties或application.yml中配置MySQL的连接信息。如果倾向于直接使用JDBC而不通过JPA，那么可以使用spring-boot-starter-jdbc，它提供了基本的JDBC支持。\nspring-boot-starter-data-redis：用于集成Redis缓存和数据存储服务。这个Starter包含了与Redis交互所需的客户端（默认是Jedis客户端，也可以配置为Lettuce客户端），以及Spring Data Redis的支持，使得在Spring Boot应用中使用Redis变得非常便捷。同样地，需要在配置文件中设置Redis服务器的连接详情。\nspring-boot-starter-test：包含了单元测试和集成测试所需的库，如JUnit, Spring Test, AssertJ等，便于进行测试驱动开发(TDD)。\n\n# 写过SpringBoot starter吗?\n\n\n\n\n\n\n\n\n步骤1: 创建Maven项目\n首先，需要创建一个新的Maven项目。在pom.xml中添加Spring Boot的starter parent和一些必要的依赖。例如：\n12345678910111213&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.7.0&lt;/version&gt;    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n\n\n\n\n\n\n\n\n\n步骤2: 添加自动配置\n在src&#x2F;main&#x2F;resources&#x2F;META-INF&#x2F;spring.factories中添加自动配置的元数据。例如：\n1org.springframework.boot.autoconfigure.EnableAutoConfiguration = com.example.starter.MyAutoConfiguration\n\n然后，创建MyAutoConfiguration类，该类需要@Configuration和@EnableConfigurationProperties注解。@EnableConfigurationProperties用于启用你定义的配置属性类。\n123456789101112@Configuration@EnableConfigurationProperties(MyProperties.class)public class MyAutoConfiguration &#123;    @Autowired    private MyProperties properties;    @Bean    public MyService myService() &#123;        return new MyServiceImpl(properties);    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n步骤3: 创建配置属性类\n创建一个配置属性类，使用@ConfigurationProperties注解来绑定配置文件中的属性。\n12345@ConfigurationProperties(prefix = &quot;my&quot;)public class MyProperties &#123;    private String name;    // getters and setters&#125;\n\n\n\n\n\n\n\n\n\n\n步骤4: 创建服务和控制器\n创建一个服务类和服务实现类，以及一个控制器来展示你的starter的功能。\n1234567891011121314151617181920212223242526272829303132@Servicepublic interface MyService &#123;    String getName();&#125;@Servicepublic class MyServiceImpl implements MyService &#123;    private final MyProperties properties;    public MyServiceImpl(MyProperties properties) &#123;        this.properties = properties;    &#125;    @Override    public String getName() &#123;        return properties.getName();    &#125;&#125;@RestControllerpublic class MyController &#123;    private final MyService myService;    public MyController(MyService myService) &#123;        this.myService = myService;    &#125;    @GetMapping(&quot;/name&quot;)    public String getName() &#123;        return myService.getName();    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n步骤5: 发布Starter\n将你的starter发布到Maven仓库，无论是私有的还是公共的，如Nexus或Maven Central。\n\n\n\n\n\n\n\n\n\n步骤6: 使用Starter\n在你的主应用的pom.xml中添加你的starter依赖，然后在application.yml或application.properties中配置你的属性。\n# SpringBoot里面有哪些重要的注解？还有一个配置相关的注解是哪个？Spring Boot 中一些常用的注解包括：\n\n@SpringBootApplication：用于标注主应用程序类，标识一个Spring Boot应用程序的入口点，同时启用自动配置和组件扫描。\n@Controller：标识控制器类，处理HTTP请求。\n@RestController：结合@Controller和@ResponseBody，返回RESTful风格的数据。\n@Service：标识服务类，通常用于标记业务逻辑层。\n@Repository：标识数据访问组件，通常用于标记数据访问层。\n@Component：通用的Spring组件注解，表示一个受Spring管理的组件。\n@Autowired：用于自动装配Spring Bean。\n@Value：用于注入配置属性值。\n@RequestMapping：用于映射HTTP请求路径到Controller的处理方法。\n@GetMapping、@PostMapping、@PutMapping、@DeleteMapping：简化@RequestMapping的GET、POST、PUT和DELETE请求。\n\n另外，一个与配置相关的重要注解是：\n\n@Configuration：用于指定一个类为配置类，其中定义的bean会被Spring容器管理。通常与@Bean配合使用，@Bean用于声明一个Bean实例，由Spring容器进行管理。\n\n# springboot怎么开启事务？在 Spring Boot 中开启事务非常简单，只需在服务层的方法上添加 @Transactional 注解即可。\n例如，假设我们有一个 UserService 接口，其中有一个保存用户的方法 saveUser()：\n123public interface UserService &#123;    void saveUser(User user);&#125;\n\n我们希望在这个方法中开启事务，只需在该方法上添加 @Transactional 注解，如下所示：\n1234567891011public class UserServiceImpl implements UserService &#123;    @Autowired    private UserRepository userRepository;    @Override    @Transactional    public void saveUser(User user) &#123;        userRepository.save(user);    &#125;&#125;\n\n这样，当调用 saveUser() 方法时，Spring 就会自动为该方法开启一个事务。如果方法执行成功，事务会自动提交；如果方法执行失败，事务会自动回滚。\n# Mybatis# 与传统的JDBC相比，MyBatis的优点？\n基于 SQL 语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任 何影响，SQL 写在 XML 里，解除 sql 与程序代码的耦合，便于统一管理；提供 XML 标签，支持编写动态 SQL 语句，并可重用。\n与 JDBC 相比，减少了 50%以上的代码量，消除了 JDBC 大量冗余的代码，不 需要手动开关连接；\n很好的与各种数据库兼容，因为 MyBatis 使用 JDBC 来连接数据库，所以只要 JDBC 支持的数据库 MyBatis 都支持。\n能够与 Spring 很好的集成，开发效率高\n提供映射标签，支持对象与数据库的 ORM 字段关系映射；提供对象关系映射 标签，支持对象关系组件维护。\n\n# 还记得JDBC连接数据库的步骤吗？使用Java JDBC连接数据库的一般步骤如下：\n\n加载数据库驱动程序：在使用JDBC连接数据库之前，需要加载相应的数据库驱动程序。可以通过 Class.forName(“com.mysql.jdbc.Driver”) 来加载MySQL数据库的驱动程序。不同数据库的驱动类名会有所不同。\n建立数据库连接：使用 DriverManager 类的 getConnection(url, username, password) 方法来连接数据库，其中url是数据库的连接字符串（包括数据库类型、主机、端口等）、username是数据库用户名，password是密码。\n创建 Statement 对象：通过 Connection 对象的 createStatement() 方法创建一个 Statement 对象，用于执行 SQL 查询或更新操作。\n执行 SQL 查询或更新操作：使用 Statement 对象的 executeQuery(sql) 方法来执行 SELECT 查询操作，或者使用 executeUpdate(sql) 方法来执行 INSERT、UPDATE 或 DELETE 操作。\n处理查询结果：如果是 SELECT 查询操作，通过 ResultSet 对象来处理查询结果。可以使用 ResultSet 的 next() 方法遍历查询结果集，然后通过 getXXX() 方法获取各个字段的值。\n关闭连接：在完成数据库操作后，需要逐级关闭数据库连接相关对象，即先关闭 ResultSet，再关闭 Statement，最后关闭 Connection。\n\n以下是一个简单的示例代码：\n123456789101112131415161718192021222324252627282930313233import java.sql.*;public class Main &#123;    public static void main(String[] args) &#123;        try &#123;            // 加载数据库驱动程序            Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;);            // 建立数据库连接            Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/mydatabase&quot;, &quot;username&quot;, &quot;password&quot;);            // 创建 Statement 对象            Statement statement = connection.createStatement();            // 执行 SQL 查询            ResultSet resultSet = statement.executeQuery(&quot;SELECT * FROM mytable&quot;);            // 处理查询结果            while (resultSet.next()) &#123;              // 处理每一行数据            &#125;            // 关闭资源            resultSet.close();            statement.close();            connection.close();        &#125; catch (ClassNotFoundException e) &#123;            e.printStackTrace();        &#125; catch (SQLException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n请注意，在实际应用中，需要进行异常处理以确保资源的正确释放，以及使用 try-with-resources 来简化代码和确保资源的及时关闭。\n# 如果项目中要用到原生的mybatis去查询，该怎样写？步骤概述：\n\n配置MyBatis： 在项目中配置MyBatis的数据源、SQL映射文件等。\n创建实体类： 创建用于映射数据库表的实体类。\n编写SQL映射文件： 创建XML文件，定义SQL语句和映射关系。\n编写DAO接口： 创建DAO接口，定义数据库操作的方法。\n编写具体的SQL查询语句： 在DAO接口中定义查询方法，并在XML文件中编写对应的SQL语句。\n调用查询方法： 在服务层或控制层调用DAO接口中的方法进行查询。\n\n详细步骤：\n\n配置MyBatis： 在配置文件中配置数据源、MyBatis的Mapper文件位置等信息。\n创建实体类： 创建与数据库表对应的实体类，字段名和类型需与数据库表保持一致。\n\n123456public class User &#123;    private Long id;    private String username;    private String email;    // Getters and setters&#125;\n\n\n编写SQL映射文件： 在resources目录下创建XML文件，定义SQL语句和映射关系。\n\n123456&lt;!-- userMapper.xml --&gt;&lt;mapper namespace=&quot;com.example.dao.UserMapper&quot;&gt;    &lt;select id=&quot;selectUserById&quot; resultType=&quot;com.example.model.User&quot;&gt;        SELECT * FROM users WHERE id = #&#123;id&#125;    &lt;/select&gt;&lt;/mapper&gt;\n\n\n编写DAO接口： 创建DAO接口，定义查询方法。\n\n123public interface UserMapper &#123;    User selectUserById(Long id);&#125;\n\n\n编写具体的SQL查询语句： 在XML文件中编写对应的SQL语句。\n调用查询方法： 在服务层或控制层中调用DAO接口中的方法进行查询。\n\n12// 在Service层中调用User user = userMapper.selectUserById(1);\n\n通过以上步骤，你可以利用原生的MyBatis框架来进行数据库查询操作。请确保配置正确、SQL语句准确并与数据库字段匹配，以确保查询的准确性和高效性。\n# Mybatis里的 # 和 $ 的区别？\nMybatis 在处理 #{} 时，会创建预编译的 SQL 语句，将 SQL 中的 #{} 替换为 ? 号，在执行 SQL 时会为预编译 SQL 中的占位符（?）赋值，调用 PreparedStatement 的 set 方法来赋值，预编译的 SQL 语句执行效率高，并且可以防止SQL 注入，提供更高的安全性，适合传递参数值。\nMybatis 在处理 ${} 时，只是创建普通的 SQL 语句，然后在执行 SQL 语句时 MyBatis 将参数直接拼入到 SQL 里，不能防止 SQL 注入，因为参数直接拼接到 SQL 语句中，如果参数未经过验证、过滤，可能会导致安全问题。\n\n# MybatisPlus和Mybatis的区别？MybatisPlus是一个基于MyBatis的增强工具库，旨在简化开发并提高效率。以下是MybatisPlus和MyBatis之间的一些主要区别：\n\nCRUD操作：MybatisPlus通过继承BaseMapper接口，提供了一系列内置的快捷方法，使得CRUD操作更加简单，无需编写重复的SQL语句。\n代码生成器：MybatisPlus提供了代码生成器功能，可以根据数据库表结构自动生成实体类、Mapper接口以及XML映射文件，减少了手动编写的工作量。\n通用方法封装：MybatisPlus封装了许多常用的方法，如条件构造器、排序、分页查询等，简化了开发过程，提高了开发效率。\n分页插件：MybatisPlus内置了分页插件，支持各种数据库的分页查询，开发者可以轻松实现分页功能，而在传统的MyBatis中，需要开发者自己手动实现分页逻辑。\n多租户支持：MybatisPlus提供了多租户的支持，可以轻松实现多租户数据隔离的功能。\n注解支持：MybatisPlus引入了更多的注解支持，使得开发者可以通过注解来配置实体与数据库表之间的映射关系，减少了XML配置文件的编写。\n\n# MyBatis运用了哪些常见的设计模式？\n建造者模式（Builder），如：SqlSessionFactoryBuilder、XMLConfigBuilder、XMLMapperBuilder、XMLStatementBuilder、CacheBuilder等；\n工厂模式，如：SqlSessionFactory、ObjectFactory、MapperProxyFactory；\n单例模式，例如ErrorContext和LogFactory；\n代理模式，Mybatis实现的核心，比如MapperProxy、ConnectionLogger，用的jdk的动态代理；还有executor.loader包使用了cglib或者javassist达到延迟加载的效果；\n组合模式，例如SqlNode和各个子类ChooseSqlNode等；\n模板方法模式，例如BaseExecutor和SimpleExecutor，还有BaseTypeHandler和所有的子类例如IntegerTypeHandler；\n适配器模式，例如Log的Mybatis接口和它对jdbc、log4j等各种日志框架的适配实现；\n装饰者模式，例如Cache包中的cache.decorators子包中等各个装饰者的实现；\n迭代器模式，例如迭代器模式PropertyTokenizer；\n\n# SpringCloud# 了解SpringCloud吗，说一下他和SpringBoot的区别Spring Boot是用于构建单个Spring应用的框架，而Spring Cloud则是用于构建分布式系统中的微服务架构的工具，Spring Cloud提供了服务注册与发现、负载均衡、断路器、网关等功能。\n两者可以结合使用，通过Spring Boot构建微服务应用，然后用Spring Cloud来实现微服务架构中的各种功能。\n# 用过哪些微服务组件？\n微服务常用的组件：\n\n注册中心：注册中心是微服务架构最核心的组件。它起到的作用是对新节点的注册与状态维护，解决了「如何发现新节点以及检查各节点的运行状态的问题」。微服务节点在启动时会将自己的服务名称、IP、端口等信息在注册中心登记，注册中心会定时检查该节点的运行状态。注册中心通常会采用心跳机制最大程度保证已登记过的服务节点都是可用的。\n负载均衡：负载均衡解决了「如何发现服务及负载均衡如何实现的问题」，通常微服务在互相调用时，并不是直接通过IP、端口进行访问调用。而是先通过服务名在注册中心查询该服务拥有哪些节点，注册中心将该服务可用节点列表返回给服务调用者，这个过程叫服务发现，因服务高可用的要求，服务调用者会接收到多个节点，必须要从中进行选择。因此服务调用者一端必须内置负载均衡器，通过负载均衡策略选择合适的节点发起实质性的通信请求。\n服务通信：服务通信组件解决了「服务间如何进行消息通信的问题」，服务间通信采用轻量级协议，通常是HTTP RESTful风格。但因为RESTful风格过于灵活，必须加以约束，通常应用时对其封装。例如在SpringCloud中就提供了Feign和RestTemplate两种技术屏蔽底层的实现细节，所有开发者都是基于封装后统一的SDK进行开发，有利于团队间的相互合作。\n配置中心：配置中心主要解决了「如何集中管理各节点配置文件的问题」，在微服务架构下，所有的微服务节点都包含自己的各种配置文件，如jdbc配置、自定义配置、环境配置、运行参数配置等。要知道有的微服务可能可能有几十个节点，如果将这些配置文件分散存储在节点上，发生配置更改就需要逐个节点调整，将给运维人员带来巨大的压力。配置中心便由此而生，通过部署配置中心服务器，将各节点配置文件从服务中剥离，集中转存到配置中心。一般配置中心都有UI界面，方便实现大规模集群配置调整。\n集中式日志管理：集中式日志主要是解决了「如何收集各节点日志并统一管理的问题」。微服务架构默认将应用日志分别保存在部署节点上，当需要对日志数据和操作数据进行数据分析和数据统计时，必须收集所有节点的日志数据。那么怎么高效收集所有节点的日志数据呢？业内常见的方案有ELK、EFK。通过搭建独立的日志收集系统，定时抓取各节点增量日志形成有效的统计报表，为统计和分析提供数据支撑。\n分布式链路追踪：分布式链路追踪解决了「如何直观的了解各节点间的调用链路的问题」。系统中一个复杂的业务流程，可能会出现连续调用多个微服务，我们需要了解完整的业务逻辑涉及的每个微服务的运行状态，通过可视化链路图展现，可以帮助开发人员快速分析系统瓶颈及出错的服务。\n服务保护：服务保护主要是解决了「如何对系统进行链路保护，避免服务雪崩的问题」。在业务运行时，微服务间互相调用支撑，如果某个微服务出现高延迟导致线程池满载，或是业务处理失败。这里就需要引入服务保护组件来实现高延迟服务的快速降级，避免系统崩溃。\n\nSpringCloud Alibaba实现的微服务架构：\n\n\nSpringCloud Alibaba中使用Alibaba Nacos组件实现注册中心，Nacos提供了一组简单易用的特性集，可快速实现动态服务发现、服务配置、服务元数据及流量管理。\nSpringCloud Alibaba 使用Nacos服务端均衡实现负载均衡，与Ribbon在调用端负载不同，Nacos是在服务发现的同时利用负载均衡返回服务节点数据。\nSpringCloud Alibaba 使用Netflix Feign和Alibaba Dubbo组件来实现服务通行，前者与SpringCloud采用了相同的方案，后者则是对自家的RPC 框架Dubbo也给予支持，为服务间通信提供另一种选择。\nSpringCloud Alibaba 在API服务网关组件中，使用与SpringCloud相同的组件，即：SpringCloud Gateway。\nSpringCloud Alibaba在配置中心组件中使用Nacos内置配置中心，Nacos内置的配置中心，可将配置信息存储保存在指定数据库中\nSpringCloud Alibaba在原有的ELK方案外，还可以使用阿里云日志服务（LOG）实现日志集中式管理。\nSpringCloud Alibaba在分布式链路组件中采用与SpringCloud相同的方案，即：Sleuth&#x2F;Zipkin Server。\nSpringCloud Alibaba使用Alibaba Sentinel实现系统保护，Sentinel不仅功能更强大，实现系统保护比Hystrix更优雅，而且还拥有更好的UI界面。\n\n# 负载均衡有哪些算法？\n简单轮询：将请求按顺序分发给后端服务器上，不关心服务器当前的状态，比如后端服务器的性能、当前的负载。\n加权轮询：根据服务器自身的性能给服务器设置不同的权重，将请求按顺序和权重分发给后端服务器，可以让性能高的机器处理更多的请求\n简单随机：将请求随机分发给后端服务器上，请求越多，各个服务器接收到的请求越平均\n加权随机：根据服务器自身的性能给服务器设置不同的权重，将请求按各个服务器的权重随机分发给后端服务器\n一致性哈希：根据请求的客户端 ip、或请求参数通过哈希算法得到一个数值，利用该数值取模映射出对应的后端服务器，这样能保证同一个客户端或相同参数的请求每次都使用同一台服务器\n最小活跃数：统计每台服务器上当前正在处理的请求数，也就是请求活跃数，将请求分发给活跃数最少的后台服务器\n\n# 如何实现一直均衡给一个用户？可以通过「一致性哈希算法」来实现，根据请求的客户端 ip、或请求参数通过哈希算法得到一个数值，利用该数值取模映射出对应的后端服务器，这样能保证同一个客户端或相同参数的请求每次都使用同一台服务器。\n# 介绍一下服务熔断服务熔断是应对微服务雪崩效应的一种链路保护机制，类似股市、保险丝。\n比如说，微服务之间的数据交互是通过远程调用来完成的。服务A调用服务，服务B调用服务c，某一时间链路上对服务C的调用响应时间过长或者服务C不可用，随着时间的增长，对服务C的调用也越来越多，然后服务C崩溃了，但是链路调用还在，对服务B的调用也在持续增多，然后服务B崩溃，随之A也崩溃，导致雪崩效应。\n服务熔断是应对雪崩效应的一种微服务链路保护机制。例如在高压电路中，如果某个地方的电压过高，熔断器就会熔断，对电路进行保护。同样，在微服务架构中，熔断机制也是起着类似的作用。当调用链路的某个微服务不可用或者响应时间太长时，会进行服务熔断，不再有该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后，恢复调用链路。\n所以，服务熔断的作用类似于我们家用的保险丝，当某服务出现不可用或响应超时的情况时，为了防止整个系统出现雪崩，暂时停止对该服务的调用。\n在Spring Cloud框架里，熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内20次调用失败，就会启动熔断机制。\n# 介绍一下服务降级服务降级一般是指在服务器压力剧增的时候，根据实际业务使用情况以及流量，对一些服务和页面有策略的不处理或者用一种简单的方式进行处理，从而释放服务器资源的资源以保证核心业务的正常高效运行。\n服务器的资源是有限的，而请求是无限的。在用户使用即并发高峰期，会影响整体服务的性能，严重的话会导致宕机，以至于某些重要服务不可用。故高峰期为了保证核心功能服务的可用性，就需要对某些服务降级处理。可以理解为舍小保大\n服务降级是从整个系统的负荷情况出发和考虑的，对某些负荷会比较高的情况，为了预防某些功能（业务场景）出现负荷过载或者响应慢的情况，在其内部暂时舍弃对一些非核心的接口和数据的请求，而直接返回一个提前准备好的fallback（退路）错误处理信息。这样，虽然提供的是一个有损的服务，但却保证了整个系统的稳定性和可用性。\n\n","slug":"框架/spring/spring面试题","date":"2024-12-03T18:12:44.000Z","categories_index":"八股","tags_index":"精选,spring","author_index":"Ivan"},{"id":"564790740ba698a5ef60f23f00c2b931","title":"jvm","content":"# Java虚拟机# 内存模型# JVM的内存模型介绍一下根据 JVM8 规范，JVM 运行时内存共分为虚拟机栈、堆、元空间、程序计数器、本地方法栈五个部分。还有一部分内存叫直接内存，属于操作系统的本地内存，也是可以直接操作的。\n\nJVM的内存结构主要分为以下几个部分：\n\n元空间：元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。\nJava 虚拟机栈：每个线程有一个私有的栈，随着线程的创建而创建。栈里面存着的是一种叫“栈帧”的东西，每个方法会创建一个栈帧，栈帧中存放了局部变量表（基本数据类型和对象引用）、操作数栈、方法出口等信息。栈的大小可以固定也可以动态扩展。\n本地方法栈：与虚拟机栈类似，区别是虚拟机栈执行Java方法，本地方法站执行native方法。在虚拟机规范中对本地方法栈中方法使用的语言、使用方法与数据结构没有强制规定，因此虚拟机可以自由实现它。\n程序计数器：程序计数器可以看成是当前线程所执行的字节码指令的行号指示器。在任何一个确定的时刻，一个处理器（对于多内核来说是一个内核）都只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要一个独立的程序计数器，我们称这类内存区域为“线程私有”内存。\n堆内存：堆内存是 JVM 所有线程共享的部分，在虚拟机启动的时候就已经创建。所有的对象和数组都在堆上进行分配。这部分空间可通过 GC 进行回收。当申请不到空间时会抛出 OutOfMemoryError。堆是JVM内存占用最大，管理最复杂的一个区域。其唯一的用途就是存放对象实例：所有的对象实例及数组都在对上进行分配。jdk1.8后，字符串常量池从永久代中剥离出来，存放在队中。\n直接内存：直接内存并不是虚拟机运行时数据区的一部分，也不是Java 虚拟机规范中定义的内存区域。在JDK1.4 中新加入了NIO(New Input&#x2F;Output)类，引入了一种基于通道(Channel)与缓冲区（Buffer）的I&#x2F;O 方式，它可以使用native 函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。\n\n# JVM内存模型里的堆和栈有什么区别？\n用途：栈主要用于存储局部变量、方法调用的参数、方法返回地址以及一些临时数据。每当一个方法被调用，一个栈帧（stack frame）就会在栈中创建，用于存储该方法的信息，当方法执行完毕，栈帧也会被移除。堆用于存储对象的实例（包括类的实例和数组）。当你使用new关键字创建一个对象时，对象的实例就会在堆上分配空间。\n生命周期：栈中的数据具有确定的生命周期，当一个方法调用结束时，其对应的栈帧就会被销毁，栈中存储的局部变量也会随之消失。堆中的对象生命周期不确定，对象会在垃圾回收机制（Garbage Collection, GC）检测到对象不再被引用时才被回收。\n存取速度：栈的存取速度通常比堆快，因为栈遵循先进后出（LIFO, Last In First Out）的原则，操作简单快速。堆的存取速度相对较慢，因为对象在堆上的分配和回收需要更多的时间，而且垃圾回收机制的运行也会影响性能。\n存储空间：栈的空间相对较小，且固定，由操作系统管理。当栈溢出时，通常是因为递归过深或局部变量过大。堆的空间较大，动态扩展，由JVM管理。堆溢出通常是由于创建了太多的大对象或未能及时回收不再使用的对象。\n可见性：栈中的数据对线程是私有的，每个线程有自己的栈空间。堆中的数据对线程是共享的，所有线程都可以访问堆上的对象。\n\n# 栈中存的到底是指针还是对象？在JVM内存模型中，栈（Stack）主要用于管理线程的局部变量和方法调用的上下文，而堆（Heap）则是用于存储所有类的实例和数组。\n当我们在栈中讨论“存储”时，实际上指的是存储基本类型的数据（如int, double等）和对象的引用，而不是对象本身。\n这里的关键点是，栈中存储的不是对象，而是对象的引用。也就是说，当你在方法中声明一个对象，比如MyObject obj = new MyObject();，这里的obj实际上是一个存储在栈上的引用，指向堆中实际的对象实例。这个引用是一个固定大小的数据（例如在64位系统上是8字节），它指向堆中分配给对象的内存区域。\n# 堆分为哪几部分呢？Java堆（Heap）是Java虚拟机（JVM）中内存管理的一个重要区域，主要用于存放对象实例和数组。随着JVM的发展和不同垃圾收集器的实现，堆的具体划分可能会有所不同，但通常可以分为以下几个部分：\n\n\n新生代（Young Generation）:新生代分为Eden Space和Survivor Space。在Eden Space中， 大多数新创建的对象首先存放在这里。Eden区相对较小，当Eden区满时，会触发一次Minor GC（新生代垃圾回收）。在Survivor Spaces中，通常分为两个相等大小的区域，称为S0（Survivor 0）和S1（Survivor 1）。在每次Minor GC后，存活下来的对象会被移动到其中一个Survivor空间，以继续它们的生命周期。这两个区域轮流充当对象的中转站，帮助区分短暂存活的对象和长期存活的对象。\n老年代（Old Generation&#x2F;Tenured Generation）:存放过一次或多次Minor GC仍存活的对象会被移动到老年代。老年代中的对象生命周期较长，因此Major GC（也称为Full GC，涉及老年代的垃圾回收）发生的频率相对较低，但其执行时间通常比Minor GC长。老年代的空间通常比新生代大，以存储更多的长期存活对象。\n元空间（Metaspace）:从Java 8开始，永久代（Permanent Generation）被元空间取代，用于存储类的元数据信息，如类的结构信息（如字段、方法信息等）。元空间并不在Java堆中，而是使用本地内存，这解决了永久代容易出现的内存溢出问题。\n大对象区（Large Object Space &#x2F; Humongous Objects）:在某些JVM实现中（如G1垃圾收集器），为大对象分配了专门的区域，称为大对象区或Humongous Objects区域。大对象是指需要大量连续内存空间的对象，如大数组。这类对象直接分配在老年代，以避免因频繁的年轻代晋升而导致的内存碎片化问题。\n\n# 程序计数器的作用，为什么是私有的？Java程序是支持多线程一起运行的，多个线程一起运行的时候cpu会有一个调动器组件给它们分配时间片，比如说会给线程1分给一个时间片，它在时间片内如果它的代码没有执行完，它就会把线程1的状态执行一个暂存，切换到线程2去，执行线程2的代码，等线程2的代码执行到了一定程度，线程2的时间片用完了，再切换回来，再继续执行线程1剩余部分的代码。\n我们考虑一下，如果在线程切换的过程中，下一条指令执行到哪里了，是不是还是会用到我们的程序计数器啊。每个线程都有自己的程序计数器，因为它们各自执行的代码的指令地址是不一样的呀，所以每个线程都应该有自己的程序计数器。\n# 方法区中的方法的执行过程？当程序中通过对象或类直接调用某个方法时，主要包括以下几个步骤：\n\n解析方法调用：JVM会根据方法的符号引用找到实际的方法地址（如果之前没有解析过的话）。\n栈帧创建：在调用一个方法前，JVM会在当前线程的Java虚拟机栈中为该方法分配一个新的栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。\n执行方法：执行方法内的字节码指令，涉及的操作可能包括局部变量的读写、操作数栈的操作、跳转控制、对象创建、方法调用等。\n返回处理：方法执行完毕后，可能会返回一个结果给调用者，并清理当前栈帧，恢复调用者的执行环境。\n\n# 方法区中还有哪些东西？《深入理解Java虚拟机》书中对方法区（Method Area）存储内容描述如下：它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。\n\n类信息：包括类的结构信息、类的访问修饰符、父类与接口等信息。\n常量池：存储类和接口中的常量，包括字面值常量、符号引用，以及运行时常量池。\n静态变量：存储类的静态变量，这些变量在类初始化的时候被赋值。\n方法字节码：存储类的方法字节码，即编译后的代码。\n符号引用：存储类和方法的符号引用，是一种直接引用不同于直接引用的引用类型。\n运行时常量池：存储着在类文件中的常量池数据，在类加载后在方法区生成该运行时常量池。\n常量池缓存：用于提升类加载的效率，将常用的常量缓存起来方便使用。\n\n# String保存在哪里呢？String 保存在字符串常量池中，不同于其他对象，它的值是不可变的，且可以被多个引用共享。\n# String s &#x3D; new String（“abc”）执行过程中分别对应哪些内存区域？首先，我们看到这个代码中有一个new关键字，我们知道new指令是创建一个类的实例对象并完成加载初始化的，因此这个字符串对象是在运行期才能确定的，创建的字符串对象是在堆内存上。\n其次，在String的构造方法中传递了一个字符串abc，由于这里的abc是被final修饰的属性，所以它是一个字符串常量。在首次构建这个对象时，JVM拿字面量”abc”去字符串常量池试图获取其对应String对象的引用。于是在堆中创建了一个”abc”的String对象，并将其引用保存到字符串常量池中，然后返回；\n所以，如果abc这个字符串常量不存在，则创建两个对象，分别是abc这个字符串常量，以及new String这个实例对象。如果abc这字符串常量存在，则只会创建一个对象。\n# 引用类型有哪些？有什么区别？引用类型主要分为强软弱虚四种：\n\n强引用指的就是代码中普遍存在的赋值方式，比如A a &#x3D; new A()这种。强引用关联的对象，永远不会被GC回收。\n软引用可以用SoftReference来描述，指的是那些有用但是不是必须要的对象。系统在发生内存溢出前会对这类引用的对象进行回收。\n弱引用可以用WeakReference来描述，他的强度比软引用更低一点，弱引用的对象下一次GC的时候一定会被回收，而不管内存是否足够。\n虚引用也被称作幻影引用，是最弱的引用关系，可以用PhantomReference来描述，他必须和ReferenceQueue一起使用，同样的当发生GC的时候，虚引用也会被回收。可以用虚引用来管理堆外内存。\n\n# 弱引用了解吗?举例说明在哪里可以用?Java中的弱引用是一种引用类型，它不会阻止一个对象被垃圾回收。\n在Java中，弱引用是通过Java.lang.ref.WeakReference类实现的。弱引用的一个主要用途是创建非强制性的对象引用，这些引用可以在内存压力大时被垃圾回收器清理，从而避免内存泄露。\n弱引用的使用场景：\n\n缓存系统：弱引用常用于实现缓存，特别是当希望缓存项能够在内存压力下自动释放时。如果缓存的大小不受控制，可能会导致内存溢出。使用弱引用来维护缓存，可以让JVM在需要更多内存时自动清理这些缓存对象。\n对象池：在对象池中，弱引用可以用来管理那些暂时不使用的对象。当对象不再被强引用时，它们可以被垃圾回收，释放内存。\n避免内存泄露：当一个对象不应该被长期引用时，使用弱引用可以防止该对象被意外地保留，从而避免潜在的内存泄露。\n\n示例代码：\n假设我们有一个缓存系统，我们使用弱引用来维护缓存中的对象：\n123456789101112131415161718192021222324import Java.lang.ref.WeakReference;import Java.util.HashMap;import Java.util.Map;public class CacheExample &#123;    private Map&lt;String, WeakReference&lt;MyHeavyObject&gt;&gt; cache = new HashMap&lt;&gt;();    public MyHeavyObject get(String key) &#123;        WeakReference&lt;MyHeavyObject&gt; ref = cache.get(key);        if (ref != null) &#123;            return ref.get();        &#125; else &#123;            MyHeavyObject obj = new MyHeavyObject();            cache.put(key, new WeakReference&lt;&gt;(obj));            return obj;        &#125;    &#125;    // 假设MyHeavyObject是一个占用大量内存的对象    private static class MyHeavyObject &#123;        private byte[] largeData = new byte[1024 * 1024 * 10]; // 10MB data    &#125;&#125;\n\n在这个例子中，使用WeakReference来存储MyHeavyObject实例，当内存压力增大时，垃圾回收器可以自由地回收这些对象，而不会影响缓存的正常运行。\n如果一个对象被垃圾回收，下次尝试从缓存中获取时，get()方法会返回null，这时我们可以重新创建对象并将其放入缓存中。因此，使用弱引用时要注意，一旦对象被垃圾回收，通过弱引用获取的对象可能会变为null，因此在使用前通常需要检查这一点。\n# 内存泄漏和内存溢出的理解？内存泄露：内存泄漏是指程序在运行过程中不再使用的对象仍然被引用，而无法被垃圾收集器回收，从而导致可用内存逐渐减少。虽然在Java中，垃圾回收机制会自动回收不再使用的对象，但如果有对象仍被不再使用的引用持有，垃圾收集器无法回收这些内存，最终可能导致程序的内存使用不断增加。\n内存泄露常见原因：\n\n静态集合：使用静态数据结构（如HashMap或ArrayList）存储对象，且未清理。\n事件监听：未取消对事件源的监听，导致对象持续被引用。\n线程：未停止的线程可能持有对象引用，无法被回收。\n\n内存溢出：内存溢出是指Java虚拟机（JVM）在申请内存时，无法找到足够的内存，最终引发OutOfMemoryError。这通常发生在堆内存不足以存放新创建的对象时。\n内存溢出常见原因：\n\n大量对象创建：程序中不断创建大量对象，超出JVM堆的限制。\n持久引用：大型数据结构（如缓存、集合等）长时间持有对象引用，导致内存累积。\n递归调用：深度递归导致栈溢出。\n\n# jvm 内存结构有哪几种内存溢出的情况？\n堆内存溢出：当出现Java.lang.OutOfMemoryError:Java heap space异常时，就是堆内存溢出了。原因是代码中可能存在大对象分配，或者发生了内存泄露，导致在多次GC之后，还是无法找到一块足够大的内存容纳当前对象。\n栈溢出：如果我们写一段程序不断的进行递归调用，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM 实际会抛出 StackOverFlowError；当然，如果 JVM 试图去扩展栈空间的的时候失败，则会抛出 OutOfMemoryError。\n元空间溢出：元空间的溢出，系统会抛出Java.lang.OutOfMemoryError: Metaspace。出现这个异常的问题的原因是系统的代码非常多或引用的第三方包非常多或者通过动态代码生成类加载等方法，导致元空间的内存占用很大。\n直接内存内存溢出：在使用ByteBuffer中的allocateDirect()的时候会用到，很多JavaNIO(像netty)的框架中被封装为其他的方法，出现该问题时会抛出Java.lang.OutOfMemoryError: Direct buffer memory异常。\n\n# 有具体的内存泄漏和内存溢出的例子么请举例及解决方案?\n\n\n\n\n\n\n\n\n1、静态属性导致内存泄露\n会导致内存泄露的一种情况就是大量使用static静态变量。在Java中，静态属性的生命周期通常伴随着应用整个生命周期（除非ClassLoader符合垃圾回收的条件）。下面来看一个具体的会导致内存泄露的实例：\n1234567891011121314public class StaticTest &#123;    public static List&lt;Double&gt; list = new ArrayList&lt;&gt;();    public void populateList() &#123;        for (int i = 0; i &lt; 10000000; i++) &#123;            list.add(Math.random());        &#125;        Log.info(&quot;Debug Point 2&quot;);    &#125;    public static void main(String[] args) &#123;        Log.info(&quot;Debug Point 1&quot;);        new StaticTest().populateList();        Log.info(&quot;Debug Point 3&quot;);    &#125;&#125;\n\n如果监控内存堆内存的变化，会发现在打印Point1和Point2之间，堆内存会有一个明显的增长趋势图。但当执行完populateList方法之后，对堆内存并没有被垃圾回收器进行回收。\n\n但针对上述程序，如果将定义list的变量前的static关键字去掉，再次执行程序，会发现内存发生了具体的变化。VisualVM监控信息如下图：\n\n对比两个图可以看出，程序执行的前半部分内存使用情况都一样，但当执行完populateList方法之后，后者不再有引用指向对应的数据，垃圾回收器便进行了回收操作。因此，我们要十分留意static的变量，如果集合或大量的对象定义为static的，它们会停留在整个应用程序的生命周期当中。而它们所占用的内存空间，本可以用于其他地方。\n那么如何优化呢？第一，进来减少静态变量；第二，如果使用单例，尽量采用懒加载。\n\n\n\n\n\n\n\n\n\n2、 未关闭的资源\n无论什么时候当我们创建一个连接或打开一个流，JVM都会分配内存给这些资源。比如，数据库链接、输入流和session对象。\n忘记关闭这些资源，会阻塞内存，从而导致GC无法进行清理。特别是当程序发生异常时，没有在finally中进行资源关闭的情况。这些未正常关闭的连接，如果不进行处理，轻则影响程序性能，重则导致OutOfMemoryError异常发生。\n如果进行处理呢？第一，始终记得在finally中进行资源的关闭；第二，关闭连接的自身代码不能发生异常；第三，Java7以上版本可使用try-with-resources代码方式进行资源关闭。\n\n\n\n\n\n\n\n\n\n3、 使用ThreadLocal\nThreadLocal提供了线程本地变量，它可以保证访问到的变量属于当前线程，每个线程都保存有一个变量副本，每个线程的变量都不同。ThreadLocal相当于提供了一种线程隔离，将变量与线程相绑定，从而实现线程安全的特性。\n\nThreadLocal的实现中，每个Thread维护一个ThreadLocalMap映射表，key是ThreadLocal实例本身，value是真正需要存储的Object。\nThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统GC时，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value。\n如果当前线程迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。\n如何解决此问题？\n\n第一，使用ThreadLocal提供的remove方法，可对当前线程中的value值进行移除；\n第二，不要使用ThreadLocal.set(null) 的方式清除value，它实际上并没有清除值，而是查找与当前线程关联的Map并将键值对分别设置为当前线程和null。\n第三，最好将ThreadLocal视为需要在finally块中关闭的资源，以确保即使在发生异常的情况下也始终关闭该资源。\n\n123456try &#123;    threadLocal.set(System.nanoTime());    //... further processing&#125; finally &#123;    threadLocal.remove();&#125;\n\n# 类初始化和类加载# 创建对象的过程？在Java中创建对象的过程包括以下几个步骤：\n\n类加载检查：虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。\n分配内存：在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。\n初始化零值：内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。\n进行必要设置，比如对象头：初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。这些信息存放在对象头中。另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。\n执行 init 方法：在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始——构造函数，即class文件中的方法还没有执行，所有的字段都还为零，对象需要的其他资源和状态信息还没有按照预定的意图构造好。所以一般来说，执行 new 指令之后会接着执行方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全被构造出来。\n\n# 对象的生命周期对象的生命周期包括创建、使用和销毁三个阶段：\n\n创建：对象通过关键字new在堆内存中被实例化，构造函数被调用，对象的内存空间被分配。\n使用：对象被引用并执行相应的操作，可以通过引用访问对象的属性和方法，在程序运行过程中被不断使用。\n销毁：当对象不再被引用时，通过垃圾回收机制自动回收对象所占用的内存空间。垃圾回收器会在适当的时候检测并回收不再被引用的对象，释放对象占用的内存空间，完成对象的销毁过程。\n\n# 类加载器有哪些？\n\n启动类加载器（Bootstrap Class Loader）：这是最顶层的类加载器，负责加载Java的核心库（如位于jre&#x2F;lib&#x2F;rt.jar中的类），它是用C++编写的，是JVM的一部分。启动类加载器无法被Java程序直接引用。\n扩展类加载器（Extension Class Loader）：它是Java语言实现的，继承自ClassLoader类，负责加载Java扩展目录（jre&#x2F;lib&#x2F;ext或由系统变量Java.ext.dirs指定的目录）下的jar包和类库。扩展类加载器由启动类加载器加载，并且父加载器就是启动类加载器。\n系统类加载器（System Class Loader）&#x2F; 应用程序类加载器（Application Class Loader）：这也是Java语言实现的，负责加载用户类路径（ClassPath）上的指定类库，是我们平时编写Java程序时默认使用的类加载器。系统类加载器的父加载器是扩展类加载器。它可以通过ClassLoader.getSystemClassLoader()方法获取到。\n自定义类加载器（Custom Class Loader）：开发者可以根据需求定制类的加载方式，比如从网络加载class文件、数据库、甚至是加密的文件中加载类等。自定义类加载器可以用来扩展Java应用程序的灵活性和安全性，是Java动态性的一个重要体现。\n\n这些类加载器之间的关系形成了双亲委派模型，其核心思想是当一个类加载器收到类加载的请求时，首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中。\n只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。\n# 双亲委派模型的作用\n保证类的唯一性：通过委托机制，确保了所有加载请求都会传递到启动类加载器，避免了不同类加载器重复加载相同类的情况，保证了Java核心类库的统一性，也防止了用户自定义类覆盖核心类库的可能。\n保证安全性：由于Java核心库被启动类加载器加载，而启动类加载器只加载信任的类路径中的类，这样可以防止不可信的类假冒核心类，增强了系统的安全性。例如，恶意代码无法自定义一个Java.lang.System类并加载到JVM中，因为这个请求会被委托给启动类加载器，而启动类加载器只会加载标准的Java库中的类。\n支持隔离和层次划分：双亲委派模型支持不同层次的类加载器服务于不同的类加载需求，如应用程序类加载器加载用户代码，扩展类加载器加载扩展框架，启动类加载器加载核心库。这种层次化的划分有助于实现沙箱安全机制，保证了各个层级类加载器的职责清晰，也便于维护和扩展。\n简化了加载流程：通过委派，大部分类能够被正确的类加载器加载，减少了每个加载器需要处理的类的数量，简化了类的加载过程，提高了加载效率。\n\n# 讲一下类加载过程？类从被加载到虚拟机内存开始，到卸载出内存为止，它的整个生命周期包括以下 7 个阶段：\n\n\n加载：通过类的全限定名（包名 + 类名），获取到该类的.class文件的二进制字节流，将二进制字节流所代表的静态存储结构，转化为方法区运行时的数据结构，在内存中生成一个代表该类的Java.lang.Class对象，作为方法区这个类的各种数据的访问入口\n\n连接：验证、准备、解析 3 个阶段统称为连接。\n\n验证：确保class文件中的字节流包含的信息，符合当前虚拟机的要求，保证这个被加载的class类的正确性，不会危害到虚拟机的安全。验证阶段大致会完成以下四个阶段的检验动作：文件格式校验、元数据验证、字节码验证、符号引用验证\n\n准备：为类中的静态字段分配内存，并设置默认的初始值，比如int类型初始值是0。被final修饰的static字段不会设置，因为final在编译的时候就分配了\n\n解析：解析阶段是虚拟机将常量池的「符号引用」直接替换为「直接引用」的过程。符号引用是以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用的时候可以无歧义地定位到目标即可。直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄，直接引用是和虚拟机实现的内存布局相关的。如果有了直接引用， 那引用的目标必定已经存在在内存中了。\n\n\n\n初始化：初始化是整个类加载过程的最后一个阶段，初始化阶段简单来说就是执行类的构造器方法（() ），要注意的是这里的构造器方法()并不是开发者写的，而是编译器自动生成的。\n\n使用：使用类或者创建对象\n\n卸载：如果有下面的情况，类就会被卸载：1. 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。2. 加载该类的ClassLoader已经被回收。 3. 类对应的Java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\n\n# 讲一下类的加载和双亲委派原则我们把 Java 的类加载过程分为三个主要步骤：加载、链接、初始化。\n首先是加载阶段（Loading），它是 Java 将字节码数据从不同的数据源读取到 JVM 中，并映射为 JVM 认可的数据结构（Class 对象），这里的数据源可能是各种各样的形态，如 jar 文件、class 文件，甚至是网络数据源等；如果输入数据不是 ClassFile 的结构，则会抛出 ClassFormatError。\n加载阶段是用户参与的阶段，我们可以自定义类加载器，去实现自己的类加载过程。\n第二阶段是链接（Linking），这是核心的步骤，简单说是把原始的类定义信息平滑地转化入 JVM 运行的过程中。这里可进一步细分为三个步骤：\n\n验证（Verification），这是虚拟机安全的重要保障，JVM 需要核验字节信息是符合 Java 虚拟机规范的，否则就被认为是 VerifyError，这样就防止了恶意信息或者不合规的信息危害 JVM 的运行，验证阶段有可能触发更多 class 的加载。\n准备（Preparation），创建类或接口中的静态变量，并初始化静态变量的初始值。但这里的“初始化”和下面的显式初始化阶段是有区别的，侧重点在于分配所需要的内存空间，不会去执行更进一步的 JVM 指令。\n解析（Resolution），在这一步会将常量池中的符号引用（symbolic reference）替换为直接引用。\n\n最后是初始化阶段（initialization），这一步真正去执行类初始化的代码逻辑，包括静态字段赋值的动作，以及执行类定义中的静态初始化块内的逻辑，编译器在编译阶段就会把这部分逻辑整理好，父类型的初始化逻辑优先于当前类型的逻辑。\n再来谈谈双亲委派模型，简单说就是当类加载器（Class-Loader）试图加载某个类型的时候，除非父加载器找不到相应类型，否则尽量将这个任务代理给当前加载器的父加载器去做。使用委派模型的目的是避免重复加载 Java 类型。\n# 垃圾回收# 什么是Java里的垃圾回收？如何触发垃圾回收？垃圾回收（Garbage Collection, GC）是自动管理内存的一种机制，它负责自动释放不再被程序引用的对象所占用的内存，这种机制减少了内存泄漏和内存管理错误的可能性。垃圾回收可以通过多种方式触发，具体如下：\n\n内存不足时：当JVM检测到堆内存不足，无法为新的对象分配内存时，会自动触发垃圾回收。\n手动请求：虽然垃圾回收是自动的，开发者可以通过调用 System.gc() 或 Runtime.getRuntime().gc() 建议 JVM 进行垃圾回收。不过这只是一个建议，并不能保证立即执行。\nJVM参数：启动 Java 应用时可以通过 JVM 参数来调整垃圾回收的行为，比如：-Xmx（最大堆大小）、-Xms（初始堆大小）等。\n对象数量或内存使用达到阈值：垃圾收集器内部实现了一些策略，以监控对象的创建和内存使用，达到某个阈值时触发垃圾回收。\n\n# 判断垃圾的方法有哪些？在Java中，判断对象是否为垃圾（即不再被使用，可以被垃圾回收器回收）主要依据两种主流的垃圾回收算法来实现：引用计数法和可达性分析算法。\n\n\n\n\n\n\n\n\n\n引用计数法（Reference Counting）\n\n原理：为每个对象分配一个引用计数器，每当有一个地方引用它时，计数器加1；当引用失效时，计数器减1。当计数器为0时，表示对象不再被任何变量引用，可以被回收。\n缺点：不能解决循环引用的问题，即两个对象相互引用，但不再被其他任何对象引用，这时引用计数器不会为0，导致对象无法被回收。\n\n\n\n\n\n\n\n\n\n\n可达性分析算法（Reachability Analysis）\n\nJava虚拟机主要采用此算法来判断对象是否为垃圾。\n\n原理：从一组称为GC Roots（垃圾收集根）的对象出发，向下追溯它们引用的对象，以及这些对象引用的其他对象，以此类推。如果一个对象到GC Roots没有任何引用链相连（即从GC Roots到这个对象不可达），那么这个对象就被认为是不可达的，可以被回收。GC Roots对象包括：虚拟机栈（栈帧中的本地变量表）中引用的对象、方法区中类静态属性引用的对象、本地方法栈中JNI（Java Native Interface）引用的对象、活跃线程的引用等。\n\n# 垃圾回收算法是什么，是为了解决了什么问题？JVM有垃圾回收机制的原因是为了解决内存管理的问题。在传统的编程语言中，开发人员需要手动分配和释放内存，这可能导致内存泄漏、内存溢出等问题。而Java作为一种高级语言，旨在提供更简单、更安全的编程环境，因此引入了垃圾回收机制来自动管理内存。\n垃圾回收机制的主要目标是自动检测和回收不再使用的对象，从而释放它们所占用的内存空间。这样可以避免内存泄漏（一些对象被分配了内存却无法被释放，导致内存资源的浪费）。同时，垃圾回收机制还可以防止内存溢出（即程序需要的内存超过了可用内存的情况）。\n通过垃圾回收机制，JVM可以在程序运行时自动识别和清理不再使用的对象，使得开发人员无需手动管理内存。这样可以提高开发效率、减少错误，并且使程序更加可靠和稳定。\n# 垃圾回收算法有哪些？\n标记-清除算法：标记-清除算法分为“标记”和“清除”两个阶段，首先通过可达性分析，标记出所有需要回收的对象，然后统一回收所有被标记的对象。标记-清除算法有两个缺陷，一个是效率问题，标记和清除的过程效率都不高，另外一个就是，清除结束后会造成大量的碎片空间。有可能会造成在申请大块内存的时候因为没有足够的连续空间导致再次 GC。\n复制算法：为了解决碎片空间的问题，出现了“复制算法”。复制算法的原理是，将内存分成两块，每次申请内存时都使用其中的一块，当内存不够时，将这一块内存中所有存活的复制到另一块上。然后将然后再把已使用的内存整个清理掉。复制算法解决了空间碎片的问题。但是也带来了新的问题。因为每次在申请内存时，都只能使用一半的内存空间。内存利用率严重不足。\n标记-整理算法：复制算法在 GC 之后存活对象较少的情况下效率比较高，但如果存活对象比较多时，会执行较多的复制操作，效率就会下降。而老年代的对象在 GC 之后的存活率就比较高，所以就有人提出了“标记-整理算法”。标记-整理算法的“标记”过程与“标记-清除算法”的标记过程一致，但标记之后不会直接清理。而是将所有存活对象都移动到内存的一端。移动结束后直接清理掉剩余部分。\n分代回收算法：分代收集是将内存划分成了新生代和老年代。分配的依据是对象的生存周期，或者说经历过的 GC 次数。对象创建时，一般在新生代申请内存，当经历一次 GC 之后如果对还存活，那么对象的年龄 +1。当年龄超过一定值(默认是 15，可以通过参数 -XX:MaxTenuringThreshold 来设定)后，如果对象还存活，那么该对象会进入老年代。\n\n# 垃圾回收器有哪些？\n\nSerial收集器（复制算法): 新生代单线程收集器，标记和清理都是单线程，优点是简单高效；\nParNew收集器 (复制算法): 新生代收并行集器，实际上是Serial收集器的多线程版本，在多核CPU环境下有着比Serial更好的表现；\nParallel Scavenge收集器 (复制算法): 新生代并行收集器，追求高吞吐量，高效利用 CPU。吞吐量 &#x3D; 用户线程时间&#x2F;(用户线程时间+GC线程时间)，高吞吐量可以高效率的利用CPU时间，尽快完成程序的运算任务，适合后台应用等对交互相应要求不高的场景；\nSerial Old收集器 (标记-整理算法): 老年代单线程收集器，Serial收集器的老年代版本；\nParallel Old收集器 (标记-整理算法)： 老年代并行收集器，吞吐量优先，Parallel Scavenge收集器的老年代版本；\nCMS(Concurrent Mark Sweep)收集器（标记-清除算法）： 老年代并行收集器，以获取最短回收停顿时间为目标的收集器，具有高并发、低停顿的特点，追求最短GC回收停顿时间。\nG1(Garbage First)收集器 (标记-整理算法)： Java堆并行收集器，G1收集器是JDK1.7提供的一个新收集器，G1收集器基于“标记-整理”算法实现，也就是说不会产生内存碎片。此外，G1收集器不同于之前的收集器的一个重要特点是：G1回收的范围是整个Java堆(包括新生代，老年代)，而前六种收集器回收的范围仅限于新生代或老年代\n\n# 标记清除算法的缺点是什么？主要缺点有两个：\n\n一个是效率问题，标记和清除过程的效率都不高；\n另外一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。\n\n# 垃圾回收算法哪些阶段会stop the world?标记-复制算法应用在CMS新生代（ParNew是CMS默认的新生代垃圾回收器）和G1垃圾回收器中。标记-复制算法可以分为三个阶段：\n\n标记阶段，即从GC Roots集合开始，标记活跃对象；\n转移阶段，即把活跃对象复制到新的内存地址上；\n重定位阶段，因为转移导致对象的地址发生了变化，在重定位阶段，所有指向对象旧地址的指针都要调整到对象新的地址上。\n\n下面以G1为例，通过G1中标记-复制算法过程（G1的Young GC和Mixed GC均采用该算法），分析G1停顿耗时的主要瓶颈。G1垃圾回收周期如下图所示：\n\nG1的混合回收过程可以分为标记阶段、清理阶段和复制阶段。\n标记阶段停顿分析\n\n初始标记阶段：初始标记阶段是指从GC Roots出发标记全部直接子节点的过程，该阶段是STW的。由于GC Roots数量不多，通常该阶段耗时非常短。\n并发标记阶段：并发标记阶段是指从GC Roots开始对堆中对象进行可达性分析，找出存活对象。该阶段是并发的，即应用线程和GC线程可以同时活动。并发标记耗时相对长很多，但因为不是STW，所以我们不太关心该阶段耗时的长短。\n再标记阶段：重新标记那些在并发标记阶段发生变化的对象。该阶段是STW的。\n\n清理阶段停顿分析\n\n清理阶段清点出有存活对象的分区和没有存活对象的分区，该阶段不会清理垃圾对象，也不会执行存活对象的复制。该阶段是STW的。\n\n复制阶段停顿分析\n\n复制算法中的转移阶段需要分配新内存和复制对象的成员变量。转移阶段是STW的，其中内存分配通常耗时非常短，但对象成员变量的复制耗时有可能较长，这是因为复制耗时与存活对象数量与对象复杂度成正比。对象越复杂，复制耗时越长。\n\n四个STW过程中，初始标记因为只标记GC Roots，耗时较短。再标记因为对象数少，耗时也较短。清理阶段因为内存分区数量少，耗时也较短。转移阶段要处理所有存活的对象，耗时会较长。\n因此，G1停顿时间的瓶颈主要是标记-复制中的转移阶段STW。\n# minorGC、majorGC、fullGC的区别，什么场景触发full GC在Java中，垃圾回收机制是自动管理内存的重要组成部分。根据其作用范围和触发条件的不同，可以将GC分为三种类型：Minor GC（也称为Young GC）、Major GC（有时也称为Old GC）、以及Full GC。以下是这三种GC的区别和触发场景：\n\n\n\n\n\n\n\n\n\nMinor GC (Young GC)\n\n作用范围：只针对年轻代进行回收，包括Eden区和两个Survivor区（S0和S1）。\n触发条件：当Eden区空间不足时，JVM会触发一次Minor GC，将Eden区和一个Survivor区中的存活对象移动到另一个Survivor区或老年代（Old Generation）。\n特点：通常发生得非常频繁，因为年轻代中对象的生命周期较短，回收效率高，暂停时间相对较短。\n\n\n\n\n\n\n\n\n\n\nMajor GC\n\n作用范围：主要针对老年代进行回收，但不一定只回收老年代。\n触发条件：当老年代空间不足时，或者系统检测到年轻代对象晋升到老年代的速度过快，可能会触发Major GC。\n特点：相比Minor GC，Major GC发生的频率较低，但每次回收可能需要更长的时间，因为老年代中的对象存活率较高。\n\n\n\n\n\n\n\n\n\n\nFull GC\n\n作用范围：对整个堆内存（包括年轻代、老年代以及永久代&#x2F;元空间）进行回收。\n\n触发条件：\n\n直接调用System.gc()或Runtime.getRuntime().gc()方法时，虽然不能保证立即执行，但JVM会尝试执行Full GC。\n\nMinor GC（新生代垃圾回收）时，如果存活的对象无法全部放入老年代，或者老年代空间不足以容纳存活的对象，则会触发Full GC，对整个堆内存进行回收。\n\n当永久代（Java 8之前的版本）或元空间（Java 8及以后的版本）空间不足时。\n\n\n\n特点：Full GC是最昂贵的操作，因为它需要停止所有的工作线程（Stop The World），遍历整个堆内存来查找和回收不再使用的对象，因此应尽量减少Full GC的触发。\n\n\n# 垃圾回收器 CMS 和 G1的区别？区别一：使用的范围不一样：\n\nCMS收集器是老年代的收集器，可以配合新生代的Serial和ParNew收集器一起使用\nG1收集器收集范围是老年代和新生代。不需要结合其他收集器使用\n\n区别二：STW的时间：\n\nCMS收集器以最小的停顿时间为目标的收集器。\nG1收集器可预测垃圾回收 (opens new window)的停顿时间（建立可预测的停顿时间模型）\n\n区别三： 垃圾碎片\n\nCMS收集器是使用“标记-清除”算法进行的垃圾回收，容易产生内存碎片\nG1收集器使用的是“标记-整理”算法，进行了空间整合，没有内存空间碎片。\n\n区别四： 垃圾回收的过程不一样\n\n注意这两个收集器第四阶段得不同\n区别五: CMS会产生浮动垃圾\n\nCMS产生浮动垃圾过多时会退化为serial old，效率低，因为在上图的第四阶段，CMS清除垃圾时是并发清除的，这个时候，垃圾回收线程和用户线程同时工作会产生浮动垃圾，也就意味着CMS垃圾回收器必须预留一部分内存空间用于存放浮动垃圾\n而G1没有浮动垃圾，G1的筛选回收是多个垃圾回收线程并行gc的，没有浮动垃圾的回收，在执行‘并发清理’步骤时，用户线程也会同时产生一部分可回收对象，但是这部分可回收对象只能在下次执行清理是才会被回收。如果在清理过程中预留给用户线程的内存不足就会出现‘Concurrent Mode Failure’,一旦出现此错误时便会切换到SerialOld收集方式。\n\n# 什么情况下使用CMS，什么情况使用G1?CMS适用场景：\n\n低延迟需求：适用于对停顿时间要求敏感的应用程序。\n老生代收集：主要针对老年代的垃圾回收。\n碎片化管理：容易出现内存碎片，可能需要定期进行Full GC来压缩内存空间。\n\nG1适用场景：\n\n大堆内存：适用于需要管理大内存堆的场景，能够有效处理数GB以上的堆内存。\n对内存碎片敏感：G1通过紧凑整理来减少内存碎片，降低了碎片化对性能的影响。\n比较平衡的性能：G1在提供较低停顿时间的同时，也保持了相对较高的吞吐量。\n\n# G1回收器的特色是什么？G1 的特点：\n\nG1最大的特点是引入分区的思路，弱化了分代的概念。\n合理利用垃圾收集各个周期的资源，解决了其他收集器、甚至 CMS 的众多缺陷\n\nG1 相比较 CMS 的改进：\n\n算法： G1 基于标记–整理算法, 不会产生空间碎片，在分配大对象时，不会因无法得到连续的空间，而提前触发一次 FULL GC 。\n停顿时间可控： G1可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间避免应用雪崩现象。\n并行与并发：G1 能更充分的利用 CPU 多核环境下的硬件优势，来缩短 stop the world 的停顿时间。\n\n# GC只会对堆进行GC吗？JVM 的垃圾回收器不仅仅会对堆进行垃圾回收，它还会对方法区进行垃圾回收。\n\n堆（Heap）： 堆是用于存储对象实例的内存区域。大部分的垃圾回收工作都发生在堆上，因为大多数对象都会被分配在堆上，而垃圾回收的重点通常也是回收堆中不再被引用的对象，以释放内存空间。\n方法区（Method Area）： 方法区是用于存储类信息、常量、静态变量等数据的区域。虽然方法区中的垃圾回收与堆有所不同，但是同样存在对不再需要的常量、无用的类信息等进行清理的过程。\n\n\n","slug":"jvm/jvm面试题","date":"2024-12-03T18:00:59.000Z","categories_index":"八股","tags_index":"java,精选,jvm","author_index":"Ivan"},{"id":"fd2c15dc5d41ab5172de4dd08fd40ea9","title":"Java集合","content":"# Java集合面# 概念# 数组与集合区别，用过哪些？数组和集合的区别：\n\n数组是固定长度的数据结构，一旦创建长度就无法改变，而集合是动态长度的数据结构，可以根据需要动态增加或减少元素。\n数组可以包含基本数据类型和对象，而集合只能包含对象。\n数组可以直接访问元素，而集合需要通过迭代器或其他方法访问元素。\n\n我用过的一些 Java 集合类：\n\nArrayList： 动态数组，实现了List接口，支持动态增长。\nLinkedList： 双向链表，也实现了List接口，支持快速的插入和删除操作。\nHashMap： 基于哈希表的Map实现，存储键值对，通过键快速查找值。\nHashSet： 基于HashMap实现的Set集合，用于存储唯一元素。\nTreeMap： 基于红黑树实现的有序Map集合，可以按照键的顺序进行排序。\nLinkedHashMap： 基于哈希表和双向链表实现的Map集合，保持插入顺序或访问顺序。\nPriorityQueue： 优先队列，可以按照比较器或元素的自然顺序进行排序。\n\n# 说说Java中的集合？List是有序的Collection，使用此接口能够精确的控制每个元素的插入位置，用户能根据索引访问List中元素。常用的实现List的类有LinkedList，ArrayList，Vector，Stack。\n\nArrayList是容量可变的非线程安全列表，其底层使用数组实现。当几何扩容时，会创建更大的数组，并把原数组复制到新数组。ArrayList支持对元素的快速随机访问，但插入与删除速度很慢。\nLinkedList本质是一个双向链表，与ArrayList相比，，其插入和删除速度更快，但随机访问速度更慢。\n\nSet不允许存在重复的元素，与List不同，set中的元素是无序的。常用的实现有HashSet，LinkedHashSet和TreeSet。\n\nHashSet通过HashMap实现，HashMap的Key即HashSet存储的元素，所有Key都是用相同的Value，一个名为PRESENT的Object类型常量。使用Key保证元素唯一性，但不保证有序性。由于HashSet是HashMap实现的，因此线程不安全。\nLinkedHashSet继承自HashSet，通过LinkedHashMap实现，使用双向链表维护元素插入顺序。\nTreeSet通过TreeMap实现的，添加元素到集合时按照比较规则将其插入合适的位置，保证插入后的集合仍然有序。\n\nMap 是一个键值对集合，存储键、值和之间的映射。Key 无序，唯一；value 不要求有序，允许重复。Map 没有继承于 Collection 接口，从 Map 集合中检索元素时，只要给出键对象，就会返回对应的值对象。主要实现有TreeMap、HashMap、HashTable、LinkedHashMap、ConcurrentHashMap\n\nHashMap：JDK1.8 之前 HashMap 由数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突），JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树，以减少搜索时间\nLinkedHashMap：LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。\nHashTable：数组+链表组成的，数组是 HashTable 的主体，链表则是主要为了解决哈希冲突而存在的\nTreeMap：红黑树（自平衡的排序二叉树）\nConcurrentHashMap：Node数组+链表+红黑树实现，线程安全的（jdk1.8以前Segment锁，1.8以后volatile + CAS 或者 synchronized）\n\n# Java中的线程安全的集合是什么？在 java.util 包中的线程安全的类主要 2 个，其他都是非线程安全的。\n\nVector：线程安全的动态数组，其内部方法基本都经过synchronized修饰，如果不需要线程安全，并不建议选择，毕竟同步是有额外开销的。Vector 内部是使用对象数组来保存数据，可以根据需要自动的增加容量，当数组已满时，会创建新的数组，并拷贝原有数组数据。\nHashtable：线程安全的哈希表，HashTable 的加锁方法是给每个方法加上 synchronized 关键字，这样锁住的是整个 Table 对象，不支持 null 键和值，由于同步导致的性能开销，所以已经很少被推荐使用，如果要保证线程安全的哈希表，可以用ConcurrentHashMap。\n\njava.util.concurrent 包提供的都是线程安全的集合：\n并发Map：\n\nConcurrentHashMap：它与 HashTable 的主要区别是二者加锁粒度的不同，在JDK1.7，ConcurrentHashMap加的是分段锁，也就是Segment锁，每个Segment 含有整个 table 的一部分，这样不同分段之间的并发操作就互不影响。在JDK 1.8 ，它取消了Segment字段，直接在table元素上加锁，实现对每一行进行加锁，进一步减小了并发冲突的概率。对于put操作，如果Key对应的数组元素为null，则通过CAS操作（Compare and Swap）将其设置为当前值。如果Key对应的数组元素（也即链表表头或者树的根元素）不为null，则对该元素使用 synchronized 关键字申请锁，然后进行操作。如果该 put 操作使得当前链表长度超过一定阈值，则将该链表转换为红黑树，从而提高寻址效率。\nConcurrentSkipListMap：实现了一个基于SkipList（跳表）算法的可排序的并发集合，SkipList是一种可以在对数预期时间内完成搜索、插入、删除等操作的数据结构，通过维护多个指向其他元素的“跳跃”链接来实现高效查找。\n\n并发Set：\n\nConcurrentSkipListSet：是线程安全的有序的集合。底层是使用ConcurrentSkipListMap实现。\nCopyOnWriteArraySet：是线程安全的Set实现，它是线程安全的无序的集合，可以将它理解成线程安全的HashSet。有意思的是，CopyOnWriteArraySet和HashSet虽然都继承于共同的父类AbstractSet；但是，HashSet是通过“散列表”实现的，而CopyOnWriteArraySet则是通过“动态数组(CopyOnWriteArrayList)”实现的，并不是散列表。\n\n并发List：\n\nCopyOnWriteArrayList：它是 ArrayList 的线程安全的变体，其中所有写操作（add，set等）都通过对底层数组进行全新复制来实现，允许存储 null 元素。即当对象进行写操作时，使用了Lock锁做同步处理，内部拷贝了原数组，并在新数组上进行添加操作，最后将新数组替换掉旧数组；若进行的读操作，则直接返回结果，操作过程中不需要进行同步。\n\n并发 Queue：\n\nConcurrentLinkedQueue：是一个适用于高并发场景下的队列，它通过无锁的方式(CAS)，实现了高并发状态下的高性能。通常，ConcurrentLinkedQueue 的性能要好于 BlockingQueue 。\nBlockingQueue：与 ConcurrentLinkedQueue 的使用场景不同，BlockingQueue 的主要功能并不是在于提升高并发时的队列性能，而在于简化多线程间的数据共享。BlockingQueue 提供一种读写阻塞等待的机制，即如果消费者速度较快，则 BlockingQueue 则可能被清空，此时消费线程再试图从 BlockingQueue 读取数据时就会被阻塞。反之，如果生产线程较快，则 BlockingQueue 可能会被装满，此时，生产线程再试图向 BlockingQueue 队列装入数据时，便会被阻塞等待。\n\n并发 Deque：\n\nLinkedBlockingDeque：是一个线程安全的双端队列实现。它的内部使用链表结构，每一个节点都维护了一个前驱节点和一个后驱节点。LinkedBlockingDeque 没有进行读写锁的分离，因此同一时间只能有一个线程对其进行操作\nConcurrentLinkedDeque：ConcurrentLinkedDeque是一种基于链接节点的无限并发链表。可以安全地并发执行插入、删除和访问操作。当许多线程同时访问一个公共集合时，ConcurrentLinkedDeque是一个合适的选择。\n\n# Collections和Collection的区别\nCollection是Java集合框架中的一个接口，它是所有集合类的基础接口。它定义了一组通用的操作和方法，如添加、删除、遍历等，用于操作和管理一组对象。Collection接口有许多实现类，如List、Set和Queue等。\nCollections（注意有一个s）是Java提供的一个工具类，位于java.util包中。它提供了一系列静态方法，用于对集合进行操作和算法。Collections类中的方法包括排序、查找、替换、反转、随机化等等。这些方法可以对实现了Collection接口的集合进行操作，如List和Set。\n\n# 集合遍历的方法有哪些？在Java中，集合的遍历方法主要有以下几种：\n\n普通 for 循环： 可以使用带有索引的普通 for 循环来遍历 List。\n\n123456789List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;A&quot;);list.add(&quot;B&quot;);list.add(&quot;C&quot;);for (int i = 0; i &lt; list.size(); i++) &#123;    String element = list.get(i);    System.out.println(element);&#125;\n\n\n增强 for 循环（for-each循环）： 用于循环访问数组或集合中的元素。\n\n12345678List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;A&quot;);list.add(&quot;B&quot;);list.add(&quot;C&quot;);for (String element : list) &#123;    System.out.println(element);&#125;\n\n\nIterator 迭代器： 可以使用迭代器来遍历集合，特别适用于需要删除元素的情况。\n\n12345678910List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;A&quot;);list.add(&quot;B&quot;);list.add(&quot;C&quot;);Iterator&lt;String&gt; iterator = list.iterator();while(iterator.hasNext()) &#123;    String element = iterator.next();    System.out.println(element);&#125;\n\n\nListIterator 列表迭代器： ListIterator是迭代器的子类，可以双向访问列表并在迭代过程中修改元素。\n\n12345678910List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;A&quot;);list.add(&quot;B&quot;);list.add(&quot;C&quot;);ListIterator&lt;String&gt; listIterator= list.listIterator();while(listIterator.hasNext()) &#123;    String element = listIterator.next();    System.out.println(element);&#125;\n\n\n使用 forEach 方法： Java 8引入了 forEach 方法，可以对集合进行快速遍历。\n\n123456List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;A&quot;);list.add(&quot;B&quot;);list.add(&quot;C&quot;);list.forEach(element -&gt; System.out.println(element));\n\n\nStream API： Java 8的Stream API提供了丰富的功能，可以对集合进行函数式操作，如过滤、映射等。\n\n123456List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;A&quot;);list.add(&quot;B&quot;);list.add(&quot;C&quot;);list.stream().forEach(element -&gt; System.out.println(element));\n\n这些是常用的集合遍历方法，根据情况选择合适的方法来遍历和操作集合。\n# List# 讲一下java里面list的几种实现，几种实现有什么不同？在Java中，List接口是最常用的集合类型之一，用于存储元素的有序集合。以下是Java中常见的List实现及其特点： \n\nVector 是 Java 早期提供的线程安全的动态数组，如果不需要线程安全，并不建议选择，毕竟同步是有额外开销的。Vector 内部是使用对象数组来保存数据，可以根据需要自动的增加容量，当数组已满时，会创建新的数组，并拷贝原有数组数据。\nArrayList 是应用更加广泛的动态数组实现，它本身不是线程安全的，所以性能要好很多。与 Vector 近似，ArrayList 也是可以根据需要调整容量，不过两者的调整逻辑有所区别，Vector 在扩容时会提高 1 倍，而 ArrayList 则是增加 50%。\nLinkedList 顾名思义是 Java 提供的双向链表，所以它不需要像上面两种那样调整容量，它也不是线程安全的。\n\n\n\n\n\n\n\n\n\n\n这几种实现具体在什么场景下应该用哪种？\n\nVector 和 ArrayList 作为动态数组，其内部元素以数组形式顺序存储的，所以非常适合随机访问的场合。除了尾部插入和删除元素，往往性能会相对较差，比如我们在中间位置插入一个元素，需要移动后续所有元素。\n而 LinkedList 进行节点插入、删除却要高效得多，但是随机访问性能则要比动态数组慢。\n\n# Arraylist和LinkedList的区别，哪个集合是线程安全的？ArrayList和LinkedList都是Java中常见的集合类，它们都实现了List接口。\n\n底层数据结构不同：ArrayList使用数组实现，通过索引进行快速访问元素。LinkedList使用链表实现，通过节点之间的指针进行元素的访问和操作。\n插入和删除操作的效率不同：ArrayList在尾部的插入和删除操作效率较高，但在中间或开头的插入和删除操作效率较低，需要移动元素。LinkedList在任意位置的插入和删除操作效率都比较高，因为只需要调整节点之间的指针，但是LinkedList是不支持随机访问的，所以除了头结点外插入和删除的时间复杂度都是0(n)，效率也不是很高所以LinkedList基本没人用。\n随机访问的效率不同：ArrayList支持通过索引进行快速随机访问，时间复杂度为O(1)。LinkedList需要从头或尾开始遍历链表，时间复杂度为O(n)。\n空间占用：ArrayList在创建时需要分配一段连续的内存空间，因此会占用较大的空间。LinkedList每个节点只需要存储元素和指针，因此相对较小。\n使用场景：ArrayList适用于频繁随机访问和尾部的插入删除操作，而LinkedList适用于频繁的中间插入删除操作和不需要随机访问的场景。\n线程安全：这两个集合都不是线程安全的，Vector是线程安全的\n\n# ArrayList线程安全吗？把ArrayList变成线程安全有哪些方法？不是线程安全的，ArrayList变成线程安全的方式有：\n\n使用Collections类的synchronizedList方法将ArrayList包装成线程安全的List：\n\n1List&lt;String&gt; synchronizedList = Collections.synchronizedList(arrayList);\n\n\n使用CopyOnWriteArrayList类代替ArrayList，它是一个线程安全的List实现：\n\n1CopyOnWriteArrayList&lt;String&gt; copyOnWriteArrayList = new CopyOnWriteArrayList&lt;&gt;(arrayList);\n\n\n使用Vector类代替ArrayList，Vector是线程安全的List实现：\n\n1Vector&lt;String&gt; vector = new Vector&lt;&gt;(arrayList);\n\n# 为什么ArrayList不是线程安全的，具体来说是哪里不安全？在高并发添加数据下，ArrayList会暴露三个问题;\n\n部分值为null（我们并没有add null进去）\n索引越界异常\nsize与我们add的数量不符\n\n为了知道这三种情况是怎么发生的，ArrayList，add 增加元素的代码如下：\n12345public boolean add(E e) &#123;        ensureCapacityInternal(size + 1);  // Increments modCount!!        elementData[size++] = e;        return true;    &#125;\n\nensureCapacityInternal()这个方法的详细代码我们可以暂时不看，它的作用就是判断如果将当前的新元素加到列表后面，列表的elementData数组的大小是否满足，如果size + 1的这个需求长度大于了elementData这个数组的长度，那么就要对这个数组进行扩容。\n大体可以分为三步：\n\n判断数组需不需要扩容，如果需要的话，调用grow方法进行扩容；\n将数组的size位置设置值（因为数组的下标是从0开始的）；\n将当前集合的大小加1\n\n下面我们来分析三种情况都是如何产生的：\n\n部分值为null：当线程1走到了扩容那里发现当前size是9，而数组容量是10，所以不用扩容，这时候cpu让出执行权，线程2也进来了，发现size是9，而数组容量是10，所以不用扩容，这时候线程1继续执行，将数组下标索引为9的位置set值了，还没有来得及执行size++，这时候线程2也来执行了，又把数组下标索引为9的位置set了一遍，这时候两个先后进行size++，导致下标索引10的地方就为null了。\n索引越界异常：线程1走到扩容那里发现当前size是9，数组容量是10不用扩容，cpu让出执行权，线程2也发现不用扩容，这时候数组的容量就是10，而线程1 set完之后size++，这时候线程2再进来size就是10，数组的大小只有10，而你要设置下标索引为10的就会越界（数组的下标索引从0开始）；\nsize与我们add的数量不符：这个基本上每次都会发生，这个理解起来也很简单，因为size++本身就不是原子操作，可以分为三步：获取size的值，将size的值加1，将新的size值覆盖掉原来的，线程1和线程2拿到一样的size值加完了同时覆盖，就会导致一次没有加上，所以肯定不会与我们add的数量保持一致的；\n\n# ArrayList 和 LinkedList 的应用场景？\nArrayList适用于需要频繁访问集合元素的场景。它基于数组实现，可以通过索引快速访问元素，因此在按索引查找、遍历和随机访问元素的操作上具有较高的性能。当需要频繁访问和遍历集合元素，并且集合大小不经常改变时，推荐使用ArrayList\nLinkedList适用于频繁进行插入和删除操作的场景。它基于链表实现，插入和删除元素的操作只需要调整节点的指针，因此在插入和删除操作上具有较高的性能。当需要频繁进行插入和删除操作，或者集合大小经常改变时，可以考虑使用LinkedList。\n\n# ArrayList的扩容机制说一下ArrayList在添加元素时，如果当前元素个数已经达到了内部数组的容量上限，就会触发扩容操作。ArrayList的扩容操作主要包括以下几个步骤：\n\n计算新的容量：一般情况下，新的容量会扩大为原容量的1.5倍（在JDK 10之后，扩容策略做了调整），然后检查是否超过了最大容量限制。\n创建新的数组：根据计算得到的新容量，创建一个新的更大的数组。\n将元素复制：将原来数组中的元素逐个复制到新数组中。\n更新引用：将ArrayList内部指向原数组的引用指向新数组。\n完成扩容：扩容完成后，可以继续添加新元素。\n\nArrayList的扩容操作涉及到数组的复制和内存的重新分配，所以在频繁添加大量元素时，扩容操作可能会影响性能。为了减少扩容带来的性能损耗，可以在初始化ArrayList时预分配足够大的容量，避免频繁触发扩容操作。\n之所以扩容是 1.5 倍，是因为 1.5 可以充分利用移位操作，减少浮点数或者运算时间和运算次数。\n12// 新容量计算int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);\n\n# 线程安全的 List， CopyonWriteArraylist是如何实现线程安全的CopyOnWriteArrayList底层也是通过一个数组保存数据，使用volatile关键字修饰数组，保证当前线程对数组对象重新赋值后，其他线程可以及时感知到。\n1private transient volatile Object[] array;\n\n在写入操作时，加了一把互斥锁ReentrantLock以保证线程安全。\n12345678910111213141516171819202122public boolean add(E e) &#123;    //获取锁    final ReentrantLock lock = this.lock;    //加锁    lock.lock();    try &#123;        //获取到当前List集合保存数据的数组        Object[] elements = getArray();        //获取该数组的长度（这是一个伏笔，同时len也是新数组的最后一个元素的索引值）        int len = elements.length;        //将当前数组拷贝一份的同时，让其长度加1        Object[] newElements = Arrays.copyOf(elements, len + 1);        //将加入的元素放在新数组最后一位，len不是旧数组长度吗，为什么现在用它当成新数组的最后一个元素的下标？建议自行画图推演，就很容易理解。        newElements[len] = e;        //替换引用，将数组的引用指向给新数组的地址        setArray(newElements);        return true;    &#125; finally &#123;        //释放锁        lock.unlock();    &#125;&#125;\n\n看到源码可以知道写入新元素时，首先会先将原来的数组拷贝一份并且让原来数组的长度+1后就得到了一个新数组，新数组里的元素和旧数组的元素一样并且长度比旧数组多一个长度，然后将新加入的元素放置都在新数组最后一个位置后，用新数组的地址替换掉老数组的地址就能得到最新的数据了。\n在我们执行替换地址操作之前，读取的是老数组的数据，数据是有效数据；执行替换地址操作之后，读取的是新数组的数据，同样也是有效数据，而且使用该方式能比读写都加锁要更加的效率。\n现在我们来看读操作，读是没有加锁的，所以读是一直都能读\n123public E get(int index) &#123;    return get(getArray(), index);&#125;\n\n# Map# HashMap实现原理介绍一下？在 JDK 1.7 版本之前， HashMap 数据结构是数组和链表，HashMap通过哈希算法将元素的键（Key）映射到数组中的槽位（Bucket）。如果多个键映射到同一个槽位，它们会以链表的形式存储在同一个槽位上，因为链表的查询时间是O(n)，所以冲突很严重，一个索引上的链表非常长，效率就很低了。  所以在 JDK 1.8 版本的时候做了优化，当一个链表的长度超过8的时候就转换数据结构，不再使用链表存储，而是使用红黑树，查找时使用红黑树，时间复杂度O（log n），可以提高查询性能，但是在数量较少时，即数量小于6时，会将红黑树转换回链表。\n\n# 了解的哈希冲突解决方法有哪些？\n链接法：使用链表或其他数据结构来存储冲突的键值对，将它们链接在同一个哈希桶中。\n开放寻址法：在哈希表中找到另一个可用的位置来存储冲突的键值对，而不是存储在链表中。常见的开放寻址方法包括线性探测、二次探测和双重散列。\n再哈希法（Rehashing）：当发生冲突时，使用另一个哈希函数再次计算键的哈希值，直到找到一个空槽来存储键值对。\n哈希桶扩容：当哈希冲突过多时，可以动态地扩大哈希桶的数量，重新分配键值对，以减少冲突的概率。\n\n# HashMap是线程安全的吗？hashmap不是线程安全的，hashmap在多线程会存在下面的问题：\n\nJDK 1.7 HashMap 采用数组 + 链表的数据结构，多线程背景下，在数组扩容的时候，存在 Entry 链死循环和数据丢失问题。\nJDK 1.8 HashMap 采用数组 + 链表 + 红黑二叉树的数据结构，优化了 1.7 中数组扩容的方案，解决了 Entry 链死循环和数据丢失问题。但是多线程背景下，put 方法存在数据覆盖的问题。\n\n如果要保证线程安全，可以通过这些方法来保证：\n\n多线程环境可以使用Collections.synchronizedMap同步加锁的方式，还可以使用HashTable，但是同步的方式显然性能不达标，而ConurrentHashMap更适合高并发场景使用。\n\nConcurrentHashmap在JDK1.7和1.8的版本改动比较大，1.7使用Segment+HashEntry分段锁的方式实现，1.8则抛弃了Segment，改为使用CAS+synchronized+Node实现，同样也加入了红黑树，避免链表过长导致性能的问题。\n\n\n# hashmap的put过程介绍一下\nHashMap HashMap的put()方法用于向HashMap中添加键值对，当调用HashMap的put()方法时，会按照以下详细流程执行（JDK8 1.8版本）：\n\n\n\n\n\n\n\n\n\n第一步：根据要添加的键的哈希码计算在数组中的位置（索引）。\n\n\n\n\n\n\n\n\n\n第二步：检查该位置是否为空（即没有键值对存在）\n\n如果为空，则直接在该位置创建一个新的Entry对象来存储键值对。将要添加的键值对作为该Entry的键和值，并保存在数组的对应位置。将HashMap的修改次数（modCount）加1，以便在进行迭代时发现并发修改。\n\n\n\n\n\n\n\n\n\n\n第三步：如果该位置已经存在其他键值对，检查该位置的第一个键值对的哈希码和键是否与要添加的键值对相同？\n\n如果相同，则表示找到了相同的键，直接将新的值替换旧的值，完成更新操作。\n\n\n\n\n\n\n\n\n\n\n第四步：如果第一个键值对的哈希码和键不相同，则需要遍历链表或红黑树来查找是否有相同的键：\n如果键值对集合是链表结构，从链表的头部开始逐个比较键的哈希码和equals()方法，直到找到相同的键或达到链表末尾。\n\n如果找到了相同的键，则使用新的值取代旧的值，即更新键对应的值。\n如果没有找到相同的键，则将新的键值对添加到链表的头部。\n\n如果键值对集合是红黑树结构，在红黑树中使用哈希码和equals()方法进行查找。根据键的哈希码，定位到红黑树中的某个节点，然后逐个比较键，直到找到相同的键或达到红黑树末尾。\n\n如果找到了相同的键，则使用新的值取代旧的值，即更新键对应的值。\n如果没有找到相同的键，则将新的键值对添加到红黑树中。\n\n\n\n\n\n\n\n\n\n\n第五步：检查链表长度是否达到阈值（默认为8）：\n\n如果链表长度超过阈值，且HashMap的数组长度大于等于64，则会将链表转换为红黑树，以提高查询效率。\n\n\n\n\n\n\n\n\n\n\n第六步：检查负载因子是否超过阈值（默认为0.75）：\n\n如果键值对的数量（size）与数组的长度的比值大于阈值，则需要进行扩容操作。\n\n\n\n\n\n\n\n\n\n\n第七步：扩容操作：\n\n创建一个新的两倍大小的数组。\n将旧数组中的键值对重新计算哈希码并分配到新数组中的位置。\n更新HashMap的数组引用和阈值参数。\n\n\n\n\n\n\n\n\n\n\n第八步：完成添加操作。\n此外，HashMap是非线程安全的，如果在多线程环境下使用，需要采取额外的同步措施或使用线程安全的ConcurrentHashMap。\n# HashMap的put(key,val)和get(key)过程\n存储对象时，我们将K&#x2F;V传给put方法时，它调用hashCode计算hash从而得到bucket位置，进一步存储，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Facotr则resize为原来的2倍)。\n获取对象时，我们将K传给get，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。如果发生碰撞的时候，Hashmap通过链表将产生碰撞冲突的元素组织起来，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。\n\n# hashmap 调用get方法一定安全吗？不是，调用 get 方法有几点需要注意的地方：\n\n空指针异常（NullPointerException）：如果你尝试用 null 作为键调用 get 方法，而 HashMap 没有被初始化（即为 null），那么会抛出空指针异常。不过，如果 HashMap 已经初始化，使用 null 作为键是允许的，因为 HashMap 支持 null 键。\n线程安全：HashMap 本身不是线程安全的。如果在多线程环境中，没有适当的同步措施，同时对 HashMap 进行读写操作可能会导致不可预测的行为。例如，在一个线程中调用 get 方法读取数据，而另一个线程同时修改了结构（如增加或删除元素），可能会导致读取操作得到错误的结果或抛出 ConcurrentModificationException。如果需要在多线程环境中使用类似 HashMap 的数据结构，可以考虑使用 ConcurrentHashMap。\n\n# HashMap一般用什么做Key？为啥String适合做Key呢？用 string 做 key，因为 String对象是不可变的，一旦创建就不能被修改，这确保了Key的稳定性。如果Key是可变的，可能会导致hashCode和equals方法的不一致，进而影响HashMap的正确性。\n# 为什么HashMap要用红黑树而不是平衡二叉树？\n平衡二叉树追求的是一种 “完全平衡” 状态：任何结点的左右子树的高度差不会超过 1，优势是树的结点是很平均分配的。这个要求实在是太严了，导致每次进行插入&#x2F;删除节点的时候，几乎都会破坏平衡树的第二个规则，进而我们都需要通过左旋和右旋来进行调整，使之再次成为一颗符合要求的平衡树。\n红黑树不追求这种完全平衡状态，而是追求一种 “弱平衡” 状态：整个树最长路径不会超过最短路径的 2 倍。优势是虽然牺牲了一部分查找的性能效率，但是能够换取一部分维持树平衡状态的成本。与平衡树不同的是，红黑树在插入、删除等操作，不会像平衡树那样，频繁着破坏红黑树的规则，所以不需要频繁着调整，这也是我们为什么大多数情况下使用红黑树的原因。\n\n# hashmap key可以为null吗？可以为 null。\n\nhashMap中使用hash()方法来计算key的哈希值，当key为空时，直接另key的哈希值为0，不走key.hashCode()方法；\n\n\n\nhashMap虽然支持key和value为null，但是null作为key只能有一个，null作为value可以有多个；\n因为hashMap中，如果key值一样，那么会覆盖相同key值的value为最新，所以key为null只能有一个。\n\n# 重写HashMap的equal和hashcode方法需要注意什么？HashMap使用Key对象的hashCode()和equals方法去决定key-value对的索引。当我们试着从HashMap中获取值的时候，这些方法也会被用到。如果这些方法没有被正确地实现，在这种情况下，两个不同Key也许会产生相同的hashCode()和equals()输出，HashMap将会认为它们是相同的，然后覆盖它们，而非把它们存储到不同的地方。\n同样的，所有不允许存储重复数据的集合类都使用hashCode()和equals()去查找重复，所以正确实现它们非常重要。equals()和hashCode()的实现应该遵循以下规则：\n\n如果o1.equals(o2)，那么o1.hashCode() &#x3D;&#x3D; o2.hashCode()总是为true的。\n如果o1.hashCode() &#x3D;&#x3D; o2.hashCode()，并不意味着o1.equals(o2)会为true。\n\n# 重写HashMap的equal方法不当会出现什么问题？HashMap在比较元素时，会先通过hashCode进行比较，相同的情况下再通过equals进行比较。\n所以 equals相等的两个对象，hashCode一定相等。hashCode相等的两个对象，equals不一定相等（比如散列冲突的情况）\n重写了equals方法，不重写hashCode方法时，可能会出现equals方法返回为true，而hashCode方法却返回false，这样的一个后果会导致在hashmap等类中存储多个一模一样的对象，导致出现覆盖存储的数据的问题，这与hashmap只能有唯一的key的规范不符合。\n# 列举HashMap在多线程下可能会出现的问题？\nJDK1.7中的 HashMap 使用头插法插入元素，在多线程的环境下，扩容的时候有可能导致环形链表的出现，形成死循环。因此，JDK1.8使用尾插法插入元素，在扩容时会保持链表元素原本的顺序，不会出现环形链表的问题。\n多线程同时执行 put 操作，如果计算出来的索引位置是相同的，那会造成前一个 key 被后一个 key 覆盖，从而导致元素的丢失。此问题在JDK 1.7和 JDK 1.8 中都存在。\n\n# HashMap的扩容机制介绍一下hashMap默认的负载因子是0.75，即如果hashmap中的元素个数超过了总容量75%，则会触发扩容，扩容分为两个步骤：\n\n第1步是对哈希表长度的扩展（2倍）\n第2步是将旧哈希表中的数据放到新的哈希表中。\n\n因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。\n如我们从16扩展为32时，具体的变化如下所示：\n\n因此元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：\n\n因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。可以看看下图为16扩充为32的resize示意图：\n\n这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。\n# HashMap的大小为什么是2的n次方大小呢？在 JDK1.7 中，HashMap 整个扩容过程就是分别取出数组元素，一般该元素是最后一个放入链表中的元素，然后遍历以该元素为头的单向链表元素，依据每个被遍历元素的 hash 值计算其在新数组中的下标，然后进行交换。这样的扩容方式会将原来哈希冲突的单向链表尾部变成扩容后单向链表的头部。\n而在 JDK 1.8 中，HashMap 对扩容操作做了优化。由于扩容数组的长度是 2 倍关系，所以对于假设初始 tableSize &#x3D; 4 要扩容到 8 来说就是 0100 到 1000 的变化（左移一位就是 2 倍），在扩容中只用判断原来的 hash 值和左移动的一位（newtable 的值）按位与操作是 0 或 1 就行，0 的话索引不变，1 的话索引变成原索引加上扩容前数组。\n之所以能通过这种“与运算“来重新分配索引，是因为 hash 值本来就是随机的，而 hash 按位与上 newTable 得到的 0（扩容前的索引位置）和 1（扩容前索引位置加上扩容前数组长度的数值索引处）就是随机的，所以扩容的过程就能把之前哈希冲突的元素再随机分布到不同的索引中去。\n# 往hashmap存20个元素，会扩容几次？当插入 20 个元素时，HashMap 的扩容过程如下：\n初始容量：16\n\n插入第 1 到第 12 个元素时，不需要扩容。\n插入第 13 个元素时，达到负载因子限制，需要扩容。此时，HashMap 的容量从 16 扩容到 32。\n\n扩容后的容量：32\n\n插入第 14 到第 24 个元素时，不需要扩容。\n\n因此，总共会进行一次扩容。\n# 说说hashmap的负载因子HashMap 负载因子 loadFactor 的默认值是 0.75，当 HashMap 中的元素个数超过了容量的 75% 时，就会进行扩容。\n默认负载因子为 0.75，是因为它提供了空间和时间复杂度之间的良好平衡。\n负载因子太低会导致大量的空桶浪费空间，负载因子太高会导致大量的碰撞，降低性能。0.75 的负载因子在这两个因素之间取得了良好的平衡。\n# Hashmap和Hashtable有什么不一样的？Hashmap一般怎么用？\nHashMap线程不安全，效率高一点，可以存储null的key和value，null的key只能有一个，null的value可以有多个。默认初始容量为16，每次扩充变为原来2倍。创建时如果给定了初始容量，则扩充为2的幂次方大小。底层数据结构为数组+链表，插入元素后如果链表长度大于阈值（默认为8），先判断数组长度是否小于64，如果小于，则扩充数组，反之将链表转化为红黑树，以减少搜索时间。\nHashTable线程安全，效率低一点，其内部方法基本都经过synchronized修饰，不可以有null的key和value。默认初始容量为11，每次扩容变为原来的2n+1。创建时给定了初始容量，会直接用给定的大小。底层数据结构为数组+链表。它基本被淘汰了，要保证线程安全可以用ConcurrentHashMap。\n怎么用：HashMap主要用来存储键值对，可以调用put方法向其中加入元素，调用get方法获取某个键对应的值，也可以通过containsKey方法查看某个键是否存在等\n\n# ConcurrentHashMap怎么实现的？\n\n\n\n\n\n\n\n\nJDK 1.7 ConcurrentHashMap\n在 JDK 1.7 中它使用的是数组加链表的形式实现的，而数组又分为：大数组 Segment 和小数组 HashEntry。 Segment 是一种可重入锁（ReentrantLock），在 ConcurrentHashMap 里扮演锁的角色；HashEntry 则用于存储键值对数据。一个 ConcurrentHashMap 里包含一个 Segment 数组，一个 Segment 里包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素。\n\nJDK 1.7 ConcurrentHashMap 分段锁技术将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。\n\n\n\n\n\n\n\n\n\nJDK 1.8 ConcurrentHashMap\n在 JDK 1.7 中，ConcurrentHashMap 虽然是线程安全的，但因为它的底层实现是数组 + 链表的形式，所以在数据比较多的情况下访问是很慢的，因为要遍历整个链表，而 JDK 1.8 则使用了数组 + 链表&#x2F;红黑树的方式优化了 ConcurrentHashMap 的实现，具体实现结构如下：\n\nJDK 1.8 ConcurrentHashMap JDK 1.8 ConcurrentHashMap 主要通过 volatile + CAS 或者 synchronized 来实现的线程安全的。添加元素时首先会判断容器是否为空：\n\n如果为空则使用 volatile 加 CAS 来初始化\n如果容器不为空，则根据存储的元素计算该位置是否为空。\n如果根据存储的元素计算结果为空，则利用 CAS 设置该节点；\n如果根据存储的元素计算结果不为空，则使用 synchronized ，然后，遍历桶中的数据，并替换或新增节点到桶中，最后再判断是否需要转为红黑树，这样就能保证并发访问时的线程安全了。\n\n\n\n如果把上面的执行用一句话归纳的话，就相当于是ConcurrentHashMap通过对头结点加锁来保证线程安全的，锁的粒度相比 Segment 来说更小了，发生冲突和加锁的频率降低了，并发操作的性能就提高了。\n而且 JDK 1.8 使用的是红黑树优化了之前的固定链表，那么当数据量比较大的时候，查询性能也得到了很大的提升，从之前的 O(n) 优化到了 O(logn) 的时间复杂度。\n# 分段锁怎么加锁的？在 ConcurrentHashMap 中，将整个数据结构分为多个 Segment，每个 Segment 都类似于一个小的 HashMap，每个 Segment 都有自己的锁，不同 Segment 之间的操作互不影响，从而提高并发性能。\n在 ConcurrentHashMap 中，对于插入、更新、删除等操作，需要先定位到具体的 Segment，然后再在该 Segment 上加锁，而不是像传统的 HashMap 一样对整个数据结构加锁。这样可以使得不同 Segment 之间的操作并行进行，提高了并发性能。\n# 分段锁是可重入的吗？JDK 1.7 ConcurrentHashMap中的分段锁是用了 ReentrantLock，是一个可重入的锁。\n# 已经用了synchronized，为什么还要用CAS呢？ConcurrentHashMap使用这两种手段来保证线程安全主要是一种权衡的考虑，在某些操作中使用synchronized，还是使用CAS，主要是根据锁竞争程度来判断的。\n比如：在putVal中，如果计算出来的hash槽没有存放元素，那么就可以直接使用CAS来进行设置值，这是因为在设置元素的时候，因为hash值经过了各种扰动后，造成hash碰撞的几率较低，那么我们可以预测使用较少的自旋来完成具体的hash落槽操作。\n当发生了hash碰撞的时候说明容量不够用了或者已经有大量线程访问了，因此这时候使用synchronized来处理hash碰撞比CAS效率要高，因为发生了hash碰撞大概率来说是线程竞争比较强烈。\n# ConcurrentHashMap用了悲观锁还是乐观锁?悲观锁和乐观锁都有用到。\n添加元素时首先会判断容器是否为空：\n\n如果为空则使用 volatile 加 CAS （乐观锁） 来初始化。\n\n如果容器不为空，则根据存储的元素计算该位置是否为空。\n\n如果根据存储的元素计算结果为空，则利用 CAS（乐观锁） 设置该节点；\n\n如果根据存储的元素计算结果不为空，则使用 synchronized（悲观锁） ，然后，遍历桶中的数据，并替换或新增节点到桶中，最后再判断是否需要转为红黑树，这样就能保证并发访问时的线程安全了。\n\n\n# HashTable 底层实现原理是什么？\n\nHashtable的底层数据结构主要是数组加上链表，数组是主体，链表是解决hash冲突存在的。\nHashTable是线程安全的，实现方式是Hashtable的所有公共方法均采用synchronized关键字，当一个线程访问同步方法，另一个线程也访问的时候，就会陷入阻塞或者轮询的状态。\n\n# HashTable线程安全是怎么实现的？因为它的put，get做成了同步方法，保证了Hashtable的线程安全性，每个操作数据的方法都进行同步控制之后，由此带来的问题任何一个时刻只能有一个线程可以操纵Hashtable，所以其效率比较低。\nHashtable 的 put(K key, V value) 和 get(Object key) 方法的源码：\n123456789101112131415161718192021222324252627282930313233public synchronized V put(K key, V value) &#123;// Make sure the value is not nullif (value == null) &#123;    throw new NullPointerException();&#125; // Makes sure the key is not already in the hashtable.Entry&lt;?,?&gt; tab[] = table;int hash = key.hashCode();int index = (hash &amp; 0x7FFFFFFF) % tab.length;@SuppressWarnings(&quot;unchecked&quot;)Entry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index];for(; entry != null ; entry = entry.next) &#123;    if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123;        V old = entry.value;        entry.value = value;        return old;    &#125;&#125; addEntry(hash, key, value, index);return null;&#125;public synchronized V get(Object key) &#123;Entry&lt;?,?&gt; tab[] = table;int hash = key.hashCode();int index = (hash &amp; 0x7FFFFFFF) % tab.length;for (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) &#123;    if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123;        return (V)e.value;    &#125;&#125;return null;&#125;\n\n可以看到，Hashtable是通过使用了 synchronized 关键字来保证其线程安全。\n在Java中，可以使用synchronized关键字来标记一个方法或者代码块，当某个线程调用该对象的synchronized方法或者访问synchronized代码块时，这个线程便获得了该对象的锁，其他线程暂时无法访问这个方法，只有等待这个方法执行完毕或者代码块执行完毕，这个线程才会释放该对象的锁，其他线程才能执行这个方法或者代码块。\n# hashtable 和concurrentHashMap有什么区别底层数据结构：\n\njdk7之前的ConcurrentHashMap底层采用的是分段的数组+链表实现，jdk8之后采用的是数组+链表&#x2F;红黑树；\nHashTable采用的是数组+链表，数组是主体，链表是解决hash冲突存在的。\n\n实现线程安全的方式：\n\njdk8以前，ConcurrentHashMap采用分段锁，对整个数组进行了分段分割，每一把锁只锁容器里的一部分数据，多线程访问不同数据段里的数据，就不会存在锁竞争，提高了并发访问；jdk8以后，直接采用数组+链表&#x2F;红黑树，并发控制使用CAS和synchronized操作，更加提高了速度。\nHashTable：所有的方法都加了锁来保证线程安全，但是效率非常的低下，当一个线程访问同步方法，另一个线程也访问的时候，就会陷入阻塞或者轮询的状态。\n\n# 说一下HashMap和Hashtable、ConcurrentMap的区别\nHashMap线程不安全，效率高一点，可以存储null的key和value，null的key只能有一个，null的value可以有多个。默认初始容量为16，每次扩充变为原来2倍。创建时如果给定了初始容量，则扩充为2的幂次方大小。底层数据结构为数组+链表，插入元素后如果链表长度大于阈值（默认为8），先判断数组长度是否小于64，如果小于，则扩充数组，反之将链表转化为红黑树，以减少搜索时间。\nHashTable线程安全，效率低一点，其内部方法基本都经过synchronized修饰，不可以有null的key和value。默认初始容量为11，每次扩容变为原来的2n+1。创建时给定了初始容量，会直接用给定的大小。底层数据结构为数组+链表。它基本被淘汰了，要保证线程安全可以用ConcurrentHashMap。\nConcurrentHashMap是Java中的一个线程安全的哈希表实现，它可以在多线程环境下并发地进行读写操作，而不需要像传统的HashTable那样在读写时加锁。ConcurrentHashMap的实现原理主要基于分段锁和CAS操作。它将整个哈希表分成了多Segment（段），每个Segment都类似于一个小的HashMap，它拥有自己的数组和一个独立的锁。在ConcurrentHashMap中，读操作不需要锁，可以直接对Segment进行读取，而写操作则只需要锁定对应的Segment，而不是整个哈希表，这样可以大大提高并发性能。\n\n# Set# Set集合有什么特点？如何实现key无重复的？\nset集合特点：Set集合中的元素是唯一的，不会出现重复的元素。\nset实现原理：Set集合通过内部的数据结构（如哈希表、红黑树等）来实现key的无重复。当向Set集合中插入元素时，会先根据元素的hashCode值来确定元素的存储位置，然后再通过equals方法来判断是否已经存在相同的元素，如果存在则不会再次插入，保证了元素的唯一性。\n\n# 有序的Set是什么？记录插入顺序的集合是什么？\n有序的 Set 是TreeSet和LinkedHashSet。TreeSet是基于红黑树实现，保证元素的自然顺序。LinkedHashSet是基于双重链表和哈希表的结合来实现元素的有序存储，保证元素添加的自然顺序\n记录插入顺序的集合通常指的是LinkedHashSet，它不仅保证元素的唯一性，还可以保持元素的插入顺序。当需要在Set集合中记录元素的插入顺序时，可以选择使用LinkedHashSet来实现。\n\n\n","slug":"java集合/Java集合面试题","date":"2024-12-03T17:46:32.000Z","categories_index":"八股","tags_index":"java,精选,java集合","author_index":"Ivan"},{"id":"fc6088a2cdd600ff4c6d74daed64c2a4","title":"并发上","content":"# Java并发编程# 多线程# java里面的线程和操作系统的线程一样吗？Java 底层会调用 pthread_create 来创建线程，所以本质上 java 程序创建的线程，就是和操作系统线程是一样的，是 1 对 1 的线程模型。\n\n# 使用多线程要注意哪些问题？要保证多线程的允许是安全，不要出现数据竞争造成的数据混乱的问题。\nJava的线程安全在三个方面体现：\n\n原子性：提供互斥访问，同一时刻只能有一个线程对数据进行操作，在Java中使用了atomic和synchronized这两个关键字来确保原子性；\n可见性：一个线程对主内存的修改可以及时地被其他线程看到，在Java中使用了synchronized和volatile这两个关键字确保可见性；\n有序性：一个线程观察其他线程中的指令执行顺序，由于指令重排序，该观察结果一般杂乱无序，在Java中使用了happens-before原则来确保有序性。\n\n# 保证数据的一致性有哪些方案呢？\n事务管理：使用数据库事务来确保一组数据库操作要么全部成功提交，要么全部失败回滚。通过ACID（原子性、一致性、隔离性、持久性）属性，数据库事务可以保证数据的一致性。\n锁机制：使用锁来实现对共享资源的互斥访问。在 Java 中，可以使用 synchronized 关键字、ReentrantLock 或其他锁机制来控制并发访问，从而避免并发操作导致数据不一致。\n版本控制：通过乐观锁的方式，在更新数据时记录数据的版本信息，从而避免同时对同一数据进行修改，进而保证数据的一致性。\n\n# 线程的创建方式有哪些?\n\n\n\n\n\n\n\n\n1.继承Thread类\n这是最直接的一种方式，用户自定义类继承java.lang.Thread类，重写其run()方法，run()方法中定义了线程执行的具体任务。创建该类的实例后，通过调用start()方法启动线程。\n1234567891011class MyThread extends Thread &#123;    @Override    public void run() &#123;        // 线程执行的代码    &#125;&#125;public static void main(String[] args) &#123;    MyThread t = new MyThread();    t.start();&#125;\n\n采用继承Thread类方式\n\n优点: 编写简单，如果需要访问当前线程，无需使用Thread.currentThread ()方法，直接使用this，即可获得当前线程\n缺点:因为线程类已经继承了Thread类，所以不能再继承其他的父类\n\n\n\n\n\n\n\n\n\n\n2.实现Runnable接口\n如果一个类已经继承了其他类，就不能再继承Thread类，此时可以实现java.lang.Runnable接口。实现Runnable接口需要重写run()方法，然后将此Runnable对象作为参数传递给Thread类的构造器，创建Thread对象后调用其start()方法启动线程。\n1234567891011class MyRunnable implements Runnable &#123;    @Override    public void run() &#123;        // 线程执行的代码    &#125;&#125;public static void main(String[] args) &#123;    Thread t = new Thread(new MyRunnable());    t.start();&#125;\n\n采用实现Runnable接口方式：\n\n优点：线程类只是实现了Runable接口，还可以继承其他的类。在这种方式下，可以多个线程共享同一个目标对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。\n缺点：编程稍微复杂，如果需要访问当前线程，必须使用Thread.currentThread()方法。\n\n\n\n\n\n\n\n\n\n\n\n实现Callable接口与FutureTask\n\njava.util.concurrent.Callable接口类似于Runnable，但Callable的call()方法可以有返回值并且可以抛出异常。要执行Callable任务，需将它包装进一个FutureTask，因为Thread类的构造器只接受Runnable参数，而FutureTask实现了Runnable接口。\n123456789101112131415161718192021class MyCallable implements Callable&lt;Integer&gt; &#123;    @Override    public Integer call() throws Exception &#123;        // 线程执行的代码，这里返回一个整型结果        return 1;    &#125;&#125;public static void main(String[] args) &#123;    MyCallable task = new MyCallable();    FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(task);    Thread t = new Thread(futureTask);    t.start();    try &#123;        Integer result = futureTask.get();  // 获取线程执行结果        System.out.println(&quot;Result: &quot; + result);    &#125; catch (InterruptedException | ExecutionException e) &#123;        e.printStackTrace();    &#125;&#125;\n\n采用实现Callable接口方式：\n\n缺点：编程稍微复杂，如果需要访问当前线程，必须调用Thread.currentThread()方法。\n优点：线程只是实现Runnable或实现Callable接口，还可以继承其他类。这种方式下，多个线程可以共享一个target对象，非常适合多线程处理同一份资源的情形。\n\n\n\n\n\n\n\n\n\n\n\n使用线程池（Executor框架）\n\n从Java 5开始引入的java.util.concurrent.ExecutorService和相关类提供了线程池的支持，这是一种更高效的线程管理方式，避免了频繁创建和销毁线程的开销。可以通过Executors类的静态方法创建不同类型的线程池。\n1234567891011121314class Task implements Runnable &#123;    @Override    public void run() &#123;        // 线程执行的代码    &#125;&#125;public static void main(String[] args) &#123;    ExecutorService executor = Executors.newFixedThreadPool(10);  // 创建固定大小的线程池    for (int i = 0; i &lt; 100; i++) &#123;        executor.submit(new Task());  // 提交任务到线程池执行    &#125;    executor.shutdown();  // 关闭线程池&#125;\n\n采用线程池方式：\n\n缺点：程池增加了程序的复杂度，特别是当涉及线程池参数调整和故障排查时。错误的配置可能导致死锁、资源耗尽等问题，这些问题的诊断和修复可能较为复杂。\n优点：线程池可以重用预先创建的线程，避免了线程创建和销毁的开销，显著提高了程序的性能。对于需要快速响应的并发请求，线程池可以迅速提供线程来处理任务，减少等待时间。并且，线程池能够有效控制运行的线程数量，防止因创建过多线程导致的系统资源耗尽（如内存溢出）。通过合理配置线程池大小，可以最大化CPU利用率和系统吞吐量。\n\n# 怎么启动线程 ？启动线程的通过Thread类的**start()**。\n12345//创建两个线程，用start启动线程MyThread myThread1 = new MyThread();  MyThread myThread2 = new MyThread();  myThread1.start();  myThread2.start();  \n\n# 如何停止一个线程的运行?主要有这些方法：\n\n异常法停止：线程调用interrupt()方法后，在线程的run方法中判断当前对象的interrupted()状态，如果是中断状态则抛出异常，达到中断线程的效果。\n在沉睡中停止：先将线程sleep，然后调用interrupt标记中断状态，interrupt会将阻塞状态的线程中断。会抛出中断异常，达到停止线程的效果\nstop()暴力停止：线程调用stop()方法会被暴力停止，方法已弃用，该方法会有不好的后果：强制让线程停止有可能使一些请理性的工作得不到完成。\n使用return停止线程：调用interrupt标记为中断状态后，在run方法中判断当前线程状态，如果为中断状态则return，能达到停止线程的效果。\n\n# 调用 interrupt 是如何让线程抛出异常的?每个线程都一个与之关联的布尔属性来表示其中断状态，中断状态的初始值为false，当一个线程被其它线程调用Thread.interrupt()方法中断时，会根据实际情况做出响应。\n\n如果该线程正在执行低级别的可中断方法（如Thread.sleep()、Thread.join()或Object.wait()），则会解除阻塞并抛出InterruptedException异常。\n否则Thread.interrupt()仅设置线程的中断状态，在该被中断的线程中稍后可通过轮询中断状态来决定是否要停止当前正在执行的任务。\n\n# Java线程的状态有哪些？\n源自《Java并发编程艺术》 java.lang.Thread.State枚举类中定义了六种线程的状态，可以调用线程Thread中的getState()方法获取当前线程的状态。\n\n\n\n线程状态\n解释\n\n\n\nNEW\n尚未启动的线程状态，即线程创建，还未调用start方法\n\n\nRUNNABLE\n就绪状态（调用start，等待调度）+正在运行\n\n\nBLOCKED\n等待监视器锁时，陷入阻塞状态\n\n\nWAITING\n等待状态的线程正在等待另一线程执行特定的操作（如notify）\n\n\nTIMED_WAITING\n具有指定等待时间的等待状态\n\n\nTERMINATED\n线程完成执行，终止状态\n\n\n# blocked和waiting有啥区别\n触发条件:线程进入BLOCKED状态通常是因为试图获取一个对象的锁（monitor lock），但该锁已经被另一个线程持有。这通常发生在尝试进入synchronized块或方法时，如果锁已被占用，则线程将被阻塞直到锁可用。线程进入WAITING状态是因为它正在等待另一个线程执行某些操作，例如调用Object.wait()方法、Thread.join()方法或LockSupport.park()方法。在这种状态下，线程将不会消耗CPU资源，并且不会参与锁的竞争。\n唤醒机制:当一个线程被阻塞等待锁时，一旦锁被释放，线程将有机会重新尝试获取锁。如果锁此时未被其他线程获取，那么线程可以从BLOCKED状态变为RUNNABLE状态。线程在WAITING状态中需要被显式唤醒。例如，如果线程调用了Object.wait()，那么它必须等待另一个线程调用同一对象上的Object.notify()或Object.notifyAll()方法才能被唤醒。\n\n# wait 状态下的线程如何进行恢复到 running 状态?\n等待的线程被其他线程对象唤醒，notify()和notifyAll()。\n如果线程没有获取到锁则会直接进入 Waiting 状态，其实这种本质上它就是执行了 LockSupport.park() 方法进入了Waiting 状态，那么解锁的时候会执行LockSupport.unpark(Thread)，与上面park方法对应，给出许可证，解除等待状态。\n\n# notify 和 notifyAll 的区别?同样是唤醒等待的线程，同样最多只有一个线程能获得锁，同样不能控制哪个线程获得锁。\n区别在于：\n\nnotify：唤醒一个线程，其他线程依然处于wait的等待唤醒状态，如果被唤醒的线程结束时没调用notify，其他线程就永远没人去唤醒，只能等待超时，或者被中断\nnotifyAll：所有线程退出wait的状态，开始竞争锁，但只有一个线程能抢到，这个线程执行完后，其他线程又会有一个幸运儿脱颖而出得到锁\n\n# notify 选择哪个线程?notify在源码的注释中说到notify选择唤醒的线程是任意的，但是依赖于具体实现的jvm。\n\nJVM有很多实现，比较流行的就是hotspot，hotspot对notofy()的实现并不是我们以为的随机唤醒,，而是“先进先出”的顺序唤醒。\n# 并发安全# 怎么保证多线程安全？\nsynchronized关键字:可以使用synchronized关键字来同步代码块或方法，确保同一时刻只有一个线程可以访问这些代码。对象锁是通过synchronized关键字锁定对象的监视器（monitor）来实现的。\n\n1234567public synchronized void someMethod() &#123; /* ... */ &#125;public void anotherMethod() &#123;    synchronized (someObject) &#123;        /* ... */    &#125;&#125;\n\n\nvolatile关键字:volatile关键字用于变量，确保所有线程看到的是该变量的最新值，而不是可能存储在本地寄存器中的副本。\n\n1public volatile int sharedVariable;\n\n\nLock接口和ReentrantLock类:java.util.concurrent.locks.Lock接口提供了比synchronized更强大的锁定机制，ReentrantLock是一个实现该接口的例子，提供了更灵活的锁管理和更高的性能。\n\n12345678910private final ReentrantLock lock = new ReentrantLock();public void someMethod() &#123;    lock.lock();    try &#123;        /* ... */    &#125; finally &#123;        lock.unlock();    &#125;&#125;\n\n\n原子类：Java并发库（java.util.concurrent.atomic）提供了原子类，如AtomicInteger、AtomicLong等，这些类提供了原子操作，可以用于更新基本类型的变量而无需额外的同步。\n\n示例：\n123AtomicInteger counter = new AtomicInteger(0);int newValue = counter.incrementAndGet();\n\n\n线程局部变量:ThreadLocal类可以为每个线程提供独立的变量副本，这样每个线程都拥有自己的变量，消除了竞争条件。\n\n1234ThreadLocal&lt;Integer&gt; threadLocalVar = new ThreadLocal&lt;&gt;();threadLocalVar.set(10);int value = threadLocalVar.get();\n\n\n并发集合:使用java.util.concurrent包中的线程安全集合，如ConcurrentHashMap、ConcurrentLinkedQueue等，这些集合内部已经实现了线程安全的逻辑。\nJUC工具类: 使用java.util.concurrent包中的一些工具类可以用于控制线程间的同步和协作。例如：Semaphore和CyclicBarrier等。\n\n# Java中有哪些常用的锁，在什么场景下使用？ava中的锁是用于管理多线程并发访问共享资源的关键机制。锁可以确保在任意给定时间内只有一个线程可以访问特定的资源，从而避免数据竞争和不一致性。Java提供了多种锁机制，可以分为以下几类：\n\n内置锁（synchronized）：Java中的synchronized关键字是内置锁机制的基础，可以用于方法或代码块。当一个线程进入synchronized代码块或方法时，它会获取关联对象的锁；当线程离开该代码块或方法时，锁会被释放。如果其他线程尝试获取同一个对象的锁，它们将被阻塞，直到锁被释放。其中，syncronized加锁时有无锁、偏向锁、轻量级锁和重量级锁几个级别。偏向锁用于当一个线程进入同步块时，如果没有任何其他线程竞争，就会使用偏向锁，以减少锁的开销。轻量级锁使用线程栈上的数据结构，避免了操作系统级别的锁。重量级锁则涉及操作系统级的互斥锁。\nReentrantLock：java.util.concurrent.locks.ReentrantLock是一个显式的锁类，提供了比synchronized更高级的功能，如可中断的锁等待、定时锁等待、公平锁选项等。ReentrantLock使用lock()和unlock()方法来获取和释放锁。其中，公平锁按照线程请求锁的顺序来分配锁，保证了锁分配的公平性，但可能增加锁的等待时间。非公平锁不保证锁分配的顺序，可以减少锁的竞争，提高性能，但可能造成某些线程的饥饿。\n读写锁（ReadWriteLock）：java.util.concurrent.locks.ReadWriteLock接口定义了一种锁，允许多个读取者同时访问共享资源，但只允许一个写入者。读写锁通常用于读取远多于写入的情况，以提高并发性。\n乐观锁和悲观锁：悲观锁（Pessimistic Locking）通常指在访问数据前就锁定资源，假设最坏的情况，即数据很可能被其他线程修改。synchronized和ReentrantLock都是悲观锁的例子。乐观锁（Optimistic Locking）通常不锁定资源，而是在更新数据时检查数据是否已被其他线程修改。乐观锁常使用版本号或时间戳来实现。\n自旋锁：自旋锁是一种锁机制，线程在等待锁时会持续循环检查锁是否可用，而不是放弃CPU并阻塞。通常可以使用CAS来实现。这在锁等待时间很短的情况下可以提高性能，但过度自旋会浪费CPU资源。\n\n# 怎么在实践中用锁的？Java提供了多种锁的实现，包括synchronized关键字、java.util.concurrent.locks包下的Lock接口及其具体实现如ReentrantLock、ReadWriteLock等。下面我们来看看这些锁的使用方式。\n\n\n\n\n\n\n\n\n\n\nsynchronized\n\nsynchronized关键字可以用于方法或代码块，它是Java中最早的锁实现，使用起来非常简单。\n示例：synchronized方法\n1234567891011public class Counter &#123;    private int count = 0;    public synchronized void increment() &#123;        count++;    &#125;    public synchronized int getCount() &#123;        return count;    &#125;&#125;\n\n示例：synchronized代码块\n12345678910public class Counter &#123;    private Object lock = new Object();    private int count = 0;    public void increment() &#123;        synchronized (lock) &#123;            count++;        &#125;    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n\n使用Lock接口\n\nLock接口提供了比synchronized更灵活的锁操作，包括尝试锁、可中断锁、定时锁等。ReentrantLock是Lock接口的一个实现。\n示例：使用ReentrantLock\n12345678910111213141516import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class Counter &#123;    private Lock lock = new ReentrantLock();    private int count = 0;    public void increment() &#123;        lock.lock();        try &#123;            count++;        &#125; finally &#123;            lock.unlock();        &#125;    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n\n使用ReadWriteLock\n\nReadWriteLock接口提供了一种读写锁的实现，允许多个读操作同时进行，但写操作是独占的。\n示例：使用ReadWriteLock\n12345678910111213141516171819202122232425262728import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReadWriteLock;import java.util.concurrent.locks.ReentrantReadWriteLock;public class Cache &#123;    private ReadWriteLock lock = new ReentrantReadWriteLock();    private Lock readLock = lock.readLock();    private Lock writeLock = lock.writeLock();    private Object data;    public Object readData() &#123;        readLock.lock();        try &#123;            return data;        &#125; finally &#123;            readLock.unlock();        &#125;    &#125;    public void writeData(Object newData) &#123;        writeLock.lock();        try &#123;            data = newData;        &#125; finally &#123;            writeLock.unlock();        &#125;    &#125;&#125;\n\n# synchronized和reentrantlock及其应用场景？\n\n\n\n\n\n\n\n\nsynchronized 工作原理\nsynchronized是Java提供的原子性内置锁，这种内置的并且使用者看不到的锁也被称为监视器锁，\n使用synchronized之后，会在编译之后在同步的代码块前后加上monitorenter和monitorexit字节码指令，他依赖操作系统底层互斥锁实现。他的作用主要就是实现原子性操作和解决共享变量的内存可见性问题。\n执行monitorenter指令时会尝试获取对象锁，如果对象没有被锁定或者已经获得了锁，锁的计数器+1。此时其他竞争锁的线程则会进入等待队列中。执行monitorexit指令时则会把计数器-1，当计数器值为0时，则锁释放，处于等待队列中的线程再继续竞争锁。\nsynchronized是排它锁，当一个线程获得锁之后，其他线程必须等待该线程释放锁后才能获得锁，而且由于Java中的线程和操作系统原生线程是一一对应的，线程被阻塞或者唤醒时时会从用户态切换到内核态，这种转换非常消耗性能。\n从内存语义来说，加锁的过程会清除工作内存中的共享变量，再从主内存读取，而释放锁的过程则是将工作内存中的共享变量写回主内存。\n实际上大部分时候我认为说到monitorenter就行了，但是为了更清楚的描述，还是再具体一点。\n如果再深入到源码来说，synchronized实际上有两个队列waitSet和entryList。\n\n当多个线程进入同步代码块时，首先进入entryList\n有一个线程获取到monitor锁后，就赋值给当前线程，并且计数器+1\n如果线程调用wait方法，将释放锁，当前线程置为null，计数器-1，同时进入waitSet等待被唤醒，调用notify或者notifyAll之后又会进入entryList竞争锁\n如果线程执行完毕，同样释放锁，计数器-1，当前线程置为null\n\n\n\n\n\n\n\n\n\n\nreentrantlock工作原理\nReentrantLock 的底层实现主要依赖于 AbstractQueuedSynchronizer（AQS）这个抽象类。AQS 是一个提供了基本同步机制的框架，其中包括了队列、状态值等。\nReentrantLock 在 AQS 的基础上通过内部类 Sync 来实现具体的锁操作。不同的 Sync 子类实现了公平锁和非公平锁的不同逻辑：\n\n可中断性： ReentrantLock 实现了可中断性，这意味着线程在等待锁的过程中，可以被其他线程中断而提前结束等待。在底层，ReentrantLock 使用了与 LockSupport.park() 和 LockSupport.unpark() 相关的机制来实现可中断性。\n设置超时时间： ReentrantLock 支持在尝试获取锁时设置超时时间，即等待一定时间后如果还未获得锁，则放弃锁的获取。这是通过内部的 tryAcquireNanos 方法来实现的。\n公平锁和非公平锁： 在直接创建 ReentrantLock 对象时，默认情况下是非公平锁。公平锁是按照线程等待的顺序来获取锁，而非公平锁则允许多个线程在同一时刻竞争锁，不考虑它们申请锁的顺序。公平锁可以通过在创建 ReentrantLock 时传入 true 来设置，例如：\n\n1ReentrantLock fairLock = new ReentrantLock(true);\n\n\n多个条件变量： ReentrantLock 支持多个条件变量，每个条件变量可以与一个 ReentrantLock 关联。这使得线程可以更灵活地进行等待和唤醒操作，而不仅仅是基于对象监视器的 wait() 和 notify()。多个条件变量的实现依赖于 Condition 接口，例如：\n\n12345ReentrantLock lock = new ReentrantLock();Condition condition = lock.newCondition();// 使用下面方法进行等待和唤醒condition.await();condition.signal();\n\n\n可重入性： ReentrantLock 支持可重入性，即同一个线程可以多次获得同一把锁，而不会造成死锁。这是通过内部的 holdCount 计数来实现的。当一个线程多次获取锁时，holdCount 递增，释放锁时递减，只有当 holdCount 为零时，其他线程才有机会获取锁。\n\n\n\n\n\n\n\n\n\n\n应用场景的区别\nsynchronized：\n\n简单同步需求： 当你需要对代码块或方法进行简单的同步控制时，synchronized是一个很好的选择。它使用起来简单，不需要额外的资源管理，因为锁会在方法退出或代码块执行完毕后自动释放。\n代码块同步： 如果你想对特定代码段进行同步，而不是整个方法，可以使用synchronized代码块。这可以让你更精细地控制同步的范围，从而减少锁的持有时间，提高并发性能。\n内置锁的使用： synchronized关键字使用对象的内置锁（也称为监视器锁），这在需要使用对象作为锁对象的情况下很有用，尤其是在对象状态与锁保护的代码紧密相关时。\n\nReentrantLock：\n\n高级锁功能需求： ReentrantLock提供了synchronized所不具备的高级功能，如公平锁、响应中断、定时锁尝试、以及多个条件变量。当你需要这些功能时，ReentrantLock是更好的选择。\n性能优化： 在高度竞争的环境中，ReentrantLock可以提供比synchronized更好的性能，因为它提供了更细粒度的控制，如尝试锁定和定时锁定，可以减少线程阻塞的可能性。\n复杂同步结构： 当你需要更复杂的同步结构，如需要多个条件变量来协调线程之间的通信时，ReentrantLock及其配套的Condition对象可以提供更灵活的解决方案。\n\n综上，synchronized适用于简单同步需求和不需要额外锁功能的场景，而ReentrantLock适用于需要更高级锁功能、性能优化或复杂同步逻辑的情况。选择哪种同步机制取决于具体的应用需求和性能考虑。\n# synchronized和reentrantlock区别？synchronized 和 ReentrantLock 都是 Java 中提供的可重入锁：\n\n用法不同：synchronized 可用来修饰普通方法、静态方法和代码块，而 ReentrantLock 只能用在代码块上。\n获取锁和释放锁方式不同：synchronized 会自动加锁和释放锁，当进入 synchronized 修饰的代码块之后会自动加锁，当离开 synchronized 的代码段之后会自动释放锁。而 ReentrantLock 需要手动加锁和释放锁\n锁类型不同：synchronized 属于非公平锁，而 ReentrantLock 既可以是公平锁也可以是非公平锁。\n响应中断不同：ReentrantLock 可以响应中断，解决死锁的问题，而 synchronized 不能响应中断。\n底层实现不同：synchronized 是 JVM 层面通过监视器实现的，而 ReentrantLock 是基于 AQS 实现的。\n\n# 怎么理解可重入锁？可重入锁是指同一个线程在获取了锁之后，可以再次重复获取该锁而不会造成死锁或其他问题。当一个线程持有锁时，如果再次尝试获取该锁，就会成功获取而不会被阻塞。\nReentrantLock实现可重入锁的机制是基于线程持有锁的计数器。\n\n当一个线程第一次获取锁时，计数器会加1，表示该线程持有了锁。在此之后，如果同一个线程再次获取锁，计数器会再次加1。每次线程成功获取锁时，都会将计数器加1。\n当线程释放锁时，计数器会相应地减1。只有当计数器减到0时，锁才会完全释放，其他线程才有机会获取锁。\n\n这种计数器的设计使得同一个线程可以多次获取同一个锁，而不会造成死锁或其他问题。每次获取锁时，计数器加1；每次释放锁时，计数器减1。只有当计数器减到0时，锁才会完全释放。\nReentrantLock通过这种计数器的方式，实现了可重入锁的机制。它允许同一个线程多次获取同一个锁，并且能够正确地处理锁的获取和释放，避免了死锁和其他并发问题。\n# synchronized 支持重入吗？如何实现的?synchronized是基于原子性的内部锁机制，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的，这就是synchronized的可重入性。\nsynchronized底层是利用计算机系统mutex Lock实现的。每一个可重入锁都会关联一个线程ID和一个锁状态status。\n当一个线程请求方法时，会去检查锁状态。\n\n如果锁状态是0，代表该锁没有被占用，使用CAS操作获取锁，将线程ID替换成自己的线程ID。\n如果锁状态不是0，代表有线程在访问该方法。此时，如果线程ID是自己的线程ID，如果是可重入锁，会将status自增1，然后获取到该锁，进而执行相应的方法；如果是非重入锁，就会进入阻塞队列等待。\n\n在释放锁时，\n\n如果是可重入锁的，每一次退出方法，就会将status减1，直至status的值为0，最后释放该锁。\n如果非可重入锁的，线程退出方法，直接就会释放该锁。\n\n# syncronized锁升级的过程讲一下具体的锁升级的过程是：无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁。\n\n无锁：这是没有开启偏向锁的时候的状态，在JDK1.6之后偏向锁的默认开启的，但是有一个偏向延迟，需要在JVM启动之后的多少秒之后才能开启，这个可以通过JVM参数进行设置，同时是否开启偏向锁也可以通过JVM参数设置。\n偏向锁：这个是在偏向锁开启之后的锁的状态，如果还没有一个线程拿到这个锁的话，这个状态叫做匿名偏向，当一个线程拿到偏向锁的时候，下次想要竞争锁只需要拿线程ID跟MarkWord当中存储的线程ID进行比较，如果线程ID相同则直接获取锁（相当于锁偏向于这个线程），不需要进行CAS操作和将线程挂起的操作。\n轻量级锁：在这个状态下线程主要是通过CAS操作实现的。将对象的MarkWord存储到线程的虚拟机栈上，然后通过CAS将对象的MarkWord的内容设置为指向Displaced Mark Word的指针，如果设置成功则获取锁。在线程出临界区的时候，也需要使用CAS，如果使用CAS替换成功则同步成功，如果失败表示有其他线程在获取锁，那么就需要在释放锁之后将被挂起的线程唤醒。\n重量级锁：当有两个以上的线程获取锁的时候轻量级锁就会升级为重量级锁，因为CAS如果没有成功的话始终都在自旋，进行while循环操作，这是非常消耗CPU的，但是在升级为重量级锁之后，线程会被操作系统调度然后挂起，这可以节约CPU资源。\n\n了解完 4 种锁状态之后，我们就可以整体的来看一下锁升级的过程了。  线程A进入 synchronized 开始抢锁，JVM 会判断当前是否是偏向锁的状态，如果是就会根据 Mark Word 中存储的线程 ID 来判断，当前线程A是否就是持有偏向锁的线程。如果是，则忽略 check，线程A直接执行临界区内的代码。\n但如果 Mark Word 里的线程不是线程 A，就会通过自旋尝试获取锁，如果获取到了，就将 Mark Word 中的线程 ID 改为自己的;如果竞争失败，就会立马撤销偏向锁，膨胀为轻量级锁。\n后续的竞争线程都会通过自旋来尝试获取锁，如果自旋成功那么锁的状态仍然是轻量级锁。然而如果竞争失败，锁会膨胀为重量级锁，后续等待的竞争的线程都会被阻塞。\n# JVM对Synchornized的优化？synchronized 核心优化方案主要包含以下 4 个：\n\n锁膨胀：synchronized 从无锁升级到偏向锁，再到轻量级锁，最后到重量级锁的过程，它叫做锁膨胀也叫做锁升级。JDK 1.6 之前，synchronized 是重量级锁，也就是说 synchronized 在释放和获取锁时都会从用户态转换成内核态，而转换的效率是比较低的。但有了锁膨胀机制之后，synchronized 的状态就多了无锁、偏向锁以及轻量级锁了，这时候在进行并发操作时，大部分的场景都不需要用户态到内核态的转换了，这样就大幅的提升了 synchronized 的性能。\n锁消除：指的是在某些情况下，JVM 虚拟机如果检测不到某段代码被共享和竞争的可能性，就会将这段代码所属的同步锁消除掉，从而到底提高程序性能的目的。\n锁粗化：将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。\n自适应自旋锁：指通过自身循环，尝试获取锁的一种方式，优点在于它避免一些线程的挂起和恢复操作，因为挂起线程和恢复线程都需要从用户态转入内核态，这个过程是比较慢的，所以通过自旋的方式可以一定程度上避免线程挂起和恢复所造成的性能开销。\n\n# 介绍一下AQSAQS全称为AbstractQueuedSynchronizer，是Java中的一个抽象类。 AQS是一个用于构建锁、同步器、协作工具类的工具类（框架）。\nAQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。\nCLH：Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。\n主要原理图如下： \nAQS使用一个Volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。\nAQS广泛用于控制并发流程的类，如下图：\n\n其中Sync是这些类中都有的内部类，其结构如下：\n\n可以看到：Sync是AQS的实现。 AQS主要完成的任务：\n\n同步状态（比如说计数器）的原子性管理；\n线程的阻塞和解除阻塞；\n队列的管理。\n\n\n\n\n\n\n\n\n\n\nAQS原理\nAQS最核心的就是三大部分：\n\n状态：state；\n控制线程抢锁和配合的FIFO队列（双向链表）；\n期望协作工具类去实现的获取&#x2F;释放等重要方法（重写）。\n\n状态state\n\n这里state的具体含义，会根据具体实现类的不同而不同：比如在Semapore里，他表示剩余许可证的数量；在CountDownLatch里，它表示还需要倒数的数量；在ReentrantLock中，state用来表示“锁”的占有情况，包括可重入计数，当state的值为0的时候，标识该Lock不被任何线程所占有。\nstate是volatile修饰的，并被并发修改，所以修改state的方法都需要保证线程安全，比如getState、setState以及compareAndSetState操作来读取和更新这个状态。这些方法都依赖于unsafe类。\n\nFIFO队列\n\n这个队列用来存放“等待的线程，AQS就是“排队管理器”，当多个线程争用同一把锁时，必须有排队机制将那些没能拿到锁的线程串在一起。当锁释放时，锁管理器就会挑选一个合适的线程来占有这个刚刚释放的锁。\nAQS会维护一个等待的线程队列，把线程都放到这个队列里，这个队列是双向链表形式。\n\n实现获取&#x2F;释放等方法\n\n这里的获取和释放方法，是利用AQS的协作工具类里最重要的方法，是由协作类自己去实现的，并且含义各不相同；\n获取方法：获取操作会以来state变量，经常会阻塞（比如获取不到锁的时候）。在Semaphore中，获取就是acquire方法，作用是获取一个许可证； 而在CountDownLatch里面，获取就是await方法，作用是等待，直到倒数结束；\n释放方法：在Semaphore中，释放就是release方法，作用是释放一个许可证； 在CountDownLatch里面，获取就是countDown方法，作用是将倒数的数减一；\n需要每个实现类重写tryAcquire和tryRelease等方法。\n\n# Threadlocal作用，原理，具体里面存的key value是啥，会有什么问题，如何解决?ThreadLocal是Java中用于解决线程安全问题的一种机制，它允许创建线程局部变量，即每个线程都有自己独立的变量副本，从而避免了线程间的资源共享和同步问题。\n\n从内存结构图，我们可以看到：\n\nThread类中，有个ThreadLocal.ThreadLocalMap 的成员变量。\nThreadLocalMap内部维护了Entry数组，每个Entry代表一个完整的对象，key是ThreadLocal本身，value是ThreadLocal的泛型对象值。\n\n\n\n\n\n\n\n\n\n\nThreadLocal的作用\n\n线程隔离：ThreadLocal为每个线程提供了独立的变量副本，这意味着线程之间不会相互影响，可以安全地在多线程环境中使用这些变量而不必担心数据竞争或同步问题。\n降低耦合度：在同一个线程内的多个函数或组件之间，使用ThreadLocal可以减少参数的传递，降低代码之间的耦合度，使代码更加清晰和模块化。\n性能优势：由于ThreadLocal避免了线程间的同步开销，所以在大量线程并发执行时，相比传统的锁机制，它可以提供更好的性能。\n\n\n\n\n\n\n\n\n\n\nThreadLocal的原理\nThreadLocal的实现依赖于Thread类中的一个ThreadLocalMap字段，这是一个存储ThreadLocal变量本身和对应值的映射。每个线程都有自己的ThreadLocalMap实例，用于存储该线程所持有的所有ThreadLocal变量的值。\n当你创建一个ThreadLocal变量时，它实际上就是一个ThreadLocal对象的实例。每个ThreadLocal对象都可以存储任意类型的值，这个值对每个线程来说是独立的。\n\n当调用ThreadLocal的get()方法时，ThreadLocal会检查当前线程的ThreadLocalMap中是否有与之关联的值。\n\n如果有，返回该值；\n\n如果没有，会调用initialValue()方法（如果重写了的话）来初始化该值，然后将其放入ThreadLocalMap中并返回。\n\n当调用set()方法时，ThreadLocal会将给定的值与当前线程关联起来，即在当前线程的ThreadLocalMap中存储一个键值对，键是ThreadLocal对象自身，值是传入的值。\n\n当调用remove()方法时，会从当前线程的ThreadLocalMap中移除与该ThreadLocal对象关联的条目。\n\n\n\n\n\n\n\n\n\n\n\n可能存在的问题\n当一个线程结束时，其ThreadLocalMap也会随之销毁，但是ThreadLocal对象本身不会立即被垃圾回收，直到没有其他引用指向它为止。\n因此，在使用ThreadLocal时需要注意，如果不显式调用remove()方法，或者线程结束时未正确清理ThreadLocal变量，可能会导致内存泄漏，因为ThreadLocalMap会持续持有ThreadLocal变量的引用，即使这些变量不再被其他地方引用。\n因此，实际应用中需要在使用完ThreadLocal变量后调用remove()方法释放资源。\n# 悲观锁和乐观锁的区别？\n乐观锁： 就像它的名字一样，对于并发间操作产生的线程安全问题持乐观状态，乐观锁认为竞争不总 是会发生，因此它不需要持有锁，将比较-替换这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。\n悲观锁： 还是像它的名字一样，对于并发间操作产生的线程安全问题持悲观状态，悲观锁认为竞争总 是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像 synchronized，不管三七二十一，直接上了锁就操作资源了。\n\n# Java中想实现一个乐观锁，都有哪些方式？\nCAS（Compare and Swap）操作： CAS 是乐观锁的基础。Java 提供了 java.util.concurrent.atomic 包，包含各种原子变量类（如 AtomicInteger、AtomicLong），这些类使用 CAS 操作实现了线程安全的原子操作，可以用来实现乐观锁。\n版本号控制：增加一个版本号字段记录数据更新时候的版本，每次更新时递增版本号。在更新数据时，同时比较版本号，若当前版本号和更新前获取的版本号一致，则更新成功，否则失败。\n时间戳：使用时间戳记录数据的更新时间，在更新数据时，在比较时间戳。如果当前时间戳大于数据的时间戳，则说明数据已经被其他线程更新，更新失败。\n\n# CAS 有什么缺点？CAS的缺点主要有3点：\n\nABA问题：ABA的问题指的是在CAS更新的过程中，当读取到的值是A，然后准备赋值的时候仍然是A，但是实际上有可能A的值被改成了B，然后又被改回了A，这个CAS更新的漏洞就叫做ABA。只是ABA的问题大部分场景下都不影响并发的最终效果。Java中有AtomicStampedReference来解决这个问题，他加入了预期标志和更新后标志两个字段，更新时不光检查值，还要检查当前的标志是否等于预期标志，全部相等的话才会更新。\n循环时间长开销大：自旋CAS的方式如果长时间不成功，会给CPU带来很大的开销。\n只能保证一个共享变量的原子操作：只对一个共享变量操作可以保证原子性，但是多个则不行，多个可以通过AtomicReference来处理或者使用锁synchronized实现。\n\n# 为什么不能所有的锁都用CAS？CAS操作是基于循环重试的机制，如果CAS操作一直未能成功，线程会一直自旋重试，占用CPU资源。在高并发情况下，大量线程自旋会导致CPU资源浪费。\n# voliatle关键字有什么作用？volatite作用有 2 个：\n\n保证变量对所有线程的可见性。当一个变量被声明为volatile时，它会保证对这个变量的写操作会立即刷新到主存中，而对这个变量的读操作会直接从主存中读取，从而确保了多线程环境下对该变量访问的可见性。这意味着一个线程修改了volatile变量的值，其他线程能够立刻看到这个修改，不会受到各自线程工作内存的影响。\n\n禁止指令重排序优化。volatile关键字在Java中主要通过内存屏障来禁止特定类型的指令重排序。\n\n1）写-写（Write-Write）屏障：在对volatile变量执行写操作之前，会插入一个写屏障。这确保了在该变量写操作之前的所有普通写操作都已完成，防止了这些写操作被移到volatile写操作之后。\n\n2）读-写（Read-Write）屏障：在对volatile变量执行读操作之后，会插入一个读屏障。它确保了对volatile变量的读操作之后的所有普通读操作都不会被提前到volatile读之前执行，保证了读取到的数据是最新的。\n\n3）写-读（Write-Read）屏障：这是最重要的一个屏障，它发生在volatile写之后和volatile读之前。这个屏障确保了volatile写操作之前的所有内存操作（包括写操作）都不会被重排序到volatile读之后，同时也确保了volatile读操作之后的所有内存操作（包括读操作）都不会被重排序到volatile写之前。\n\n\n\n\n# 指令重排序的原理是什么？在执行程序时，为了提高性能，处理器和编译器常常会对指令进行重排序，但是重排序要满足下面 2 个条件才能进行：\n\n在单线程环境下不能改变程序运行的结果\n存在数据依赖关系的不允许重排序。\n\n所以重排序不会对单线程有影响，只会破坏多线程的执行语义。\n我们看这个例子，A和C之间存在数据依赖关系，同时B和C之间也存在数据依赖关系。因此在最终执行的指令序列中，C不能被重排序到A和B的前面，如果C排到A和B的前面，那么程序的结果将会被改变。但A和B之间没有数据依赖关系，编译器和处理器可以重排序A和B之间的执行顺序。\n\n# volatile可以保证线程安全吗？volatile关键字可以保证可见性，但不能保证原子性，因此不能完全保证线程安全。volatile关键字用于修饰变量，当一个线程修改了volatile修饰的变量的值，其他线程能够立即看到最新的值，从而避免了线程之间的数据不一致。\n但是，volatile并不能解决多线程并发下的复合操作问题，比如i++这种操作不是原子操作，如果多个线程同时对i进行自增操作，volatile不能保证线程安全。对于复合操作，需要使用synchronized关键字或者Lock来保证原子性和线程安全。\n# volatile和sychronized比较？Synchronized解决了多线程访问共享资源时可能出现的竞态条件和数据不一致的问题，保证了线程安全性。Volatile解决了变量在多线程环境下的可见性和有序性问题，确保了变量的修改对其他线程是可见的。\n\nSynchronized: Synchronized是一种排他性的同步机制，保证了多个线程访问共享资源时的互斥性，即同一时刻只允许一个线程访问共享资源。通过对代码块或方法添加Synchronized关键字来实现同步。\nVolatile: Volatile是一种轻量级的同步机制，用来保证变量的可见性和禁止指令重排序。当一个变量被声明为Volatile时，线程在读取该变量时会直接从内存中读取，而不会使用缓存，同时对该变量的写操作会立即刷回主内存，而不是缓存在本地内存中。\n\n# 什么是公平锁和非公平锁？\n公平锁： 指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点在于各个线程公平平等，每个线程等待一段时间后，都有执行的机会，而它的缺点就在于整体执行速度更慢，吞吐量更小。\n非公平锁： 多个线程加锁时直接尝试获取锁，能抢到锁到直接占有锁，抢不到才会到等待队列的队尾等待。非公平锁的优势就在于整体执行速度更快，吞吐量更大，但同时也可能产生线程饥饿问题，也就是说如果一直有线程插队，那么在等待队列中的线程可能长时间得不到运行。\n\n# 非公平锁吞吐量为什么比公平锁大？\n公平锁执行流程：获取锁时，先将线程自己添加到等待队列的队尾并休眠，当某线程用完锁之后，会去唤醒等待队列中队首的线程尝试去获取锁，锁的使用顺序也就是队列中的先后顺序，在整个过程中，线程会从运行状态切换到休眠状态，再从休眠状态恢复成运行状态，但线程每次休眠和恢复都需要从用户态转换成内核态，而这个状态的转换是比较慢的，所以公平锁的执行速度会比较慢。\n非公平锁执行流程：当线程获取锁时，会先通过 CAS 尝试获取锁，如果获取成功就直接拥有锁，如果获取锁失败才会进入等待队列，等待下次尝试获取锁。这样做的好处是，获取锁不用遵循先到先得的规则，从而避免了线程休眠和恢复的操作，这样就加速了程序的执行效率。\n\n# Synchronized是公平锁吗？Synchronized不属于公平锁，ReentrantLock是公平锁。\n# ReentrantLock是怎么实现公平锁的？我们来看一下公平锁与非公平锁的加锁方法的源码。公平锁的锁获取源码如下：\n12345678910111213141516171819202122232425262728protected final boolean tryAcquire(int acquires) &#123;    final Thread current = Thread.currentThread();    int c = getState();    if (c == 0) &#123;        if (!hasQueuedPredecessors() &amp;&amp; //这里判断了 hasQueuedPredecessors()                compareAndSetState(0, acquires)) &#123;                        setExclusiveOwnerThread(current);                        return true;        &#125;    &#125; else if (current == getExclusiveOwnerThread()) &#123;        int nextc = c + acquires;        if (nextc &lt; 0) &#123;            throw new Error(&quot;Maximum lock count exceeded&quot;);        &#125;        setState(nextc);        return true;    &#125;    return false;&#125;\n\n非公平锁的锁获取源码如下：\n12345678910111213141516171819202122232425262728293031323334final boolean nonfairTryAcquire(int acquires) &#123;    final Thread current = Thread.currentThread();    int c = getState();    if (c == 0) &#123;        if (compareAndSetState(0, acquires)) &#123; //这里没有判断      hasQueuedPredecessors()            setExclusiveOwnerThread(current);            return true;        &#125;    &#125;    else if (current == getExclusiveOwnerThread()) &#123;        int nextc = c + acquires;        if (nextc &lt; 0) // overflow        throw new Error(&quot;Maximum lock count exceeded&quot;);        setState(nextc);        return true;    &#125;    return false;&#125;\n\n通过对比，我们可以明显的看出公平锁与非公平锁的 lock() 方法唯一的区别就在于公平锁在获取锁时多了一个限制条件：hasQueuedPredecessors() 为 false，这个方法就是判断在等待队列中是否已经有线程在排队了。\n这也就是公平锁和非公平锁的核心区别，如果是公平锁，那么一旦已经有线程在排队了，当前线程就不再尝试获取锁；对于非公平锁而言，无论是否已经有线程在排队，都会尝试获取一下锁，获取不到的话，再去排队。这里有一个特例需要我们注意，针对 tryLock() 方法，它不遵守设定的公平原则。\n例如，当有线程执行 tryLock() 方法的时候，一旦有线程释放了锁，那么这个正在 tryLock 的线程就能获取到锁，即使设置的是公平锁模式，即使在它之前已经有其他正在等待队列中等待的线程，简单地说就是 tryLock 可以插队。\n看它的源码就会发现：\n12345public boolean tryLock() &#123;    return sync.nonfairTryAcquire(1);&#125;\n\n这里调用的就是 nonfairTryAcquire()，表明了是不公平的，和锁本身是否是公平锁无关。综上所述，公平锁就是会按照多个线程申请锁的顺序来获取锁，从而实现公平的特性。\n非公平锁加锁时不考虑排队等待情况，直接尝试获取锁，所以存在后申请却先获得锁的情况，但由此也提高了整体的效率。\n# 线程池# 介绍一下线程池的工作原理线程池是为了减少频繁的创建线程和销毁线程带来的性能损耗，线程池的工作原理如下图：\n\n线程池分为核心线程池，线程池的最大容量，还有等待任务的队列，提交一个任务，如果核心线程没有满，就创建一个线程，如果满了，就是会加入等待队列，如果等待队列满了，就会增加线程，如果达到最大线程数量，如果都达到最大线程数量，就会按照一些丢弃的策略进行处理。\n# 线程池的参数有哪些？线程池的构造函数有7个参数：\n\n\ncorePoolSize：线程池核心线程数量。默认情况下，线程池中线程的数量如果 &lt;&#x3D; corePoolSize，那么即使这些线程处于空闲状态，那也不会被销毁。\nmaximumPoolSize：线程池中最多可容纳的线程数量。当一个新任务交给线程池，如果此时线程池中有空闲的线程，就会直接执行，如果没有空闲的线程且当前线程池的线程数量小于corePoolSize，就会创建新的线程来执行任务，否则就会将该任务加入到阻塞队列中，如果阻塞队列满了，就会创建一个新线程，从阻塞队列头部取出一个任务来执行，并将新任务加入到阻塞队列末尾。如果当前线程池中线程的数量等于maximumPoolSize，就不会创建新线程，就会去执行拒绝策略。\nkeepAliveTime：当线程池中线程的数量大于corePoolSize，并且某个线程的空闲时间超过了keepAliveTime，那么这个线程就会被销毁。\nunit：就是keepAliveTime时间的单位。\nworkQueue：工作队列。当没有空闲的线程执行新任务时，该任务就会被放入工作队列中，等待执行。\nthreadFactory：线程工厂。可以用来给线程取名字等等\nhandler：拒绝策略。当一个新任务交给线程池，如果此时线程池中有空闲的线程，就会直接执行，如果没有空闲的线程，就会将该任务加入到阻塞队列中，如果阻塞队列满了，就会创建一个新线程，从阻塞队列头部取出一个任务来执行，并将新任务加入到阻塞队列末尾。如果当前线程池中线程的数量等于maximumPoolSize，就不会创建新线程，就会去执行拒绝策略\n\n# 线程池工作队列满了有哪些拒接策略？当线程池的任务队列满了之后，线程池会执行指定的拒绝策略来应对，常用的四种拒绝策略包括：CallerRunsPolicy、AbortPolicy、DiscardPolicy、DiscardOldestPolicy，此外，还可以通过实现RejectedExecutionHandler接口来自定义拒绝策略。\n四种预置的拒绝策略：\n\nCallerRunsPolicy，使用线程池的调用者所在的线程去执行被拒绝的任务，除非线程池被停止或者线程池的任务队列已有空缺。\nAbortPolicy，直接抛出一个任务被线程池拒绝的异常。\nDiscardPolicy，不做任何处理，静默拒绝提交的任务。\nDiscardOldestPolicy，抛弃最老的任务，然后执行该任务。\n自定义拒绝策略，通过实现接口可以自定义任务拒绝策略。\n\n# 有线程池参数设置的经验吗？\nCPU密集型：corePoolSize &#x3D; CPU核数 + 1\nIO密集型：corePoolSize &#x3D; CPU核数 * 2\n\n# 核心线程数设置为0可不可以？可以，当核心线程数为0的时候，会创建一个非核心线程进行执行。\n从下面的源码也可以看到，当核心线程数为 0 时，来了一个任务之后，会先将任务添加到任务队列，同时也会判断当前工作的线程数是否为 0，如果为 0，则会创建线程来执行线程池的任务。\n\n# 线程池种类有哪些？\nScheduledThreadPool：可以设置定期的执行任务，它支持定时或周期性执行任务，比如每隔 10 秒钟执行一次任务，我通过这个实现类设置定期执行任务的策略。\nFixedThreadPool：它的核心线程数和最大线程数是一样的，所以可以把它看作是固定线程数的线程池，它的特点是线程池中的线程数除了初始阶段需要从 0 开始增加外，之后的线程数量就是固定的，就算任务数超过线程数，线程池也不会再创建更多的线程来处理任务，而是会把超出线程处理能力的任务放到任务队列中进行等待。而且就算任务队列满了，到了本该继续增加线程数的时候，由于它的最大线程数和核心线程数是一样的，所以也无法再增加新的线程了。\nCachedThreadPool：可以称作可缓存线程池，它的特点在于线程数是几乎可以无限增加的（实际最大可以达到 Integer.MAX_VALUE，为 2^31-1，这个数非常大，所以基本不可能达到），而当线程闲置时还可以对线程进行回收。也就是说该线程池的线程数量不是固定不变的，当然它也有一个用于存储提交任务的队列，但这个队列是 SynchronousQueue，队列的容量为0，实际不存储任何任务，它只负责对任务进行中转和传递，所以效率比较高。\nSingleThreadExecutor：它会使用唯一的线程去执行任务，原理和 FixedThreadPool 是一样的，只不过这里线程只有一个，如果线程在执行任务的过程中发生异常，线程池也会重新创建一个线程来执行后续的任务。这种线程池由于只有一个线程，所以非常适合用于所有任务都需要按被提交的顺序依次执行的场景，而前几种线程池不一定能够保障任务的执行顺序等于被提交的顺序，因为它们是多线程并行执行的。\nSingleThreadScheduledExecutor：它实际和 ScheduledThreadPool 线程池非常相似，它只是 ScheduledThreadPool 的一个特例，内部只有一个线程。\n\n# 线程池一般是怎么用的？Java 中的 Executors 类定义了一些快捷的工具方法，来帮助我们快速创建线程池。《阿里巴巴 Java 开发手册》中提到，禁止使用这些方法来创建线程池，而应该手动 new ThreadPoolExecutor 来创建线程池。这一条规则的背后，是大量血淋淋的生产事故，最典型的就是 newFixedThreadPool 和 newCachedThreadPool，可能因为资源耗尽导致 OOM 问题。\n所以，不建议使用 Executors 提供的两种快捷的线程池，原因如下：\n\n我们需要根据自己的场景、并发情况来评估线程池的几个核心参数，包括核心线程数、最大线程数、线程回收策略、工作队列的类型，以及拒绝策略，确保线程池的工作行为符合需求，一般都需要设置有界的工作队列和可控的线程数。\n任何时候，都应该为自定义线程池指定有意义的名称，以方便排查问题。当出现线程数量暴增、线程死锁、线程占用大量 CPU、线程执行出现异常等问题时，我们往往会抓取线程栈。此时，有意义的线程名称，就可以方便我们定位问题。\n\n除了建议手动声明线程池以外，我还建议用一些监控手段来观察线程池的状态。线程池这个组件往往会表现得任劳任怨、默默无闻，除非是出现了拒绝策略，否则压力再大都不会抛出一个异常。如果我们能提前观察到线程池队列的积压，或者线程数量的快速膨胀，往往可以提早发现并解决问题。\n# 线程池中shutdown ()，shutdownNow()这两个方法有什么作用？从源码【高亮】注释可以很清晰的看出两者的区别：\n\nshutdown使用了以后会置状态为SHUTDOWN，正在执行的任务会继续执行下去，没有被执行的则中断。此时，则不能再往线程池中添加任何任务，否则将会抛出 RejectedExecutionException 异常\n而 shutdownNow 为STOP，并试图停止所有正在执行的线程，不再处理还在池队列中等待的任务，当然，它会返回那些未执行的任务。 它试图终止线程的方法是通过调用 Thread.interrupt() 方法来实现的，但是这种方法的作用有限，如果线程中没有sleep 、wait、Condition、定时锁等应用, interrupt()方法是无法中断当前的线程的。所以，ShutdownNow()并不代表线程池就一定立即就能退出，它可能必须要等待所有正在执行的任务都执行完成了才能退出。\n\nshutdown 源码：\n1234567891011121314public void shutdown() &#123;\tfinal ReentrantLock mainLock = this.mainLock;\tmainLock.lock();\ttry &#123;\t\tcheckShutdownAccess();\t\t// 高亮\t\tadvanceRunState(SHUTDOWN);\t\tinterruptIdleWorkers();\t\tonShutdown();\t&#125; finally &#123;\t\tmainLock.unlock();\t&#125;\ttryTerminate();&#125;\n\nshutdownNow 源码：\n123456789101112131415161718public List&lt;Runnable&gt; shutdownNow() &#123;\tList&lt;Runnable&gt; tasks;\tfinal ReentrantLock mainLock = this.mainLock;\tmainLock.lock();\ttry &#123;\t\tcheckShutdownAccess();\t\t// 高亮\t\tadvanceRunState(STOP);\t\tinterruptWorkers();\t\t// 高亮\t\ttasks = drainQueue();\t&#125; finally &#123;\t\tmainLock.unlock();\t&#125;\ttryTerminate();\t// 高亮\treturn tasks;&#125;\n\n# 提交给线程池中的任务可以被撤回吗？可以，当向线程池提交任务时，会得到一个Future对象。这个Future对象提供了几种方法来管理任务的执行，包括取消任务。\n取消任务的主要方法是Future接口中的cancel(boolean mayInterruptIfRunning)方法。这个方法尝试取消执行的任务。参数mayInterruptIfRunning指示是否允许中断正在执行的任务。如果设置为true，则表示如果任务已经开始执行，那么允许中断任务；如果设置为false，任务已经开始执行则不会被中断。\n12345678910111213public interface Future&lt;V&gt; &#123;    // 是否取消线程的执行    boolean cancel(boolean mayInterruptIfRunning);    // 线程是否被取消    boolean isCancelled();    //线程是否执行完毕    boolean isDone();      // 立即获得线程返回的结果    V get() throws InterruptedException, ExecutionException;      // 延时时间后再获得线程返回的结果    V get(long timeout, TimeUnit unit)        throws InterruptedException, ExecutionException, TimeoutException;&#125;\n\n取消线程池中任务的方式，代码如下，通过 future 对象的 cancel(boolean) 函数来定向取消特定的任务。\n12345678910111213141516public static void main(String[] args) &#123;        ExecutorService service = Executors.newSingleThreadExecutor();        Future future = service.submit(new TheradDemo());        try &#123;          // 可能抛出异常            future.get();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; catch (ExecutionException e) &#123;            e.printStackTrace();        &#125;finally &#123;          //终止任务的执行            future.cancel(true);        &#125; &#125;\n\n# 场景# 多线程打印奇偶数，怎么控制打印的顺序可以利用wait()和notify()来控制线程的执行顺序。\n以下是一个基于这种方法的简单示例：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class PrintOddEven &#123;    private static final Object lock = new Object();    private static int count = 1;    private static final int MAX_COUNT = 10;    public static void main(String[] args) &#123;        Runnable printOdd = () -&gt; &#123;            synchronized (lock) &#123;                while (count &lt;= MAX_COUNT) &#123;                    if (count % 2 != 0) &#123;                        System.out.println(Thread.currentThread().getName() + &quot;: &quot; + count++);                        lock.notify();                    &#125; else &#123;                        try &#123;                            lock.wait();                        &#125; catch (InterruptedException e) &#123;                            e.printStackTrace();                        &#125;                    &#125;                &#125;            &#125;        &#125;;        Runnable printEven = () -&gt; &#123;            synchronized (lock) &#123;                while (count &lt;= MAX_COUNT) &#123;                    if (count % 2 == 0) &#123;                        System.out.println(Thread.currentThread().getName() + &quot;: &quot; + count++);                        lock.notify();                    &#125; else &#123;                        try &#123;                            lock.wait();                        &#125; catch (InterruptedException e) &#123;                            e.printStackTrace();                        &#125;                    &#125;                &#125;            &#125;        &#125;;        Thread oddThread = new Thread(printOdd, &quot;OddThread&quot;);        Thread evenThread = new Thread(printEven, &quot;EvenThread&quot;);        oddThread.start();        evenThread.start();    &#125;&#125;\n\n在上面的示例中，通过一个共享的锁对象lock来控制两个线程的交替执行。一个线程负责打印奇数，另一个线程负责打印偶数，通过wait()和notify()方法来在两个线程之间实现顺序控制。当当前应该打印奇数时，偶数线程会进入等待状态，反之亦然。\n\n","slug":"并发/并发常见面试题（上）","date":"2024-12-03T17:21:45.000Z","categories_index":"八股","tags_index":"java,精选,并发框架","author_index":"Ivan"},{"id":"5bcef49cfc4866658bd7f1721b4f6cb7","title":"反射机制","content":"对于Java的反射机制，精炼一点就是，可以在程序运行时获取类和对象的信息，包括属性和方法。\n反射基础Class类和普通的类没有什么区别，有属性，有方法。\n我们编写的类在被编译后，都会附带一个Class对象，表示创建类的类型信息，被写入在同名的class字节码文件中。\n我们无法手动创建Class类的对象，因为其构造函数是私有化的。\nClass对象的作用是运行时提供某个对象的类型信息。\n反射的使用对于对象，我们的常规操作是什么？\n无非就是new一个对象出来、改变对象的状态（修改属性值）、调用对象方法。\n不过，现在，我们要使用反射机制来完成这些操作。\nClass类对象的获取在类加载的时候，jvm会创建一个class对象。\n获取class对象的三种方式：\n\n类名.class\n对象.getClass()\nClass.forName(全限定类名)\n\n（这里简单演示一下就行了，毕竟平时开发的时候真的很少用这玩意儿啦）\n1234567891011121314151617181920212223242526272829303132333435class Person &#123;    private String name;    private int age;    public Person(String name, int age) &#123;        this.name = name;        this.age = age;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public int getAge() &#123;        return age;    &#125;    public void setAge(int age) &#123;        this.age = age;    &#125;    private void sayHello()&#123;        System.out.println(&quot;hello&quot;);    &#125;    @Override    public String toString() &#123;        return &quot;Person [name=&quot; + name + &quot;, age=&quot; + age + &quot;]&quot;;    &#125;&#125;\n\n创建一个新的对象：\n12345678public class Test &#123;    public static void main(String[] args) throws NoSuchMethodException, SecurityException, InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException &#123;       Constructor&lt;Person&gt; constructor = Person.class.getDeclaredConstructor(String.class,int.class);       Person person = constructor.newInstance(&quot;kaiven&quot;,20);       System.out.println(person);    &#125;&#125;\n\n改变对象的状态：\n1234567891011public class Test &#123;    public static void main(String[] args) throws NoSuchMethodException, SecurityException, InstantiationException,            IllegalAccessException, IllegalArgumentException, InvocationTargetException, NoSuchFieldException &#123;        Person person = new Person(&quot;kaiven&quot;, 20);        Field namField = person.getClass().getDeclaredField(&quot;name&quot;);        namField.setAccessible(true);        namField.set(person, &quot;lucy&quot;);        System.out.println(person.getName());    &#125;&#125;\n\n调用对象方法：\n12345678910public class Test &#123;    public static void main(String[] args) throws NoSuchMethodException, SecurityException, InstantiationException,            IllegalAccessException, IllegalArgumentException, InvocationTargetException, NoSuchFieldException &#123;        Person person = new Person(&quot;kaiven&quot;, 20);        Method method = person.getClass().getDeclaredMethod(&quot;sayHello&quot;);        method.setAccessible(true);        method.invoke(person);    &#125;&#125;\n\n（想玩儿的时候自己去查阅文档玩儿一下就行了）\n反射机制执行的流程（等我去搞一下JVM，哈哈。先欠着，以后还。）\n\n","slug":"java基础/反射机制","date":"2024-12-03T16:33:37.000Z","categories_index":"八股","tags_index":"java","author_index":"Ivan"},{"id":"ffb5215d2da6c9afc674d09b81aafa43","title":"注解机制","content":"注解基础注解是JDK1.5版本引入的一个新特性，用于对代码进行说明。\n注解的作用\n通过代码里标识的元数据生成javadoc文档\n编译检查\n编译时动态处理，比如说动态生成代码\n运行时动态处理，比如说使用反射注入实例\n\n注解的分类\nJava自带的标准注解，包括@Override、@Deprecated和@SuppressWarnings，分别用于标明重写某个方法、标明某个类或方法过时、标明要忽略的警告，用这些注解标明后编译器就会进行检查。\n元注解，元注解是用于定义注解的注解，包括@Retention、@Target、@Inherited、@Documented，@Retention用于标明注解被保留的阶段，@Target用于标明注解使用的范围，@Inherited用于标明注解可继承，@Documented用于标明是否生成javadoc文档。\n自定义注解，可以根据自己的需求定义注解，并可用元注解对自定义注解进行注解。\n\nJava内置注解12345678910111213141516171819202122232425262728293031public class Solution &#123;    public void test()&#123;&#125;&#125;class Test extends Solution &#123;    /**     * 重写父类方法     */    @Override    public void test() &#123;            &#125;    /**     * 被弃用的方法（后续版本可能移除，不推荐再使用）     */    @Deprecated    public void oldMethod()&#123;    &#125;    /**     * 忽略警告     */    @SuppressWarnings(&quot;rawtypes&quot;)    public List list()&#123;        return new ArrayList&lt;&gt;();    &#125;&#125;\n\n@Override我们来看一下这个注解的内部是什么样子：\n1234@Target(ElementType.METHOD) // 表示该注解用来修饰方法的@Retention(RetentionPolicy.SOURCE) // 表示该注解仅在编译时有效public @interface Override &#123;&#125;\n\n@Deprecated123456789101112131415161718192021222324@Documented // 能够被文档化@Retention(RetentionPolicy.RUNTIME) // 可以保留到运行时@Target(value=&#123;CONSTRUCTOR, FIELD, LOCAL_VARIABLE, METHOD, PACKAGE, MODULE, PARAMETER, TYPE&#125;) // 作用域相当的广泛public @interface Deprecated &#123;    /**     * Returns the version in which the annotated element became deprecated.     * The version string is in the same format and namespace as the value of     * the &#123;@code @since&#125; javadoc tag. The default value is the empty     * string.     *     * @return the version string     * @since 9     */    String since() default &quot;&quot;;    /**     * Indicates whether the annotated element is subject to removal in a     * future version. The default value is &#123;@code false&#125;.     *     * @return whether the element is subject to removal     * @since 9     */    boolean forRemoval() default false;&#125;\n\n@SuppressWarnings123456789101112131415161718192021@Target(&#123;TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE, MODULE&#125;) // 作用域相当广泛@Retention(RetentionPolicy.SOURCE) // 仅在编译时有效public @interface SuppressWarnings &#123;    /**     * The set of warnings that are to be suppressed by the compiler in the     * annotated element.  Duplicate names are permitted.  The second and     * successive occurrences of a name are ignored.  The presence of     * unrecognized warning names is &lt;i&gt;not&lt;/i&gt; an error: Compilers must     * ignore any warning names they do not recognize.  They are, however,     * free to emit a warning if an annotation contains an unrecognized     * warning name.     *     * &lt;p&gt; The string &#123;@code &quot;unchecked&quot;&#125; is used to suppress     * unchecked warnings. Compiler vendors should document the     * additional warning names they support in conjunction with this     * annotation type. They are encouraged to cooperate to ensure     * that the same names work across multiple compilers.     * @return the set of warnings to be suppressed     */    String[] value();&#125;\n\n元注解@Target123456789101112@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Target &#123;    /**     * Returns an array of the kinds of elements an annotation interface     * can be applied to.     * @return an array of the kinds of elements an annotation interface     * can be applied to     */    ElementType[] value();&#125;\n\n该注解的作用就是限定注解的使用范围，具体范围如下：\n1234567891011121314151617181920212223public enum ElementType &#123;     TYPE, // 类、接口、枚举类     FIELD, // 成员变量（包括：枚举常量）     METHOD, // 成员方法     PARAMETER, // 方法参数     CONSTRUCTOR, // 构造方法     LOCAL_VARIABLE, // 局部变量     ANNOTATION_TYPE, // 注解类     PACKAGE, // 可用于修饰：包     TYPE_PARAMETER, // 类型参数，JDK 1.8 新增     TYPE_USE // 使用类型的任何地方，JDK 1.8 新增 &#125;\n\n我们可以看到该注解自身也加上了一个 @Target(ElementType.ANNOTATION_TYPE) 。\n@Retention12345678910@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Retention &#123;    /**     * Returns the retention policy.     * @return the retention policy     */    RetentionPolicy value();&#125;\n\n该注解的作用就是描述注解保留的时间（或者叫做阶段吧）。总共有三个阶段：\n123456789101112131415161718192021public enum RetentionPolicy &#123;    /**     * Annotations are to be discarded by the compiler.     */    SOURCE,    /**     * Annotations are to be recorded in the class file by the compiler     * but need not be retained by the VM at run time.  This is the default     * behavior.     */    CLASS,    /**     * Annotations are to be recorded in the class file by the compiler and     * retained by the VM at run time, so they may be read reflectively.     *     * @see java.lang.reflect.AnnotatedElement     */    RUNTIME&#125;\n\n（英文描述得已经很清晰了）\n@Documented该注解的作用就是在使用 javadoc 工具为类生成帮助文档时保留注解信息。\n12345@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Documented &#123;&#125;\n\n@Inherited如果某个类使用了被@Inherited修饰的Annotation，则其子类将自动具有该注解。\n12345@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Inherited &#123;&#125;\n\n注解与反射在使用SpringBoot进行开发的时候，你会感慨为什么写几个注解就能够将项目跑起来，那肯定是因为框架的开发者在你看不见的地方替你完成了某些操作。\n注意：注解的生命周期只有是 RUNTIME 才能通过反射去获取。\n自定义注解我们来编写一个属于自己的注解吧。\n123456789101112package com.kaiven.anno;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(ElementType.METHOD) // 作用在方法上@Retention(RetentionPolicy.RUNTIME) // 保留到运行时，否则无法通过反射获取public @interface GetMapping &#123;    String value() default &quot;&quot;;&#125;\n\n123456789101112131415161718192021package com.kaiven;import com.kaiven.anno.GetMapping;import java.lang.reflect.Method;public class Main &#123;    public static void main(String[] args) throws NoSuchMethodException &#123;        Method hello = Main.class.getMethod(&quot;hello&quot;);        // 如果该方法上有GetMapping注解        if (hello.isAnnotationPresent(GetMapping.class)) &#123;            GetMapping annotation = hello.getAnnotation(GetMapping.class);            System.out.println(annotation.value());        &#125;    &#125;    @GetMapping(&quot;/hello&quot;)    public String hello()&#123;        return &quot;Hello world!&quot;;    &#125;&#125;\n\n有没有那一点点的味道了？\n深入理解注解注解支持继承嘛？注解是不支持继承的，但注解在编译之后，编译器会自动继承java.lang.annotation.Annotation接口。\n注解实现的原理？https://blog.csdn.net/qq\\_20009015/article/details/106038023\n（对于注解的应用，大多还是与Spring相关的，最大的一个变化就是从xml配置项目到注解化的转变）\n\n","slug":"java基础/注解机制","date":"2024-12-03T16:29:44.000Z","categories_index":"八股","tags_index":"java","author_index":"Ivan"},{"id":"5fa7811420fef5e890cc85bbf0c3fa40","title":"SPI","content":"什么是 SPI 机制？SPI（Service Provider Interface），是 JDK 内置的一种服务提供发现机制，可以用来启用框架扩展和替换组件，主要是被框架的开发人员使用，Java的SPI机制可以为某个接口寻找服务实现。\nJava中SPI机制的主要思想是将装配的控制权转移到程序外，降低耦合度。\n\n当服务的提供者提供了一种接口的实现之后，需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的META-INF/services/中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：java.util.ServiceLoader。\nSPI机制的简单示例定义一个搜索接口，搜索关键词是一个参数，返回对应的搜索结果：\n123public interface Search &#123;    String search(String keywords);&#125;\n\n文件搜索的具体实现：\n123456public class FileSearchImpl implements Search&#123;    @Override    public String search(String keywords) &#123;        return &quot;我是文件搜索功能的具体实现&quot;;    &#125;&#125;\n\n数据库搜索的具体实现：\n123456public class DataBaseSearchImpl implements Search&#123;    @Override    public String search(String keywords) &#123;        return &quot;我是数据库搜索功能的实现&quot;;    &#125;&#125;\n\n接下来可以在resources下新建META-INF&#x2F;services&#x2F;目录，然后新建接口全限定名的文件：com.kaiven.spi.Search，里面加上我们需要用到的实现类。\n12com.kaiven.spi.DataBaseSearchImplcom.kaiven.spi.FileSearchImpl\n\n测试：\n12345678public class Main &#123;    public static void main(String[] args) &#123;        ServiceLoader&lt;Search&gt; load = ServiceLoader.load(Search.class);        for (Search search : load) &#123;            System.out.println(search.search(&quot;&quot;));        &#125;    &#125;&#125;\n\n（好玩吧，哈哈）\nSPI机制的典型应用数据库JDBC提供了统一的数据库相关操作的接口：\n123456789101112131415public interface Driver &#123;    Connection connect(String url, java.util.Properties info)        throws SQLException;    boolean acceptsURL(String url) throws SQLException;    DriverPropertyInfo[] getPropertyInfo(String url, java.util.Properties info)                         throws SQLException;    int getMajorVersion();    int getMinorVersion();    public Logger getParentLogger() throws SQLFeatureNotSupportedException;&#125;\n\n这就是所谓的数据库驱动接口。\n让我们看一下mysql是怎么实现的：\n\n是不是和我们上面写的例子一模一样呢？哈哈。\n（其他的应用场景可以自行百度扩展一下，特别是Spring的，想一下没有SpringBoot之前，是不是一大堆的xml配置文件）\nSPI机制深入理解SPI和API的区别？使用SPI机制的时候，我们会将具体的实现抽离出程序外，也就是相当于接口的定义与实现不在同一个包中，比如 JDBC和MySQL驱动的实现。对于API的话，平时的开发中，会将接口与实现类放在同一个包中。前者强调调用方，后者强调实现方。\nSPI机制的实现原理（这个感兴趣的可以自行去查看JDK中ServiceLoader&lt;S&gt;方法的具体实现，面试的话，这里你能讲出一些自己的理解就行了）\nSPI机制的缺陷\n不能按需加载，需要遍历所有实现，并实例化，然后再循环中才能找到我们的实现。如果不想使用某些实现类，或者某些类实例化很耗时，它也被载入并实例化，这就造成了浪费。\n获取某个实现类的方式不够灵活，只能通过Iterator形式获取，不能根据某个参数来获取对应的实现类。\n多线程使用 ServiceLoader 类的实例是不安全的。\n\n\n","slug":"java基础/SPI","date":"2024-12-03T16:25:08.000Z","categories_index":"八股","tags_index":"java","author_index":"Ivan"},{"id":"da333f82be06d5afcb21795dbc6a2364","title":"final详解","content":"final基础使用修饰类当某个类的整体定义为final时，就表明了你不能打算继承该类，而且也不允许别人这么做。即这个类是不能有子类的。\n注意：final类中的所有方法都隐式为final，因为无法覆盖他们，所以在final类中给任何方法添加final关键字是没有任何意义的。\n修饰方法\nprivate 方法是隐式的final\n类中所有private方法都隐式地指定为final的，由于无法取用private方法，所以也就不能覆盖它。可以对private方法增添final关键字，但这样做并没有什么好处。\n\nfinal方法是可以被重载的\n1234567public class FinalExampleParent &#123;    public final void test() &#123;    &#125;    public final void test(String str) &#123;    &#125;&#125;\n\n修饰参数Java允许在参数列表中以声明的方式将参数指明为final，这意味这你无法在方法中更改参数引用所指向的对象。这个特性主要用来向匿名内部类传递数据。\n修饰变量所有被final修饰的变量都是编译期常量嘛？12345678910111213public class Test &#123;    //编译期常量    final int i = 1;    final static int J = 1;    final int[] a = &#123;1,2,3,4&#125;;    //非编译期常量    Random r = new Random();    final int k = r.nextInt();    public static void main(String[] args) &#123;    &#125;&#125;\n\nk的值由随机数对象决定，所以不是所有的final修饰的字段都是编译期常量，只是k的值在被初始化后无法被更改。\nstatci final一个既是static又是final 的字段只占据一段不能改变的存储空间，它必须在定义的时候进行赋值，否则编译器将不予通过。\n1234567891011public class Test &#123;    static Random r = new Random();    final int k = r.nextInt(10);    static final int k2 = r.nextInt(10);     public static void main(String[] args) &#123;        Test t1 = new Test();        System.out.println(&quot;k=&quot;+t1.k+&quot; k2=&quot;+t1.k2);        Test t2 = new Test();        System.out.println(&quot;k=&quot;+t2.k+&quot; k2=&quot;+t2.k2);    &#125;&#125;\n\n我们可以发现对于不同的对象k的值是不同的，但是k2的值却是相同的，这是为什么呢? 因为static关键字所修饰的字段并不属于一个对象，而是属于这个类的。也可简单的理解为static final所修饰的字段仅占据内存的一个一份空间，一旦被初始化之后便不会被更改。\nfinal域重排序规则Java中，无非就是两种数据类型，基本数据类型和引用（对象）。在下文中，我们展开来看：\nfinal域为基本类型写final域的重排序规则写final域的重排序规则禁止对final域的写重排序到构造函数之外，这个规则的实现主要包含了两个方面：\n\nJMM禁止编译器把final域的写重排序到构造函数之外；\n编译器会在final域写之后，构造函数return之前，插入一个storestore屏障。这个屏障可以禁止处理器把final域的写重排序到构造函数之外。\n\n1234567891011121314151617181920public class FinalDemo &#123;    private int a;  //普通域    private final int b; //final域    private static FinalDemo finalDemo;    public FinalDemo() &#123;        a = 1; // 1. 写普通域        b = 2; // 2. 写final域    &#125;    public static void writer() &#123;        finalDemo = new FinalDemo();    &#125;    public static void reader() &#123;        FinalDemo demo = finalDemo; // 3.读对象引用        int a = demo.a;    //4.读普通域        int b = demo.b;    //5.读final域    &#125;&#125;\n\n假设线程A执行writer方法，线程B执行reader方法。\n线程A在进行对象的构造时，由于b带有final域，所以写指令不会被重排序到构造函数外，而a是普通域，可能会被重排序到构造函数外。线程B读取b的值的时候，一定是可以读到最新值2的（假设对象已经构造完毕），读取a的值就不一定了，可能会读取到默认值。\n读final域重排序规则读final域重排序规则为：在一个线程中，初次读对象引用和初次读该对象包含的final域，JMM会禁止这两个操作的重排序。(注意，这个规则仅仅是针对处理器)，处理器会在读final域操作的前面插入一个LoadLoad屏障。实际上，读对象的引用和读该对象的final域存在间接依赖性，一般处理器不会重排序这两个操作。但是有一些处理器会重排序，因此，这条禁止重排序规则就是针对这些处理器而设定的。\n上文的线程B在进行final域变量值b的读取时，一定会先读取对象的引用，在通过对象的引用读取对应的值。\n读final域的重排序规则可以确保：在读一个对象的final域之前，一定会先读这个包含这个final域的对象的引用。\nfinal域为引用类型对final修饰的对象的成员域写操作针对引用数据类型，final域写针对编译器和处理器重排序增加了这样的约束：在构造函数内对一个final修饰的对象的成员域的写入，与随后在构造函数之外把这个被构造的对象的引用赋给一个引用变量，这两个操作是不能被重排序的。注意这里的是“增加”也就说前面对final基本数据类型的重排序规则在这里还是使用。\n1234567891011121314151617181920212223public class FinalReferenceDemo &#123;    final int[] arrays;    private FinalReferenceDemo finalReferenceDemo;    public FinalReferenceDemo() &#123;        arrays = new int[1];  //1        arrays[0] = 1;        //2    &#125;    public void writerOne() &#123;        finalReferenceDemo = new FinalReferenceDemo(); //3    &#125;    public void writerTwo() &#123;        arrays[0] = 2;  //4    &#125;    public void reader() &#123;        if (finalReferenceDemo != null) &#123;  //5            int temp = finalReferenceDemo.arrays[0];  //6        &#125;    &#125;&#125;\n\n针对上面的实例程序，线程线程A执行wirterOne方法，执行完后线程B执行writerTwo方法，然后线程C执行reader方法。\n由于对final域的写禁止重排序到构造方法外，因此1和3不能被重排序。由于一个final域的引用对象的成员域写入不能与随后将这个被构造出来的对象赋给引用变量重排序，因此2和3不能重排序。\n对final修饰的对象的成员域读操作JMM可以确保线程C至少能看到写线程A对final引用的对象的成员域的写入，即能看下arrays[0] &#x3D; 1，而写线程B对数组元素的写入可能看到可能看不到。JMM不保证线程B的写入对线程C可见，线程B和线程C之间存在数据竞争，此时的结果是不可预知的。如果可见的，可使用锁或者volatile。\n关于final域重排序的总结按照final修饰的数据类型分类：\n\n基本数据类型:\nfinal域写：禁止final域写与构造方法重排序，即禁止final域写重排序到构造方法之外，从而保证该对象对所有线程可见时，该对象的final域全部已经初始化过。\nfinal域读：禁止初次读对象的引用与读该对象包含的final域的重排序。\n\n\n引用数据类型：\n额外增加约束：禁止在构造函数对一个final修饰的对象的成员域的写入与随后将这个被构造的对象的引用赋值给引用变量 重排序\n\n\n\n\n","slug":"并发/final详解","date":"2024-12-03T15:28:28.000Z","categories_index":"八股","tags_index":"java,并发框架","author_index":"Ivan"},{"id":"2d6047dcb37a308542a367e2837e0e0c","title":"Sychronized详解","content":"synchronized的使用在应用Sychronized关键字时需要把握如下注意点：\n\n一把锁只能同时被一个线程获取，没有获得锁的线程只能等待；\n每个实例都对应有自己的一把锁(this),不同实例之间互不影响；例外：锁对象是*.class以及synchronized修饰的是static方法的时候，所有对象公用同一把锁\nsynchronized修饰的方法，无论方法正常执行完毕还是抛出异常，都会释放锁\n\nsynchronized原理分析加锁和释放锁的原理1234567891011121314public class Test &#123;    Object object = new Object();        public void func()&#123;        synchronized(object)&#123;        &#125;        method();    &#125;    private static void method()&#123;        System.out.println(1);    &#125;&#125;\n\n生成的字节码（非完整，只关注函数func）：\n123456789101112131415161718192021222324public void func();    descriptor: ()V    flags: (0x0001) ACC_PUBLIC    Code:      stack=2, locals=3, args_size=1         0: aload_0         1: getfield      #7                  // Field object:Ljava/lang/Object;         4: dup         5: astore_1         6: monitorenter // 注意这里         7: aload_1         8: monitorexit // 注意这里         9: goto          17        12: astore_2        13: aload_1        14: monitorexit // 注意这里        15: aload_2        16: athrow        17: invokestatic  #13                 // Method method:()V        20: return      Exception table:         from    to  target type             7     9    12   any            12    15    12   any\n\nMonitorenter和Monitorexit指令，会让对象在执行，使其锁计数器加1或者减1。每一个对象在同一时间只与一个monitor(锁)相关联，而一个monitor在同一时间只能被一个线程获得，一个对象在尝试获得与这个对象相关联的Monitor锁的所有权的时候，monitorenter指令会发生如下3中情况之一：\n\nmonitor计数器为0，意味着目前还没有被获得，那这个线程就会立刻获得然后把锁计数器+1，一旦+1，别的线程再想获取，就需要等待\n如果这个monitor已经拿到了这个锁的所有权，又重入了这把锁，那锁计数器就会累加，变成2，并且随着重入的次数，会一直累加\n这把锁已经被别的线程获取了，等待锁释放\n\nmonitorexit指令：释放对于monitor的所有权，释放过程很简单，就是讲monitor的计数器减1，如果减完以后，计数器不是0，则代表刚才是重入进来的，当前线程还继续持有这把锁的所有权，如果计数器变成0，则代表当前线程不再拥有该monitor的所有权，即释放锁。\n\n该图可以看出，任意线程对Object的访问，首先要获得Object的监视器，如果获取失败，该线程就进入同步状态，线程状态变为BLOCKED，当Object的监视器占有者释放后，在同步队列中得线程就会有机会重新获取该监视器.\n(这也是可重入的原理)\n保证可见性的原理：内存模型和happens-before规则Synchronized的happens-before规则，即监视器锁规则：对同一个监视器的解锁，happens-before于对该监视器的加锁。\n（这是JVM对你的一个承诺）\nJVM中锁的优化简单来说在JVM中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的，但是由于使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；然而在现实中的大部分情况下，同步方法是运行在单线程环境(无锁竞争环境)如果每次都调用Mutex Lock那么将严重的影响程序的性能。不过在jdk1.6中对锁的实现引入了大量的优化，如锁粗化(Lock Coarsening)、锁消除(Lock Elimination)、轻量级锁(Lightweight Locking)、偏向锁(Biased Locking)、适应性自旋(Adaptive Spinning)等技术来减少锁操作的开销。\n\n锁粗化(Lock Coarsening)：也就是减少不必要的紧连在一起的unlock，lock操作，将多个连续的锁扩展成一个范围更大的锁。\n锁消除(Lock Elimination)：通过运行时JIT编译器的逃逸分析来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本的Stack上进行对象空间的分配(同时还可以减少Heap上的垃圾收集开销)。\n轻量级锁(Lightweight Locking)：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态(即单线程执行环境)，在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒(具体处理步骤下面详细讨论)。\n偏向锁(Biased Locking)：是为了在无锁竞争的情况下避免在锁获取过程中执行不必要的CAS原子指令，因为CAS原子指令虽然相对于重量级锁来说开销比较小但还是存在非常可观的本地延迟。\n适应性自旋(Adaptive Spinning)：当线程在获取轻量级锁的过程中执行CAS操作失败时，在进入与monitor相关联的操作系统重量级锁(mutex semaphore)前会进入忙等待(Spinning)然后再次尝试，当尝试一定的次数后如果仍然没有成功则调用与该monitor关联的semaphore(即互斥锁)进入到阻塞状态。\n\n锁的类型在Java SE 1.6里Synchronied同步锁，一共有四种状态：无锁、偏向锁、轻量级锁、重量级锁，它会随着竞争情况逐渐升级。锁可以升级但是不可以降级，目的是为了提供获取锁和释放锁的效率。\n（ 锁膨胀方向： 无锁 → 偏向锁 → 轻量级锁 → 重量级锁 (此过程是不可逆的) ）\n自旋锁与自适应自旋锁引入背景：大家都知道，在没有加入锁优化时，Synchronized是一个非常“胖大”的家伙。在多线程竞争锁时，当一个线程获取锁时，它会阻塞所有正在竞争的线程，这样对性能带来了极大的影响。在挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作对系统的并发性能带来了很大的压力。同时HotSpot团队注意到在很多情况下，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和回复阻塞线程并不值得。在如今多处理器环境下，完全可以让另一个没有获取到锁的线程在门外等待一会(自旋)，但不放弃CPU的执行时间。等待持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需要让线程执行一个忙循环(自旋)，这便是自旋锁由来的原因。\n自旋锁早在JDK1.4 中就引入了，只是当时默认时关闭的。在JDK 1.6后默认为开启状态。自旋锁本质上与阻塞并不相同，先不考虑其对多处理器的要求，如果锁占用的时间非常的短，那么自旋锁的性能会非常的好，相反，其会带来更多的性能开销(因为在线程自旋时，始终会占用CPU的时间片，如果锁占用的时间太长，那么自旋的线程会白白消耗掉CPU资源)。因此自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然没有成功获取到锁，就应该使用传统的方式去挂起线程了，在JDK定义中，自旋锁默认的自旋次数为10次，用户可以使用参数-XX:PreBlockSpin来更改。\n可是现在又出现了一个问题：如果线程锁在线程自旋刚结束就释放掉了锁，那么是不是有点得不偿失。所以这时候我们需要更加聪明的锁来实现更加灵活的自旋。来提高并发的性能。(这里则需要自适应自旋锁！)\n在JDK 1.6中引入了自适应自旋锁。这就意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋 时间及锁的拥有者的状态来决定的。如果在同一个锁对象上，自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，那么JVM会认为该锁自旋获取到锁的可能性很大，会自动增加等待时间。比如增加到100此循环。相反，如果对于某个锁，自旋很少成功获取锁。那再以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，JVM对程序的锁的状态预测会越来越准确，JVM也会越来越聪明。\n锁消除锁消除是指虚拟机即时编译器再运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持。意思就是：JVM会判断再一段程序中的同步明显不会逃逸出去从而被其他线程访问到，那JVM就把它们当作栈上数据对待，认为这些数据是线程独有的，不需要加同步。此时就会进行锁消除。\n当然在实际开发中，我们很清楚的知道哪些是线程独有的，不需要加同步锁，但是在Java API中有很多方法都是加了同步的，那么此时JVM会判断这段代码是否需要加锁。如果数据并不会逃逸，则会进行锁消除。\n锁粗化原则上，我们都知道在加同步锁时，尽可能的将同步块的作用范围限制到尽量小的范围(只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小。在存在锁同步竞争中，也可以使得等待锁的线程尽早的拿到锁)。\n大部分上述情况是完美正确的，但是如果存在连串的一系列操作都对同一个对象反复加锁和解锁，甚至加锁操作时出现在循环体中的，那即使没有线程竞争，频繁的进行互斥同步操作也会导致不必要的性能操作。\n1234567public static String test04(String s1, String s2, String s3) &#123;    StringBuffer sb = new StringBuffer();    sb.append(s1);    sb.append(s2);    sb.append(s3);    return sb.toString();&#125;\n\n在上述的连续append()操作中就属于这类情况。JVM会检测到这样一连串的操作都是对同一个对象加锁，那么JVM会将加锁同步的范围扩展(粗化)到整个一系列操作的 外部，使整个一连串的append()操作只需要加锁一次就可以了。\n轻量级锁在JDK 1.6之后引入的轻量级锁，需要注意的是轻量级锁并不是替代重量级锁的，而是对在大多数情况下同步块并不会有竞争出现提出的一种优化。它可以减少重量级锁对线程的阻塞带来的线程开销。从而提高并发性能。\n如果要理解轻量级锁，那么必须先要了解HotSpot虚拟机中对象头的内存布局。上面介绍Java对象头也详细介绍过。在对象头中(Object Header)存在两部分。第一部分用于存储对象自身的运行时数据，HashCode、GC Age、锁标记位、是否为偏向锁。等。一般为32位或者64位(视操作系统位数定)。官方称之为Mark Word，它是实现轻量级锁和偏向锁的关键。 另外一部分存储的是指向方法区对象类型数据的指针(Klass Point)，如果对象是数组的话，还会有一个额外的部分用于存储数据的长度。\n在线程执行同步块之前，JVM会先在当前线程的栈帧中创建一个名为锁记录(Lock Record)的空间，用于存储锁对象目前的Mark Word的拷贝(JVM会将对象头中的Mark Word拷贝到锁记录中，官方称为Displaced Mark Ward)这个时候线程堆栈与对象头的状态如图：\n\n如上图所示：如果当前对象没有被锁定，那么锁标志位为01状态，JVM在执行当前线程时，首先会在当前线程栈帧中创建锁记录Lock Record的空间用于存储锁对象目前的Mark Word的拷贝。\n然后，虚拟机使用CAS操作将标记字段Mark Word拷贝到锁记录中，并且将Mark Word更新为指向Lock Record的指针。如果更新成功了，那么这个线程就拥用了该对象的锁，并且对象Mark Word的锁标志位更新为(Mark Word中最后的2bit)00，即表示此对象处于轻量级锁定状态，如图：\n\n如果这个更新操作失败，JVM会检查当前的Mark Word中是否存在指向当前线程的栈帧的指针，如果有，说明该锁已经被获取，可以直接调用。如果没有，则说明该锁被其他线程抢占了，如果有两条以上的线程竞争同一个锁，那轻量级锁就不再有效，直接膨胀为重量级锁，没有获得锁的线程会被阻塞。此时，锁的标志位为10.Mark Word中存储的指向重量级锁的指针。\n轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头中，如果成功，则表示没有发生竞争关系。如果失败，表示当前锁存在竞争关系。锁就会膨胀成重量级锁。两个线程同时争夺锁，导致锁膨胀的流程图如下：\n\n偏向锁引入背景：在大多实际环境下，锁不仅不存在多线程竞争，而且总是由同一个线程多次获取，那么在同一个线程反复获取所释放锁中，其中并还没有锁的竞争，那么这样看上去，多次的获取锁和释放锁带来了很多不必要的性能开销和上下文切换。\n为了解决这一问题，HotSpot的作者在Java SE 1.6 中对Synchronized进行了优化，引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁。只需要简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果成功，表示线程已经获取到了锁。\n\n偏向锁使用了一种等待竞争出现才会释放锁的机制。所以当其他线程尝试获取偏向锁时，持有偏向锁的线程才会释放锁。但是偏向锁的撤销需要等到全局安全点(就是当前线程没有正在执行的字节码)。它会首先暂停拥有偏向锁的线程，让你后检查持有偏向锁的线程是否活着。如果线程不处于活动状态，直接将对象头设置为无锁状态。如果线程活着，JVM会遍历栈帧中的锁记录，栈帧中的锁记录和对象头要么偏向于其他线程，要么恢复到无锁状态或者标记对象不适合作为偏向锁。\n\n锁的优缺点对比\n\n","slug":"并发/Sychronized详解","date":"2024-12-03T15:23:37.000Z","categories_index":"八股","tags_index":"java,并发框架","author_index":"Ivan"},{"id":"4dfa428c08a3d894cc1c145fbc03603c","title":"Volatile详解","content":"volatile的作用详解防重排序从一个经典的双检索单例模式开始：\n1234567891011121314151617public class Singleton &#123;    public static volatile Singleton singleton;    /**     * 构造函数私有，禁止外部实例化     */    private Singleton() &#123;&#125;;    public static Singleton getInstance() &#123;        if (singleton == null) &#123;            synchronized (singleton.class) &#123;                if (singleton == null) &#123;                    singleton = new Singleton();                &#125;            &#125;        &#125;        return singleton;    &#125;&#125;\n\n现在我们分析一下为什么要在变量singleton之间加上volatile关键字。要理解这个问题，先要了解对象的构造过程，实例化一个对象其实可以分为三个步骤：\n\n分配内存空间。\n初始化对象。\n将内存空间的地址赋值给对应的引用。\n\n但是由于操作系统可以对指令进行重排序，所以上面的过程也可能会变成如下过程：\n\n分配内存空间。\n将内存空间的地址赋值给对应的引用。\n初始化对象\n\n如果是这个流程，多线程环境下就可能将一个未初始化的对象引用暴露出来，从而导致不可预料的结果。因此，为了防止这个过程的重排序，我们需要将变量设置为volatile类型的变量。\n实现可见性可见性问题主要指一个线程修改了共享变量值，而另一个线程却看不到。引起可见性问题的主要原因是每个线程拥有自己的一个高速缓存区——线程工作内存。\n123456789101112131415161718192021222324public class TestVolatile &#123;    private static boolean stop = false;    public static void main(String[] args) &#123;        // Thread-A        new Thread(&quot;Thread A&quot;) &#123;            @Override            public void run() &#123;                while (!stop) &#123;                &#125;                System.out.println(Thread.currentThread() + &quot; stopped&quot;);            &#125;        &#125;.start();        // Thread-main        try &#123;            TimeUnit.SECONDS.sleep(1);            System.out.println(Thread.currentThread() + &quot; after 1 seconds&quot;);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        stop = true;    &#125;&#125;\n\n可以看到 Thread-main 休眠1秒之后，设置 stop &#x3D; ture，但是Thread A根本没停下来，这就是可见性问题。如果通过在stop变量前面加上volatile关键字则会真正stop。\n这里有必要做一下详细的解释：\nCPU的多级缓存机制是大小限制的，上下文切换的时候，会将线程相关状态保存在TCB中，TCB在内存中。下次再次切换会该线程的时候，会从TCB中恢复线程的上下文信息。即，从上面的程序来说，“stop的值被保存在TCB中”，一直读取的都是老值。\n保证原子性：单次读&#x2F;写volatile不能保证完全的原子性，只能保证单次的读&#x2F;写操作具有原子性。\n我们先来看两个经典的问题：\n1. i++为什么不能保证原子性？对于原子性，需要强调一点，也是大家容易误解的一点：对volatile变量的单次读&#x2F;写操作可以保证原子性的，如long和double类型变量，但是并不能保证i++这种操作的原子性，因为本质上i++是读、写两次操作。\ni++其实是一个复合操作，包括三步骤：\n\n读取i的值。\n对i加1。\n将i的值写回内存。\n\nvolatile是无法保证这三个操作是具有原子性的，我们可以通过AtomicInteger或者Synchronized来保证+1操作的原子性。\n2. 共享的long和double变量为什么要用volatile？因为long和double两种数据类型的操作可分为高32位和低32位两部分，因此普通的long或double类型读&#x2F;写可能不是原子的。因此，鼓励大家将共享的long和double变量设置为volatile类型，这样能保证任何情况下对long和double的单次读&#x2F;写操作都具有原子性。\n（目前各种平台下的商用虚拟机都选择把 64 位数据的读写操作作为原子操作来对待，因此我们在编写代码时一般不把long 和 double 变量专门声明为 volatile多数情况下也是不会错的）\nvolatile 的实现原理volatile 可见性实现volatile 变量的内存可见性是基于内存屏障(Memory Barrier)实现:\n内存屏障，又称内存栅栏，是一个 CPU 指令。\n在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，JMM 为了保证在不同的编译器和 CPU 上有相同的结果，通过插入特定类型的内存屏障来禁止+ 特定类型的编译器重排序和处理器重排序，插入一条内存屏障会告诉编译器和 CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序。\n为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存(L1，L2 或其他)后再进行操作，但操作完不知道何时会写到内存。\n如果对声明了 volatile 的变量进行写操作，JVM 就会向处理器发送一条 lock 前缀的指令，将这个变量所在缓存行的数据写回到系统内存。\n为了保证各个处理器的缓存是一致的，实现了缓存一致性协议(MESI)，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。\n所有多核处理器下还会完成：当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值。\nvolatile 变量通过这样的机制就使得每个线程都能获得该变量的最新值。\nvolatile 有序性实现1. happens-beforehappens-before 规则中有一条是 volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。\n（简单说，如果写在读的前面的话，那么一定读到的就是最新值）\n2. 写操作禁止重排序为了性能优化，JMM 在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序。JMM 提供了内存屏障阻止这种重排序。\nJava 编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。\n\n","slug":"并发/Volatile详解","date":"2024-12-03T15:19:43.000Z","categories_index":"八股","tags_index":"java,并发框架","author_index":"Ivan"},{"id":"6f65c61888737e8d4204dac5a8495701","title":"锁的概念","content":"导图\n乐观锁 VS 悲观锁乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。\n先说概念。对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。\n而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。\n乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。\n\n根据从上面的概念描述我们可以发现：\n\n悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。\n乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。\n\n自旋锁 VS 适应性自旋锁阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。\n在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。\n而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。\n\n自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。\n自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。\n无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁这四种锁是指锁的状态，专门针对synchronized的。\n（后续的文章会详细讲解）\n总结而言： 偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。\n公平锁 VS 非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。\n非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。\n可重入锁 VS 非可重入锁可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。\n1234567891011121314151617class Test &#123;    public synchronized void func01(int arg)&#123;        System.out.println(arg);        func02(arg + 1);    &#125;    public synchronized void func02(int arg)&#123;        System.out.println(arg);    &#125;    public static void main(String[] args) &#123;        Test test = new Test();        ExecutorService executorService = Executors.newCachedThreadPool();        executorService.execute(() -&gt; test.func01(1));        executorService.execute(() -&gt; test.func01(3));        executorService.shutdown();    &#125;&#125;\n\n如果 synchronized 不是可重入锁的话，那么很明显上述代码会造成死锁。\n可重入锁的实现原理大致是这样的：内部维护了一个计数器，获取到锁的时候，判断一下计数器的值。如果计数器的值是0的话，那么执行+1操作；如果不是0的话，判断当前线程是否是获取到锁的线程，如果是的话，就执行+1操作。释放锁就是每执行完一个同步代码块后，将计数器的值-1，计数器的值为0时，释放锁。\n独享锁(排他锁) VS 共享锁独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。\n共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。\n（本文主要是介绍一下锁的概念上的东西，具体的实现请看后续章节）\n\n","slug":"并发/锁的概念","date":"2024-12-03T15:13:49.000Z","categories_index":"八股","tags_index":"java,并发框架","author_index":"Ivan"},{"id":"6245dd4deb5ec4d8e16e80935a8a30db","title":"线程基础","content":"线程状态的转换新建（New）创建后未启动。\n可运行（Runable）可能正在运行，也可能等待CPU时间片。\n阻塞（Blocking）等待获取一个排它锁，如果其他线程释放了锁，就会结束该状态。\n无限期等待（Waiting）等待其他线程显式的唤醒，否则不会被分配时间片。\n限期等待（Timed Waiting）无需等待其他线程显式地唤醒，在一定时间之后被系统自动唤醒。\n死亡（Terminated）可以是线程结束任务之后自己结束，或产生异常而结束。\n线程使用方式有三种使用线程的方法:\n\n实现 Runnable 接口；\n实现 Callable 接口；\n继承 Thread 类。\n\n实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以说任务是通过线程驱动从而执行的。\n1.实现 Runnable 接口123456789101112131415class MyRunable implements Runnable &#123;    @Override    public void run() &#123;        System.out.println(&quot;hello world!&quot;);    &#125;    public static void main(String[] args) throws InterruptedException &#123;        MyRunable myRunable = new MyRunable();        Thread thread = new Thread(myRunable);        thread.start();        thread.join();    &#125;    &#125;\n\n2. 实现 Callable 接口123456789101112131415class MyCallable implements Callable&lt;String&gt; &#123;    @Override    public String call() throws Exception &#123;        return &quot;Hello World!&quot;;    &#125;    public static void main(String[] args) throws InterruptedException, ExecutionException &#123;        MyCallable myCallable = new MyCallable();        FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(myCallable);        Thread thread = new Thread(futureTask);        thread.start();        System.out.println(futureTask.get());    &#125;&#125;\n\n3. 继承Thread类1234567891011121314class MyThread extends Thread &#123;    @Override    public void run() &#123;        System.out.println(&quot;Hello World!&quot;);    &#125;    public static void main(String[] args) throws InterruptedException &#123;        MyThread myThread = new MyThread();        myThread.start();        myThread.join();    &#125;    &#125;\n\n实现接口 VS 继承 Thread 类实现接口会更好一些，因为:\n\nJava 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口；\n类可能只要求可执行就行，继承整个 Thread 类开销过大。\n\n基础线程机制ExecutorExecutor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。\n主要有三种 Executor:\n\nCachedThreadPool: 一个任务创建一个线程；\nFixedThreadPool: 所有任务只能使用固定大小的线程；\nSingleThreadExecutor: 相当于大小为 1 的 FixedThreadPool。\n\n123456789101112public class Solution &#123;    public static void main(String[] args) &#123;        ExecutorService newCachedThreadPool = Executors.newCachedThreadPool();        for(int i=0;i&lt;5;i++)&#123;            final int I = i;            newCachedThreadPool.execute(() -&gt; &#123;                System.out.println(&quot;hello world! &quot;+I);            &#125;);        &#125;        newCachedThreadPool.shutdown();    &#125;&#125;\n\nDaemon守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。\n当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。\nmain() 属于非守护线程。\n使用 setDaemon() 方法将一个线程设置为守护线程。\n12345678public class Solution &#123;    public static void main(String[] args) &#123;        Thread thread = new Thread(() -&gt; &#123;            System.out.println(&quot;hello world!&quot;);        &#125;);        thread.setDaemon(true);    &#125;&#125;\n\nsleep()Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。\nsleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。\n1234public static void main(String[] args) throws InterruptedException &#123;    Thread.sleep(3000);    System.out.println(&quot;hello world!&quot;);&#125;\n\nyield()对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。\n12345678910111213141516public static void main(String[] args) throws InterruptedException &#123;    Thread thread_01 = new Thread(() -&gt; &#123;        System.out.println(1);        Thread.yield();        System.out.println(3);    &#125;);    Thread thread_02 = new Thread(() -&gt; &#123;        System.out.println(2);        Thread.yield();        System.out.println(4);    &#125;);    thread_01.start();    thread_02.start();    thread_01.join();    thread_02.join();&#125;\n\n线程中断一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。\nInterruptedException通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I&#x2F;O 阻塞和 synchronized 锁阻塞。\n1234567891011121314public static void main(String[] args) throws InterruptedException &#123;    Thread thread = new Thread(() -&gt; &#123;        try &#123;            Thread.sleep(3000);            System.out.println(&quot;hello&quot;);        &#125; catch (InterruptedException e) &#123;            System.out.println(&quot;我被干掉了&quot;);        &#125;    &#125;);    thread.start();    Thread.sleep(1000);    thread.interrupt();    thread.join();&#125;\n\ninterrupted()如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。\n但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。\n123456789101112131415161718class MyThread extends Thread &#123;    @Override    public void run() &#123;        while (!interrupted()) &#123;            System.out.println(&quot;没有被打断&quot;);        &#125;        System.out.println(&quot;完蛋了！&quot;);    &#125;        public static void main(String[] args) throws InterruptedException &#123;        MyThread myThread = new MyThread();        myThread.start();        Thread.sleep(1000);        myThread.interrupt();        myThread.join();    &#125;&#125;\n\nExecutor 的中断操作调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。\n123456789101112public static void main(String[] args) throws InterruptedException &#123;    ExecutorService newCachedThreadPool = Executors.newCachedThreadPool();    newCachedThreadPool.execute(() -&gt; &#123;        try &#123;            Thread.sleep(3000);            System.out.println(&quot;hello world&quot;);        &#125; catch (InterruptedException e) &#123;            System.out.println(&quot;被中断喽&quot;);        &#125;    &#125;);    newCachedThreadPool.shutdownNow();&#125;\n\n如果只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。\n1234567891011public static void main(String[] args) throws InterruptedException, ExecutionException &#123;    ExecutorService executorService = Executors.newCachedThreadPool();    Future&lt;Object&gt; submit = executorService.submit(() -&gt; &#123;        for(int i=0;i&lt;100000000;i++)&#123;            System.out.println(i);        &#125;        return null;    &#125;);    submit.cancel(true);    System.out.println(&quot;hello&quot;);&#125;\n\n线程互斥同步Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。\nsynchronized1. 同步一个代码块1234567891011121314151617181920class Test &#123;    public void func() &#123;        synchronized (this) &#123;            for (int i = 0; i &lt; 10; i++) &#123;                System.out.println(i);            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        Test test = new Test();        ExecutorService executorService = Executors.newCachedThreadPool();        executorService.execute(() -&gt; &#123;            test.func();        &#125;);        executorService.execute(() -&gt; &#123;            test.func();        &#125;);        executorService.shutdown();    &#125;&#125;\n\n它只作用于同一个对象，如果调用两个对象上的同步代码块，就不会进行同步：\n123456789101112131415161718192021class Test &#123;    public void func() &#123;        synchronized (this) &#123;            for (int i = 0; i &lt; 10; i++) &#123;                System.out.println(i);            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        Test test = new Test();        Test test2 = new Test();        ExecutorService executorService = Executors.newCachedThreadPool();        executorService.execute(() -&gt; &#123;            test.func();        &#125;);        executorService.execute(() -&gt; &#123;            test2.func();        &#125;);        executorService.shutdown();    &#125;&#125;\n\n2. 同步一个方法1234567891011121314151617181920class Test &#123;    public synchronized void func() &#123;        for (int i = 0; i &lt; 10; i++) &#123;            System.out.println(i);        &#125;    &#125;    public static void main(String[] args) &#123;        Test test = new Test();        Test test2 = new Test();        ExecutorService executorService = Executors.newCachedThreadPool();        executorService.execute(() -&gt; &#123;            test.func();        &#125;);        executorService.execute(() -&gt; &#123;            test2.func();        &#125;);        executorService.shutdown();    &#125;&#125;\n\n它和同步代码块一样，作用于同一个对象。\n3. 同步一个类12345678910111213141516171819202122class Test &#123;    public void func() &#123;        synchronized (Test.class) &#123;            for (int i = 0; i &lt; 10; i++) &#123;                System.out.println(i);            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        Test test = new Test();        Test test2 = new Test();        ExecutorService executorService = Executors.newCachedThreadPool();        executorService.execute(() -&gt; &#123;            test.func();        &#125;);        executorService.execute(() -&gt; &#123;            test2.func();        &#125;);        executorService.shutdown();    &#125;&#125;\n\n作用于整个类，也就是说两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。\n4. 同步一个静态方法123456789101112131415161718class Test &#123;    public static synchronized void func() &#123;        for (int i = 0; i &lt; 10; i++) &#123;            System.out.println(i);        &#125;    &#125;    public static void main(String[] args) &#123;        ExecutorService executorService = Executors.newCachedThreadPool();        executorService.execute(() -&gt; &#123;            Test.func();        &#125;);        executorService.execute(() -&gt; &#123;            Test.func();        &#125;);        executorService.shutdown();    &#125;&#125;\n\n作用于整个类。\nReentrantLockReentrantLock 是 java.util.concurrent(J.U.C)包中的锁。\n12345678910111213141516171819202122232425class Test &#123;    private Lock lock;    &#123;        lock = new ReentrantLock();    &#125;    public void func() &#123;        lock.lock();        try &#123;            for(int i=0;i&lt;10;i++)&#123;                System.out.println(i);            &#125;        &#125; finally &#123;            lock.unlock();        &#125;    &#125;    public static void main(String[] args) &#123;        Test test = new Test();        ExecutorService executorService = Executors.newCachedThreadPool();        executorService.execute(() -&gt; test.func());        executorService.execute(() -&gt; test.func());        executorService.shutdown();    &#125;&#125;\n\n比较1. 锁的实现synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。\n2. 性能新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。\n3. 等待可中断当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。\nReentrantLock 可中断，而 synchronized 不行。\n4. 公平锁公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。\nsynchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。\n5. 锁绑定多个条件一个 ReentrantLock 可以同时绑定多个 Condition 对象。\n使用选择除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。\n线程之间的协作当多个线程可以一起工作去解决某个问题时，如果某些部分必须在其它部分之前完成，那么就需要对线程进行协调。\njoin()在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。\n（这里就不掩饰了，经常用的）\nwait() notify() notifyAll()调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。\n它们都属于 Object 的一部分，而不属于 Thread。\n只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateExeception。\n使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。\n12345678910111213141516171819202122232425262728class Test &#123;    public synchronized void before() &#123;        try &#123;            Thread.sleep(1500);        &#125; catch (InterruptedException e) &#123;            System.out.println(&quot;被打断lou&quot;);        &#125;        System.out.println(&quot;before&quot;);        notifyAll();    &#125;    public synchronized void after() &#123;        try &#123;            wait();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(&quot;after&quot;);    &#125;    public static void main(String[] args) &#123;        Test test = new Test();        ExecutorService newCachedThreadPool = Executors.newCachedThreadPool();        newCachedThreadPool.execute(() -&gt; test.after());        newCachedThreadPool.execute(() -&gt; test.before());        newCachedThreadPool.shutdown();    &#125;&#125;\n\n（以上代码有死锁的风险，如果是after函数先执行，那没有问题；如果是before先执行，就证明了after没有拿到锁，等before释放锁之后，after拿到锁，然后进入休眠状态，然后也没有人唤醒它）\nwait() 和 sleep() 的区别\nwait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法\nwait() 会释放锁，sleep() 不会\n\nawait() signal() signalAll()java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。\n123456789101112131415161718192021222324252627282930313233343536373839404142class Test &#123;    private Lock lock;    private Condition condition;    &#123;        lock = new ReentrantLock();        condition = lock.newCondition();    &#125;    public void before() &#123;        lock.lock();        try &#123;            Thread.sleep(1500);            System.out.println(&quot;before&quot;);        &#125; catch (InterruptedException e) &#123;            System.out.println(&quot;被打断lou&quot;);        &#125;        finally&#123;            condition.signalAll();            lock.unlock();        &#125;    &#125;    public void after() &#123;        lock.lock();        try &#123;            condition.await();            System.out.println(&quot;after&quot;);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        finally&#123;            lock.unlock();        &#125;    &#125;    public static void main(String[] args) &#123;        Test test = new Test();        ExecutorService newCachedThreadPool = Executors.newCachedThreadPool();        newCachedThreadPool.execute(() -&gt; test.after());        newCachedThreadPool.execute(() -&gt; test.before());        newCachedThreadPool.shutdown();    &#125;&#125;\n\n（和上文一下，也是会有死锁的风险，虽然我没有测出来，但是理论上来说，是这样的）\n\n","slug":"并发/线程基础","date":"2024-12-03T14:40:50.000Z","categories_index":"八股","tags_index":"java,并发框架","author_index":"Ivan"},{"id":"f5276a6470bcf00967ce9121d16c19cd","title":"并发基础","content":"为什么需要多线程？早期的单CPU时代，CPU制作厂商沉迷于提高单个核心的计算能力。但是随着时间的推移，提高单核心的计算能力越来越困难了。于是乎，堆核心成为了快速提高CPU计算能力的另一种途径。这样一来，多个任务就可以并行的跑在CPU的不同核心上。\n一个程序只是一个单线程的应用的话，无法利用现代多核心CPU的优势。所以，学习并发编程可以提高我们程序的运行效率。\n线程安全示例多线程编程虽然可以提高我们程序的运行效率，但是同样也面临着线程安全或者说并发安全问题：\n12345678910111213141516171819202122232425262728public class ThreadUnsafeExample &#123;    private int cnt = 0;    public void add() &#123;        cnt++;    &#125;    public int get() &#123;        return cnt;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        final int threadSize = 1000;        ThreadUnsafeExample example = new ThreadUnsafeExample();        final CountDownLatch countDownLatch = new CountDownLatch(threadSize);        ExecutorService executorService = Executors.newCachedThreadPool();        for (int i = 0; i &lt; threadSize; i++) &#123;            executorService.execute(() -&gt; &#123;                example.add();                countDownLatch.countDown();            &#125;);        &#125;        countDownLatch.await();        executorService.shutdown();        System.out.println(example.get());    &#125;&#125;\n\n运行的结果总是小于1000。\n并发问题发生的三要素1. 可见性：CPU缓存引起的\nCPU直接与自己的L1级缓存进行交互，L1级缓存的数据来自L2，L2中的数据来自L3，L3中的数据来自内存。\n假设线程A和线程B并发的执行这段代码的话，线程A在CPU1上执行，线程B在CPU2上执行，会有以下这种情况：\n线程A将i的值从内存载入CPU1对应的缓存中，此时i的值为0；\n线程B将i的值从内存载入CPU2对应的缓存中，此时i的值为0；\n线程A执行了自增操作，CPU1缓存中的i的值为1；\n线程B执行了自增操作，CPU2缓存中的i的值为1；\n线程A将CPU1缓存i的值写入内存，内存中i的值是1；\n线程B将CPU2缓存i的值写入内存，内存中i的值是1。\n其中一次操作的值将另一次操作的值给覆盖了。\n本质问题就是一个线程在CPU缓存中修改了共享的值，另一个线程并不知道。\n2. 原子性：分时复用引起的对于【i++】操作来说，它对应三条指令：\n\n将变量i从内存中读到寄存器\n将寄存器中i的值+1\n写回内存（由于缓存机制，也可能是缓存，而不是内存）\n\n我们都知道，CPU运作机制就是执行一条又一条的指令。无论是Linux、windows还是Max OS，它们都属于分时操作系统。CPU并发的运行着N多个程序。CPU有一个时钟硬件设备，定期向CPU发送时钟中断信号，CPU收到信号后，操作系统介入，调度下一个程序运行。\n所以，就算是在只有一个CPU的机器上，运行多线程的程序，由于分时复用机制，一个操作如果由多条指令集合构成，那么也会造成并发安全问题。\n3. 有序性：重排序引起1234int i = 0;              boolean flag = false;i = 1;                //语句1  flag = true;          //语句2\n\n从我们开发的角度来看，语句1应该在语句2之前执行的，那事实真的是这样嘛？\n在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：\n\n编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。\n指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。\n内存系统的重排序。由于处理器使用缓存和读 &#x2F; 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。\n\n从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序：\n\n上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。\nJava是怎么解决并发问题的？JMM（Java内存模型）。\n理解的第一个维度：核心知识点\nJMM本质上可以理解为，Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括：\n\nvolatile、synchronized 和 final 三个关键字\nHappens-Before 规则\n\n理解的第二个维度：可见性，有序性，原子性\n\n原子性\n\n在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。\n请分析以下哪些操作是原子性操作：\n1234x = 10;        //语句1: 直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中y = x;         //语句2: 包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。x++;           //语句3： x++包括3个操作：读取x的值，进行加1操作，写入新的值。x = x + 1;     //语句4： 同语句3\n\n只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。\nJava内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。\n\n可见性\n\nJava提供了volatile关键字来保证可见性。\n当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。\n而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。\n另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。\n\n有序性\n\n在Java里面，可以通过volatile关键字来保证一定的“有序性”。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。当然JMM是通过Happens-Before 规则来保证有序性的。\nHappens-Before 规则上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。\n1. 单一线程原则在一个线程内，在程序前面的操作先行发生于后面的操作。\n2. 管程锁定规则一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。\n3. volatile变量规则对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。\n4. 线程启动规则Thread 对象的 start() 方法调用先行发生于此线程的每一个动作。\n5. 线程加入规则Thread 对象的结束先行发生于 join() 方法返回。\n6. 线程中断规则对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。\n7. 对象终结规则一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize() 方法的开始。\n8. 传递性如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。\n线程安全一个类在可以被多个线程安全调用时就是线程安全的。\n线程安全不是一个非真即假的命题，可以将共享数据按照安全程度的强弱顺序分成以下五类: 不可变、绝对线程安全、相对线程安全、线程兼容和线程对立。\n1. 不可变不可变(Immutable)的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态。\n多线程环境下，应当尽量使对象成为不可变，来满足线程安全。\n不可变的类型:\n\nfinal 关键字修饰的基本数据类型\nString\n枚举类型\nNumber 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。\n\n2. 相对线程安全相对线程安全需要保证对这个对象单独的操作是线程安全的，在调用的时候不需要做额外的保障措施。但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。\n在 Java 语言中，大部分的线程安全类都属于这种类型，例如 Vector、HashTable、Collections 的 synchronizedCollection() 方法包装的集合等。\n3. 线程兼容线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用，我们平常说一个类不是线程安全的，绝大多数时候指的是这一种情况。Java API 中大部分的类都是属于线程兼容的，如与前面的 Vector 和 HashTable 相对应的集合类 ArrayList 和 HashMap 等。\n4. 线程对立线程对立是指无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码。由于 Java 语言天生就具备多线程特性，线程对立这种排斥多线程的代码是很少出现的，而且通常都是有害的，应当尽量避免。\n线程安全的实现方法1. 互斥同步synchronized 和 ReentrantLock。\n2. 非阻塞同步互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。\n互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁(这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁)、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。\n（一）CAS随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略: 先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施(不断地重试，直到成功为止)。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。\n乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是: 比较并交换(Compare-and-Swap，CAS)。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。\n（二）ABA如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。\nJ.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。\n3. 无同步方案要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。\n（一）栈封闭多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。\n（二）线程本地存储（Thread Local Storage）如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。\n符合这种特点的应用并不少见，大部分使用消费队列的架构模式(如“生产者-消费者”模式)都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”(Thread-per-Request)的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。\n可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。\nThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。\n在一些场景 (尤其是使用线程池) 下，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal 有内存泄漏的情况，应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。\n（三）可重入代码这种代码也叫做纯代码(Pure Code)，可以在代码执行的任何时刻中断它，转而去执行另外一段代码(包括递归调用它本身)，而在控制权返回后，原来的程序不会出现任何错误。\n可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。\n\n","slug":"并发/并发基础","date":"2024-12-03T14:35:07.000Z","categories_index":"八股","tags_index":"java,并发框架,并发基础","author_index":"Ivan"},{"id":"293c17b4d2a4292133cc4d1ffd7f8725","title":"计算机网络","content":"OSI模型、TCP&#x2F;IP模型、五层模型 ？\n刚开始学习的小伙伴一定会被这些搞懵逼的，傻傻分不清哦。\n这个所谓的七层模型，实际上那帮搞学术的弄出来的，但是很可惜，并没有流行开了，主要原因就是搭建这样的体系架构网络很复杂。（了解一下就行了）\nTCP&#x2F;IP网络模型是目前最流行的网络协议模型。在我们的实际生活中被广泛的使用。\n最后这个五层协议，主要是为了教学需要而设计的，了解一下即可，但是我还是会简单介绍的。\nTCP&#x2F;IP模型每一层的作用？\n应用层\n这是我们大部分开发最为熟悉的一层，应用层对于我们来说，是相对可控的，因为传输层及以下是操作系统的网络协议栈接管，用户态的我怎么敢触碰内核态的你。\n你所熟知的各种协议，比如 HTTP、HTTPS、DNS等，都属于应用层协议。\n\n传输层\n这一层的协议就少了，就两个：TCP和UDP\n之后的文章会做详细的讲解，这里简单说一下两个协议的特点。\nTCP提供面向连接的、可靠的传输服务；UDP提供无连接、尽最大努力交付的传输服务。\n\n网络层\nIP协议起了至关重要的作用，想一下，现在的网络体系，离得开IP嘛？\n\n网络接口层\n对于上层的协议来说，这一层就是数据的发送层，实际上，并不是，后面会说。\n\n\n数据发送的大致流程？\n应用层将需要发送的数据交给传输层，传输层拿到后加上TCP头部，向下交给网络层，网络层又加上IP头部，交给网络接口层，加上帧头和帧尾，然后发出去。\n（上层协议委托的数据对于下层协议来说是透明的，比如说对于网络层来说，它是不知道有TCP头部和应用数据之分的，只会认为是一个整体）\n网络接口层简介物理层没有什么好说的，这里主要说一下数据链路层。\n数据链路层的协议很多，但是他们都面临着三个问题：封装成帧、透明传输和差错检测\n\n封装成帧\n数据链路层会将网络层交付的数据添加首部和尾部，这就封装成了一个帧，首部和尾部就标识了该帧的开始与结束。\n帧长 &#x3D; 首部长度 + 数据段长度 + 尾部长度。\nMTU（最大传输单元） —— 数据部分长度限制，看图：\n\n帧定界符：就是表示一个帧的开始与结束的标志。=&gt; 有个场景，如果发送端发送的时候，突然“掉线”了，那么接收端就永远不会收到帧结束符。等到下一个帧的帧开始符到达时，接收端就知道上一个帧不完整了，就会把它丢弃。\n\n\n透明传输\n这个问题与数据链路层的机制有关系。数据链路层奉行一种“来者不拒”的理念，“只要给我的，我都要”，对于帧的隔离，识别比特流中的定界符就好了。也就是说，数据链路层并不知道你传的内容是些什么玩意儿，它只负责去“截断”（找到帧开始符合帧结束符）。所以，什么样的比特组合都能通过该层。对于这些比特流而言，数据链路层就好像不存在一样。\n但是这样会引发一个什么样的问题呢？对于文本数据还好说，里面的内容都是键盘上录入进去的，帧开始符和帧结束符找两个用户录入不进去的字符就好了。可是，如果是一些音视频或者其他的比特流，很难保证里面其中一个字节的比特组合不会与帧开始符和帧结束符不同（毕竟对于数据链路层来说，它唯一能做的就是扫描字节，找到帧定界符）。\n如果数据段中出现了“帧开始”符，那么前面的数据就会被丢弃；如果数据段中出现了“帧结束符”，那么后面的数据就会被丢弃。\n为了解决该问题，发送端在数据链路层封装成帧的时候，如果数据内容里面出现了帧定界符，那么就在对应的字节前面添加一个转义字符，如果转义字符也重复了，那么就再添加一个转移字符。&#x3D;&gt; 该过程称作字节填充或者字节填充。\n\n\n差错检测\n比特差错 &#x3D;&gt; 世界上没有完美无暇的东西，总会出问题的。数据在传输的过程中，可能会出现0变成1，或者1变成0的情况。\n泼出去的水无法改变，那就只能在收到的时候，利用各种手段去检测数据是否完整了。\n在数据链路层，广泛采用循环冗余检验CRC检错技术 &#x3D;&gt; 其实就是数据段后添加一个冗余码（帧检验序列FCS） &#x3D;&gt; 发送端根据一定的算法生成，接收端根据一定的算法检测（别问，问就是了解就行了，难道我还要把算法的逻辑说出来嘛，呜呜呜）。\n值得一提的是，FCS的生成和CRC的运用，都是在硬件层面进行的，非常之快。\n数据链路层只能以一种无限接近1的概率向上抛出帧，保障帧无差错。\n但是依然会出现这三个问题：帧丢失、帧失序、帧重复 &#x3D;&gt; 不能提供可靠的传输服务\n\n\n关于MAC地址相信大家都听过一个词，叫做“MAC地址”，到底是一个什么东西呢？ 它就是一个硬件地址，网卡（或者说网络适配器）厂商在生产的时候，写死在硬件里面的，全球唯一的。 网络适配器有过滤功能。每收到一个MAC帧，先用硬件检测一下MAC帧中的硬件地址，看一下是不是发往本站的。是，则收下；不是，则丢弃。 （所以，MAC地址也叫做硬件地址）\n\n","slug":"计网/计算机网络","date":"2024-12-03T14:23:01.000Z","categories_index":"八股","tags_index":"计算机网络","author_index":"Ivan"},{"id":"282ca770e6df8001dbda062738b2a12a","title":"java面向对象","content":"Java给我的感觉就是一个有一个的类，毕竟类是其代码的基本组织单元。\n对象是类实例化的结果，所以对象有时也被称为实例，从类到对象的过程称为实例化。\n面向对象的三大特点：封装、继承、多态\n封装学术上的东西就不讲了，从开发的视角阐述这个概念。\n通常我们都会将字段的可访问性设置为private，然后通过Getter和Setter方法对外提供查看和设置字段值的接口。\n（我习惯于称作字段，貌似大家都喜欢叫属性）\n上代码：\n12345678910111213141516171819202122public class Person &#123;    private String name;    private int age;        public Person(String name, int age) &#123;        this.name = name;        this.age = age;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public int getAge() &#123;        return age;    &#125;    public void setAge(int age) &#123;        this.age = age;    &#125;&#125;\n\n这是一个Person类，对人这个实体的抽象。类中有两个字段：name和age，代表人的姓名和年龄。从代码层面上看，Person类外面的任何方法都不能直接访问这两个字段，只能通过类中提供的方法进行访问和修改。\n这就是封装！！！\n至于说有什么有点，AI来吧：\n面向对象编程（OOP）中的封装是一个核心概念，它提供了以下优点：\n\n数据隐藏：封装允许对象隐藏其内部状态和复杂性，只暴露一个清晰的接口给外部世界。这降低了代码的复杂性，并提高了代码的可理解性。\n\n实现细节的保护：通过隐藏内部实现，封装防止了外部代码直接访问对象的内部数据，从而防止了可能的错误或不当的修改。\n\n接口与实现的分离：封装使得对象的内部实现可以独立于其接口进行修改，只要接口保持不变，外部代码就不需要修改。\n\n提高代码的可维护性：由于对象的内部实现被隐藏，修改这些实现不会影响依赖于该对象的代码，这使得维护和更新变得更加容易。\n\n增强代码的安全性：封装可以防止外部代码访问或修改对象的私有成员，这有助于防止潜在的安全风险。\n\n促进重用：封装提供了一个清晰的接口，使得对象可以在不同的程序和环境中重用，而不需要了解其内部工作机制。\n\n减少耦合：封装减少了类与类之间的直接依赖，从而降低了系统中各部分之间的耦合度。\n\n提高代码的可测试性：封装使得单元测试可以针对特定的对象进行，而不需要考虑整个系统的复杂性。\n\n支持多态：封装与多态一起工作，允许基于接口而非实现编程，这使得使用基类指针或引用调用派生类的方法成为可能。\n\n封装继承：在支持继承的语言中，封装允许子类继承父类的属性和方法，同时可以扩展或修改这些属性和方法，而不需要更改外部代码。\n\n促进模块化设计：封装鼓励将系统分解成模块或类，每个模块或类都有自己的职责，这有助于构建更大规模的系统。\n\n提高代码的组织性：封装要求将相关的数据和操作这些数据的方法组合在一起，这有助于提高代码的组织性和结构化。\n\n\n总的来说，封装是面向对象设计的一个关键原则，它有助于创建更健壮、更灵活和更易于维护的软件。\n随便扫一眼就行了。。。\n继承这个没有什么好说的，子类可以继承父类非private的字段和方法。\n在实际开发中，我们往往使用父类变量去引用子类对象，除非想调用子类对象的扩展的方法。\n1234567891011121314151617class Student extends Person &#123;    public Student(String name, int age) &#123;        super(name, age);    &#125;    public void sayHello()&#123;        System.out.println(&quot;Hello Java&quot;);    &#125;&#125;class Test &#123;    public static void main(String[] args) &#123;        Person person = new Student(&quot;kaiven&quot;, 20);        System.out.println(person.getName() + person.getAge());    &#125;&#125;\n\n由于Student继承了Person，所以Person类型的变量可以引用Student类型的对象。\n当然，考虑以下语句，能够正常运行：\n如果你尝试了，会发现不行。其实是可以的，因为引用的是Student对象嘛。但是，通不过编译器，因为Person类中没有sayHello这个方法。\n如果我们想调用属于这个子类对象的特有方法，只能通过类型强转去通过编译器的检查：\n1234567class Test &#123;    public static void main(String[] args) &#123;        Person person = new Student(&quot;kaiven&quot;, 20);        Student student = (Student) person;        student.sayHello();    &#125;&#125;\n\n多态不要去抓着这个字眼不放了，你越想就越容易钻牛角尖。\nJava中的多态，分为编译时多态和运行时多态。\n编译时多态指的是方法的重载：\n1234567891011121314class Student extends Person &#123;        public Student(String name, int age) &#123;        super(name, age);    &#125;    public void sayHello()&#123;        System.out.println(&quot;Hello Java&quot;);    &#125;    public void sayHello(String content)&#123;        System.out.println(content);    &#125;&#125;\n\n运行时多态指的是程序中定义的对象引用的具体类型在运行期间才确定。\n运行时多态的三个条件：继承、覆盖（重写）、向上转型\n123456789101112131415161718192021222324252627282930313233class Student extends Person &#123;    public Student(String name, int age) &#123;        super(name, age);    &#125;    @Override    public String getName() &#123;        return &quot;我就不告诉你我的名次&quot;;    &#125;    &#125;class Teacher extends Person&#123;    public Teacher(String name, int age) &#123;        super(name, age);    &#125;        @Override    public String getName() &#123;        return &quot;我可以告诉你我的名字，但是是假的&quot;;    &#125;&#125;class Test &#123;    public static void main(String[] args) &#123;        Person person01 = new Student(&quot;kaiven&quot;, 20);        Person person02 = new Teacher(&quot;jack&quot;, 22);        System.out.println(person01.getName());        System.out.println(person02.getName());    &#125;&#125;\n\nJVM知道应该调用哪个方法的，不用担心。\n\n","slug":"java基础/javamxdx","date":"2024-12-03T13:21:54.000Z","categories_index":"八股","tags_index":"java","author_index":"Ivan"},{"id":"5d0fb8fa16015e90389a3f31d7e8667c","title":"java导学","content":"恭喜你，成功入坑Java开发，以后将走上后端开发的道路。\nJava是一门什么样的编程语言呢？\n（AI的回答）\nJava 是一种广泛使用的编程语言，它由Sun Microsystems（现在是Oracle Corporation的一部分）在1995年发布。Java 被设计为具有跨平台兼容性、安全性、网络中心化和健壮性等特点，这使得它成为了构建企业级应用、Android 应用、网站后台服务和其他类型软件的热门选择。\n以下是Java的一些关键特性：\n\n跨平台兼容性：Java的口号“一次编写，到处运行”（Write Once, Run Anywhere，简称WORA）强调了其跨平台的能力。这意味着在一台机器上编写的Java程序可以在其他装有Java虚拟机（JVM）的机器上运行，而无需任何修改。\n\n面向对象：Java是一种面向对象的语言，它支持类、对象、封装、继承和多态等概念。\n\n内存管理：Java有自动垃圾回收机制，这意味着程序员不需要（也不能）手动管理内存。这减少了内存泄漏和其他内存管理错误的可能性。\n\n健壮性：Java的设计目标之一是创建一个健壮的语言，这意味着它旨在消除某些类别的错误，例如数组越界、野指针等。\n\n安全性：Java提供了一个安全的环境，其中包括一个沙箱执行环境和一个强大的安全管理体系。\n\n多线程：Java内置了对多线程编程的支持，这使得开发多线程应用程序变得相对容易。\n\n网络编程：Java有强大的网络编程支持，这使得它非常适合创建网络应用程序和服务。\n\n开源：Java有一个活跃的开源社区，提供了大量的库和框架，如Spring、Hibernate等，这些工具可以帮助开发者快速构建高质量的应用程序。\n\n\nJava在企业级应用开发中非常流行，也被广泛应用于Android移动应用开发。此外，Java还被用于桌面应用程序、游戏开发、科学计算和教育等领域。随着技术的发展，Java也在不断更新和改进，以适应新的编程范式和市场需求。\n快速的浏览一下就好了，对于一个小白来说，这些都是废话。学就完事儿了，现在，管这么多的概念干嘛。\n学的东西是不是很多嘞？\n的确是这样的，技术这种东西是学不完的。我之所以入坑Java就是因为觉得Java框架的统一性，就只用学一个Spring框架。可是深入学习后，才知道是我肤浅了。\n（之前是写前端的，然后就是觉得前端的生态太乱了，真的是百花齐放，然后转到Java后端，发现，其实也差不多）\n但是无论技术多么的复杂多样，掌握好基本的开发要求，不断的扩展知识和技术，这才是正解。\n如果你和我一样，学一个东西非要去搞清楚底层的运行原理或者源码实现，那么，恭喜你，你会陷入一个内耗循环。\n不是说这样不好，但是技术这个东西真的太多啦。比如说一个消息中间件，就有ActiveMQ、RabbitMQ、Kafka、RocketMQ。。。\n你去学嘛，你去看源码嘛，哈哈。\n对于一门技术，我们的态度应该是：\n\n搞明白基本的概念和特性，明白大致的应用场景\n学会技术的基本使用以及了解一些高级特性的适用场景\n对于基本原理，围绕面试八股展开，出现频率高的，重点学习\n源码嘛，看时间喽（如果有人给你出视频去讲源码了，那就不要浪费时间自己看）\n\n不要总是想着要把技术搞得多么的牛逼，要让面试官觉得你牛逼，那才是真的牛逼。\n（面试，也是一门技术活）\n不过，现在，不用考虑这么多，干就完事儿！\n\n","slug":"java导学","date":"2024-12-03T13:13:19.000Z","categories_index":"八股","tags_index":"java,java基础","author_index":"Ivan"},{"id":"eb843316efe7fc0d2e0c7904a0ae2582","title":"mysql进阶","content":"MySQL的系统架构1、数据库和数据库实例在与MySQL相关的学习和研究中，我们需要搞清楚一些概念：\n\n数据库：按照一定的数据结构来组织、存储和管理数据的仓库，通常由数据库管理系统进行管理。\n数据库管理软件（RDBMS）：就是我们说的数据库管理软件，我们常说的MySQL指的就是它。\n数据库实例：其实就是正在运行的数据库管理程序，一个数据库管理程序我们称作一个数据库实例。\n\n2、MySQL架构\n（现在的话，有个印象就行了）\n（1）MySQL向外提供的交互接口Connectors组件，是MySQL向外提供的交互组件，如java,.net,php等语言可以通过该组件来操作SQL语句，实现\n与SQL的交互。通过客户端&#x2F;服务器通信协议与MySQL建立连接。MySQL 客户端与服务端的通信方式是 “ 半双工\n”。对于每一个 MySQL 的连接，时刻都有一个线程状态来标识这个连接正在做什么。\n（2）管理服务组件和工具组件提供MySQL的各项服务组件和管理工具，如备份(Backup)，恢复(Recovery)，安全管理(Security)等功能。\n（3）连接池组件负责监听客户端向MySQL Server端的各种请求，接收请求，转发请求到目标模块。每个成功连接MySQL Server的客户请求都会被创建或分配一个线程，该线程负责客户端与MySQL Server端的通信，接收客户端发送的命令，传递服务端的结果信息等。\n（4）SQL接口组件接收用户SQL命令，如DML,DDL和存储过程等，并将最终结果返回给用户。\n（5）查询分析器组件首先分析SQL命令语法的合法性，并进行抽象语法树解析，如果sql有语法错误，会抛出异常信息。\n（6）优化器组件对SQL命令按照标准流程进行优化分析，mysql会按照它认为的最优方式进行优化，选用成本最小的执行计划。\n（7）缓存组件缓存和缓冲组件，这里边的内容我们后边会详细的讲解。\n（8）MySQL存储引擎MySQL属于关系型数据库，而关系型数据库的存储是以表的形式进行的，对于表的创建，数据的存储，检索，更新等都是由MySQL存储引擎完成的。\nMySQL存储引擎在MySQL中扮演着重要角色。研究过SQL Server和Oracle的读者可能很清楚，这两种数据库的存\n储引擎只有一个，而MySQL的存储引擎种类比较多，如MyIsam存储引擎，InnoDB存储引擎和Memory存储引\n擎。\n因为mysql本身就是开源的，他允许第三方基于MySQL骨架，开发适合自己业务需求的存储引擎。从MySQL存储引擎种类上来说，可以分为官方存储引擎和第三方存储引擎，比较常用的存储引擎包括InnoDB存储引擎，MyIsam 存储引擎和Momery存储引擎。\n3、SQL语句的执行流程\n（图应该都可以看得懂的吧）\n小问题：MySQL8为什么取消了查询缓存？\n锁争用问题：在高并发环境中，查询缓存会引起锁争用问题。每次对查询缓存的读写操作都需要获取锁，这在高并发下会导致锁的争用，进而引发性能瓶颈。\n缓存无效化问题：查询缓存的无效化机制导致缓存命中率较低。当一个表的数据发生变化时（如INSERT、UPDATE、DELETE操作），与该表相关的所有查询缓存都会被无效化。对于写操作频繁的系统，这意味着查询缓存的有效性非常短暂，导致缓存命中率很低，反而增加了缓存维护的开销而没有带来明显的性能提升。\n内存开销：查询缓存的管理需要额外的内存资源，而且如果查询语句的字符大小写、空格或者注释的不同，查询缓存都会认为是不同的查询（因为他们的hash值会不同），这可能会导致内存资源的过度消耗。\n\nMySQL的目录结构windows中的目录结构在mysql启动的时候，会从【安装目录】加载软件数据，在运行过程中，会从【数据目录】中读取数据。这两个目\n录我们不要放在一起，避免重新安装软件导致数据丢失：\n\n\nbin目录：用于放置一些可执行的工具文件，如mysql.exe、mysqld.exe、mysqlshow.exe等。\ninclude目录：用于放置一些头文件，如：mysql.h、mysql_ername.h等。（MySQL是C语言写的，这个都知道的吧）\nlib目录：用于放置一系列库文件。\ndata目录：用于放置一些日志文件以及数据库。\nmy.ini文件：MySQL的配置文件，MySQL实例初始化时会加载该文件中的内容\n\n\ndata目录中，每个文件夹对应一个数据库，数据库中的表就是一个又一个的文件。\nLinux中的文件目录这个和windows下的文件目录是差不多的，如果是默认的安装方式的话，文件是分散在不同地方的。\n（百度或者问AI）\n字符集和排序规则mysql支持大量的字符集，但是我们通常使用的是utf8，【show collation】命令可以查看mysql支持的所有的排序规则和字符集，如下所示部分：\n1show collation like &#x27;%utf8%&#x27;;\n\n\n一种字符集会对应很多的规则：\n\nutf8-polish-ci，表示utf-8的字符集的波兰语的比较规则，ci代表忽略大小写。\n\nutf8-general-ci，就是通用的忽略大小写的utf8字符集比较规则。\n\nutf8mb4_0900_ai_ci中的0900指的是Unicode 9.0的规范，后边的后缀代表不区分重音也不区分大小写，他是utf8mb4字符集一个新的通用排序归则。\n\n\n\nutf8和utf8mb4的区别：\n\nutf8mb3(utf-8)：使用1~3个字节表示字符，utf8默认就是utf8mb3。\n\nutf8mb4：使用1~4个字节表示字符，他是utf8的超集，甚至可以存储很多【emoji表情?????】，\n\nmysql8.0已经默认字符集设置为utf8mb4。\n\n\n【字符集】和【比较规则】可以作用在全局、数据库、表、甚至是列级别。（想了解的自行百度怎么设置，大家最熟悉的莫过于在创建库和表的时候指定字符集和比较规则吧）\nMySQL修改配置的方法1、修改全局变量很显然，这些东西你百度都能得到的，这里就不去复制粘贴了。全局修改的变量对每一个会话都起作用。\n2、当前会话的变量这个修改的作用域只对某一个会话起作用。\n3、修改配置文件先看一个示例：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225[client]port = 3306socket = /tmp/mysql.sock[mysqld]port = 3306basedir = /project/mysql/mysql-8.0.18datadir = /project/mysql/datapid-file = /project/mysql/mysql-8.0.18/mysqld.pidsocket = /tmp/mysql.socktmpdir = /project/mysql/tmpuser = mysql#关闭MySQL X plugin（33060）mysqlx=0###日志配置------innodb_log_file_size = 1Glog_error = /project/mysql/mysql-8.0.18/log/error.logslow_query_log = 1long_query_time = 5slow_query_log_file = /project/mysql/mysql-8.0.18/log/slow.log#记录没有索引导致的慢查询###连接配置------#最大连接数max_connections = 3000#最大错误连接数max_connect_errors = 10#连接闲置超时时间interactive_timeout = 1800wait_timeout = 1800#连接响应超时时间connect-timeout = 60###默认配置（插件、字符------default_authentication_plugin = mysql_native_passwordcharacter-set-server = utf8sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLESinnodb_log_file_size = 1024M#关闭InnoDB严格模式，防止报错 Row size too large (&gt; 8126)innodb_strict_mode=0default-storage-engine=INNODBbind-address = 0.0.0.0#域名解析，设置为1之后就不能直接127.0.0.1连接数据库，需要root@127.0.0.1#skip_name_resolve = 1#忽略大小写，此项很重要（MySQL8之后的版本必须在初始化就设定此参数，初始化之后配置更改不生效）lower_case_table_names = 1###主备相关------server-id = 25log-bin = backup.log#二进制日志格式,三种模式：statement语句&gt;模式,row行模式，mixed混合模式binlog_format = mixedmax_binlog_size = 1Gexpire_logs_days = 7#事务提交前产生的日志缓存binlog_cache_size = 16M#Auto_increment_increment和auto_increment_offset用于主－主服务器（master-to-master）复制，避免主键冲突#为了避免两台服务器同时做更新时自增长字段的值之间发生冲突。一般在主主同步配置时，需要将两台服务器的auto_increment_increment增长量都配置为2（根据从库节点数量配置），而要把auto_increment_offset分别配置为1（主库）和2（从库）#递增值auto_increment_increment = 2#初始值auto_increment_offset = 1#表示需要记录二进制日志的数据库binlog_do_db=csspbinlog_do_db=mysql#从库配置replicate_do_db=cssp#表示不需要记录二进制日志的数据库binlog_ignore_db=information_schema#忽略表replicate-wild-ignore-table=pva_db.pva_login_%replicate-wild-ignore-table=pva_db.pva_login_log#忽略错误代码（从库配置）slave-skip-errors = 1032,1062,126,1114,1146,1048,1396#自动清空不再需要中继日志（从库配置）relay-log-purge = 1###系统资源相关------#接收连接请求队列back_log = 600#最大打开文件数（前提mysql用户需要调整最大打开文件数）open_files_limit = 10240#所有线程打开表数量table_open_cache = 512#处理请求包最大大小max_allowed_packet = 32M#临时表最大大小tmp_table_size = 512M#独立内存表所允许最大容量max_heap_table_size = 512M#用于索引块的缓冲区大小key_buffer_size = 64M#查询排序的缓冲区大小sort_buffer_size = 8M#读操作的缓冲区大小read_buffer_size = 8M#联表查询缓冲区大小join_buffer_size = 8M#批量数据插入缓存bulk_insert_buffer_size = 120M#保存索引以及原始数据的缓冲池（原则上最大为系统内存的 80%）innodb_buffer_pool_size = 2G#脏页比例，脏页占innodb_buffer_pool_size的比例时，触发刷脏页到磁盘（25~50）innodb_max_dirty_pages_pct = 30#事务提交 flushinnodb_flush_log_at_trx_commit = 1#1，（默认值）每一次提交刷新日志到磁盘#2，先写入缓存，由系统设置每秒刷新日志到磁盘（可能丢失1~2秒的数据）###多线程优化------#可重新被利用保存在缓存中的线程数量thread_cache_size = 300###其他配置------#占用内存过高调整以下参数配置#table_definition_cache = 400#open_files_limit = 2048#table_open_cache = 256#跳过密码表检查#skip-grant-tables\n\n修改了配置文件需要重启MySQL服务实例重新加载。\n内置数据库\nmysql：这个库很重要，他是mysql的核心数据库，负责存储数据库的用户、权限设置、关键字等mysql自己需要使用，控制和管理的信息。\n\ninformation_schema：这个数据库维护了数据库其他表的一些描述性信息，也称为元数据。比如，当前有哪\n\n\n些表，哪些视图，哪些触发器，哪些列等。\n\nperformation_schema：这个数据库用来存储mysql服务器运行过程中的一些状态信息，是做性能监控的。\n\n比如最近执行了什么sql语句，内存使用情况等\n\nsys：结合information_schema和performation_schema的数据，能更方便的了解mysql服务器的性能信\n\n息。\n\n2024.11.05\nwriteBy kaiven\n","slug":"mysql/mysql进阶","date":"2024-12-03T12:56:15.000Z","categories_index":"八股","tags_index":"mysql","author_index":"Ivan"},{"id":"76e26cf6d70a50daf8e75fb7d566964d","title":"面试官到底喜欢什么样的人？","content":"面试官到底喜欢什么样的人？在统一批次的面试中，可能就有好几百号人，无可否认的是，我们都喜欢优秀的人，都想和优秀的人共事，那怎么表现出我们的优秀呢？\n面试官喜欢爱学习、爱动脑、有技术广度和深度并且有实际经验的人。\n面试时间一般30分钟左右，我们必须通过自己的话术，去展现【爱学习、爱动脑、技术广度和深度以及实际经验】给他&#x2F;她看。\n建立正确的面试心态在这种大环境下，面试时间会被拉的很长，一面、二面、三面……面试的环节越多，那么你挂掉的概率也就越大，但没办法，就是这么卷。。。\n我们不需要唬住所有的面试官，因为在面试的过程中，面试官是用他最熟悉的东西去问题，有可能他熟悉的地方你并不是特别的熟悉，所以可能就会出现答得不好或者答不上来的情况，这很正常。。。\n我们做的事情，就是拿下我们能拿下的面试官。其实大部分面试官都是一边工作一边去面试的，所以八股的知识也就一般。比如说大厂的面试官，可能就会对原理性的东西进行深层次的拷打，如果你还只能回答出一些表面性的东西或者说大家都会说的一些东西，那么就不能体现出你的优势，面试挂掉的概率极大。当然，这些面试官也不是我们的菜。\n这小节最重要的一点就是：你对面试准备有多充分，就决定了你能找到什么样的工作！\n（不会说你随便糊弄了一下就能拿到一份很好的offer，而别人准备了大半年却颗粒无收，匹配机制嘛，找到符合自己目前口味的面试官，才是重点）\n如何把面试官拉倒坑里？上文也叙述过，其实大部分面试官的水平也一般，所以他其实也不知道自己该问些什么东西，如果你也没有对他进行相关的引导的话，他不就只能随便问了嘛。\n如何引导面试官？原理其实也比较简单：\n\n自我介绍阶段，突出描述自己擅长的部分\n回答问题的时候，为下一个问题做铺垫\n\n对于自我介绍，下文会进行详细的叙述。\n我们来说一下第二点，往往面试官问的问题都是层层递进的，会从你对某个问题的回答中捕风捉影，想好下一个要问你的问题。那是不是可以提前预判呢？把面试官引导上你准备好的问题链中去。\n还要一个比较重要的点就是拖延时间，或者说扩展描述，做到问一答三，因为你能回答出来的东西，那肯定是你提前准备好的，你给他暴露的信息越多，他问的点也就越多。但是，短短的半小时，他不可能什么都去问你，一定是从你的问答中挑他感兴趣的点，继续追问。你给他的选项，一定是你准备过的，每个点都这样的去扩展描述，一方面体现出你是一个【爱学习、爱动脑、有技术广度和深度并且有实际经验的人】，另一方面这样也将面试时间的主导权交到了自己的手上，你一直再说，面试官一直在听，问个两三个问题后，他可能就不会在问其他的了。\n（面试也要占用面试官的时间，谁不想休息啊，而且人家也有自己的事情要去做）\n面试的本质是什么？问题：面试是介绍你自己还是你的项目？\n答案：一定是介绍你自己。本质上来说，大多数的项目都是CRUD，没有什么特别的亮点。那和面试官对话的时候，就不要关注项目本身了，而是要去关注某个功能的实现，简单描述一下项目中的功能是怎么去实现的，然后重点叙述一下该方式存在什么样的不足，你会怎么去解决这个问题？\n场景：\n假设你现在的项目就是一个纯粹的后端管理系统，登录方式采用的是JavaWeb的Cookie + Session。\n针对该功能的叙述：\n由于我这个项目其实是一个学习项目，算不上真正意义上的生产级别的项目，所以登录功能只是采用了JavaWeb的 Cookie + Session 这样一种简单的形式。但是呢，这样做存在一些问题。比如说在分布式的环境中，多个JVM实例无法共享 Session ，就会出现明明用户已经登录了，但是后续的请求打在了其他机器上，导致用户会出现重复登录的情况，用户体验感不好。针对这个问题，需要我们去实现session的共享嘛，常见的实现方式就是将 Session 对象序列化放入 Redis 中进行共享，然后每一次的登录请求都去查询Redis。但是呢，这种方式也会出现一定的问题，。。。。。\n（你需要根据实际的场景去提前写好这些话术，你这一套话术下来，是不是达到了拖延时间的效果？你准备的这些话术中的内容的扩展问题你也回去准备的，是不是将面试官引入坑里面了？这一堆东西下来，是不是体现了你是一个【爱学习、爱动脑、有技术广度和深度并且有实际经验的人】？）\n公司招你肯定不是简单的让你做你熟悉的业务，而是想给你什么业务你都能够应对。\n你是一个厨师，业务需求就是食材，只会做几道菜的不叫做厨师。\n项目的亮点角度：架构、业务拆分、技术选型、大数据量处理\n如何写好简历避免已读不回？简历到底看什么？（校招）\n学历（至少全日制本科）\n专业排名（非科班成绩优异也可以，至少证明学习能力很强 &#x3D;&gt; 黑魔法）\n荣誉奖项（黑魔法，如果是大厂的话，斟酌一下，很有可能会让你提供证明材料）\n实习经历（大厂很加分，也可以黑魔法，但是不建议）\n\n学历这个东西确实没有办法，现在的大环境就是这样的，如果你是专科的同学，那么请先专升本，否则你可能会感慨世界的炎凉。（专升本你就写你本科的学历就好了，装傻）\n专业排名真的是最好造假的了，前20%？可以不？谁会去管呢？\n荣誉奖项也是，基本上不会查的，而且你也不会写什么特别高级的奖项，比如说 ACM金牌。。。（当然，如果是大厂的话，背景调查可能比较严格哦，请斟酌）\n实习经历也可以造假的，对，没错，只要你能唬住面试官。（大厂同样需要斟酌）\n如果是找实习的同学，那么肯定是没有实习经历这么一说的（除非你有过一段），那么重点在你的项目经历上。\n虽然说面试是介绍我们自己，但是前提是简历得入得了面试官的法眼，否则面试的资格都没有。\n一个项目的基本元素：\n项目名称（次要，但是不能太土）\n个人职责（在项目中负责什么，应届生次要）\n项目的线上地址（重要，增加项目的真实度）\n项目简介（重要，让面试官能够了解你这个项目的业务类型）\n项目的亮点（重要）\n\n对于项目简介，一定要言简意赅，主要是要让面试官知道你这个项目的大概业务有哪些。你做的那些项目基本上都能找到相似且开源的（大部分同学的项目也是根据这些开源的项目改的），所以没必要去过多的介绍。所以，这里你的项目名称最好是见名知意，比如说xx在线教育平台，面试官甚至都不用去读你的项目简介，就知道你这个项目的业务有哪些。\n对于项目的亮点，这个东西，得从实际的项目出发，体现出你的思考，还是那句话，可能项目真的没有什么亮点，就是一个很普通的CURD。但是，你可以通过引入一些其他的技术，去解决了什么问题，优化了什么东西。（无论是公司里面的大项目还是你的小项目，都会有bug和不足，不然为什么要持续的更新迭代，总会有问题的。）而且，你的亮点话术，要做到有针对性，而不是这些语句迁移到其他的项目上都能使用。\n(什么样的场景，通过什么方式，解决了什么问题或者优化了什么东西)\n如何做好自我介绍？（面试中最重要的环节）好的自我介绍有什么用？\n体现出你自己的价值和逻辑思维能力，快速让面试官对你感兴趣\n引导面试官对你进行提问\n\n什么是一份好的自我介绍？\n语言的流利程度，表达能力流畅的人，面试成功率会高很多。因为语言表达流利的话，证明了你的思维逻辑是流畅的，沟通能力是OK的。\n把自己相关的优势介绍清楚。\n能够讲清楚自己在项目中的职责，成果，并且有量化的数据支撑（人对数字是比较敏感的）。\n拉平和面试官之间的信息差，让面试官能够快速带入我们的项目中，能清楚他想要问的问题。\n\n很有必要去手写一份800字左右的自我介绍，在面试之前不断的打磨，这样才能在面试的时候流利的阐述。\n八股文怎么去准备怎么去回答？八股文这个东西是必须背的，你很难保证面试官不会去问，特别是对于应届生而言。\n八股文大概考什么？市面上的八股文这么多，动不动就几十万字的，没必要啊。这东西是有重点的：\n\njava基础：集合类、JVM、锁、多线程（这里会有实操，比如写代码实现三个线程交替打印“abc”）。\nJUC、AQS、线程池。线程池的核心参数，拒绝策略，队列有哪些。\nSpring、SpringMVC、SpringBoot：老演员了，问的也就那些东西（这里可以结合设计模式去讲，Spring中运用了大量的设计模式）。\nMySQL：。。。\nRedis：数据结构，一些机制。\n\n这里给鱼皮（B站搜索：程序员鱼皮）的面试鸭刷题网站打一个广告：https://www.mianshiya.com/\n这是一个专门为程序员提供的在线刷题平台，涵盖从IT各大学科的面试经典八股文，支持网页端和小程序端，目前（2024.10.20）永久会员只需要 129 元。\n（不要求每一道八股文你都能回答得很好，但是你必须有一两道八股文讲得非常出彩，结合自己的理解和实际的业务场景）\n总结总的来说，面试的宗旨就是：通过和面试官的沟通，去展示你的优秀，你是一个爱学习、爱动脑、有技术广度和深度并且有实际经验的人。\n","slug":"面试","date":"2024-12-03T12:35:49.000Z","categories_index":"","tags_index":"面试","author_index":"Ivan"},{"id":"3316961ecf1671c6065b043220187c47","title":"Java基础","content":"# Java基础# 概念# 说一下Java的特点主要有以下的特点：\n\n平台无关性：Java的“编写一次，运行无处不在”哲学是其最大的特点之一。Java编译器将源代码编译成字节码（bytecode），该字节码可以在任何安装了Java虚拟机（JVM）的系统上运行。\n面向对象：Java是一门严格的面向对象编程语言，几乎一切都是对象。面向对象编程（OOP）特性使得代码更易于维护和重用，包括类（class）、对象（object）、继承（inheritance）、多态（polymorphism）、抽象（abstraction）和封装（encapsulation）。\n内存管理：Java有自己的垃圾回收机制，自动管理内存和回收不再使用的对象。这样，开发者不需要手动管理内存，从而减少内存泄漏和其他内存相关的问题。\n\n# Java为什么是跨平台的？Java 能支持跨平台，主要依赖于 JVM 关系比较大。\nJVM也是一个软件，不同的平台有不同的版本。我们编写的Java源码，编译后会生成一种 .class 文件，称为字节码文件。Java虚拟机就是负责将字节码文件翻译成特定平台下的机器码然后运行。也就是说，只要在不同平台上安装对应的JVM，就可以运行字节码文件，运行我们编写的Java程序。\n而这个过程中，我们编写的Java程序没有做任何改变，仅仅是通过JVM这一”中间层“，就能在不同平台上运行，真正实现了”一次编译，到处运行“的目的。\nJVM是一个”桥梁“，是一个”中间件“，是实现跨平台的关键，Java代码首先被编译成字节码文件，再由JVM将字节码文件翻译成机器语言，从而达到运行Java程序的目的。\n编译的结果不是生成机器码，而是生成字节码，字节码不能直接运行，必须通过JVM翻译成机器码才能运行。不同平台下编译生成的字节码是一样的，但是由JVM翻译成的机器码却不一样。\n所以，运行Java程序必须有JVM的支持，因为编译的结果不是机器码，必须要经过JVM的再次翻译才能执行。即使你将Java程序打包成可执行文件（例如 .exe），仍然需要JVM的支持。\n跨平台的是Java程序，不是JVM。JVM是用C&#x2F;C++开发的，是编译后的机器码，不能跨平台，不同平台下需要安装不同版本的JVM。\n\n# JVM、JDK、JRE三者关系？\n它们之间的关系如下：\n\nJVM是Java虚拟机，是Java程序运行的环境。它负责将Java字节码（由Java编译器生成）解释或编译成机器码，并执行程序。JVM提供了内存管理、垃圾回收、安全性等功能，使得Java程序具备跨平台性。\nJDK是Java开发工具包，是开发Java程序所需的工具集合。它包含了JVM、编译器（javac）、调试器（jdb）等开发工具，以及一系列的类库（如Java标准库和开发工具库）。JDK提供了开发、编译、调试和运行Java程序所需的全部工具和环境。\nJRE是Java运行时环境，是Java程序运行所需的最小环境。它包含了JVM和一组Java类库，用于支持Java程序的执行。JRE不包含开发工具，只提供Java程序运行所需的运行环境。\n\n# 为什么Java解释和编译都有？首先在Java经过编译之后生成字节码文件，接下来进入JVM中，就有两个步骤编译和解释。 如下图：\n\n编译性：\n\nJava源代码首先被编译成字节码，JIT 会把编译过的机器码保存起来,以备下次使用。\n\n解释性：\n\nJVM中一个方法调用计数器，当累计计数大于一定值的时候，就使用JIT进行编译生成机器码文件。否则就是用解释器进行解释执行，然后字节码也是经过解释器进行解释运行的。\n\n所以Java既是编译型也是解释性语言，默认采用的是解释器和编译器混合的模式。\n# jvm是什么JVM是 java 虚拟机，主要工作是解释自己的指令集（即字节码）并映射到本地的CPU指令集和OS的系统调用。\nJVM屏蔽了与操作系统平台相关的信息，使得Java程序只需要生成在Java虚拟机上运行的目标代码（字节码），就可在多种平台上不加修改的运行，这也是Java能够“一次编译，到处运行的”原因。\n# 编译型语言和解释型语言的区别？编译型语言和解释型语言的区别在于：\n\n编译型语言：在程序执行之前，整个源代码会被编译成机器码或者字节码，生成可执行文件。执行时直接运行编译后的代码，速度快，但跨平台性较差。\n解释型语言：在程序执行时，逐行解释执行源代码，不生成独立的可执行文件。通常由解释器动态解释并执行代码，跨平台性好，但执行速度相对较慢。\n典型的编译型语言如C、C++，典型的解释型语言如Python、JavaScript。\n\n# Python和Java区别是什么？\nJava是一种已编译的编程语言，Java编译器将源代码编译为字节码，而字节码则由Java虚拟机执行\npython是一种解释语言，翻译时会在执行程序的同时进行翻译。\n\n# 数据类型# 八种基本的数据类型Java支持数据类型分为两类： 基本数据类型和引用数据类型。\n基本数据类型共有8种，可以分为三类：\n\n数值型：整数类型（byte、short、int、long）和浮点类型（float、double）\n字符型：char\n布尔型：boolean\n\n\n8种基本数据类型的默认值、位数、取值范围，如下表所示：\n\nFloat和Double的最小值和最大值都是以科学记数法的形式输出的，结尾的“E+数字”表示E之前的数字要乘以10的多少倍。比如3.14E3就是3.14×1000&#x3D;3140，3.14E-3就是3.14&#x2F;1000&#x3D;0.00314。\n注意一下几点：\n\njava八种基本数据类型的字节数:1字节(byte、boolean)、 2字节(short、char)、4字节(int、float)、8字节(long、double)\n浮点数的默认类型为double（如果需要声明一个常量为float型，则必须要在末尾加上f或F）\n整数的默认类型为int（声明Long型在末尾加上l或者L）\n八种基本数据类型的包装类：除了char的是Character、int类型的是Integer，其他都是首字母大写\nchar类型是无符号的，不能为负，所以是0开始的\n\n# long和int可以互转吗 ？可以的，Java中的long和int可以相互转换。由于long类型的范围比int类型大，因此将int转换为long是安全的，而将long转换为int可能会导致数据丢失或溢出。\n将int转换为long可以通过直接赋值或强制类型转换来实现。例如：\n12int intValue = 10;long longValue = intValue; // 自动转换，安全的\n\n将long转换为int需要使用强制类型转换，但需要注意潜在的数据丢失或溢出问题。\n\n例如：\n12long longValue = 100L;int intValue = (int) longValue; // 强制类型转换，可能会有数据丢失或溢出\n\n在将long转换为int时，如果longValue的值超出了int类型的范围，转换结果将是截断后的低位部分。因此，在进行转换之前，建议先检查longValue的值是否在int类型的范围内，以避免数据丢失或溢出的问题。\n# 数据类型转换方式你知道哪些？\n自动类型转换（隐式转换）：当目标类型的范围大于源类型时，Java会自动将源类型转换为目标类型，不需要显式的类型转换。例如，将int转换为long、将float转换为double等。\n强制类型转换（显式转换）：当目标类型的范围小于源类型时，需要使用强制类型转换将源类型转换为目标类型。这可能导致数据丢失或溢出。例如，将long转换为int、将double转换为int等。语法为：目标类型 变量名 &#x3D; (目标类型) 源类型。\n字符串转换：Java提供了将字符串表示的数据转换为其他类型数据的方法。例如，将字符串转换为整型int，可以使用Integer.parseInt()方法；将字符串转换为浮点型double，可以使用Double.parseDouble()方法等。\n数值之间的转换：Java提供了一些数值类型之间的转换方法，如将整型转换为字符型、将字符型转换为整型等。这些转换方式可以通过类型的包装类来实现，例如Character类、Integer类等提供了相应的转换方法。\n\n# 类型互转会出现什么问题吗？\n数据丢失：当将一个范围较大的数据类型转换为一个范围较小的数据类型时，可能会发生数据丢失。例如，将一个long类型的值转换为int类型时，如果long值超出了int类型的范围，转换结果将是截断后的低位部分，高位部分的数据将丢失。\n数据溢出：与数据丢失相反，当将一个范围较小的数据类型转换为一个范围较大的数据类型时，可能会发生数据溢出。例如，将一个int类型的值转换为long类型时，转换结果会填充额外的高位空间，但原始数据仍然保持不变。\n精度损失：在进行浮点数类型的转换时，可能会发生精度损失。由于浮点数的表示方式不同，将一个单精度浮点数(float)转换为双精度浮点数(double)时，精度可能会损失。\n类型不匹配导致的错误：在进行类型转换时，需要确保源类型和目标类型是兼容的。如果两者不兼容，会导致编译错误或运行时错误。\n\n# 为什么用bigDecimal 不用double ？double会出现精度丢失的问题，double执行的是二进制浮点运算，二进制有些情况下不能准确的表示一个小数，就像十进制不能准确的表示1&#x2F;3(1&#x2F;3&#x3D;0.3333…)，也就是说二进制表示小数的时候只能够表示能够用1&#x2F;(2^n)的和的任意组合，但是0.1不能够精确表示，因为它不能够表示成为1&#x2F;(2^n)的和的形式。\n比如：\n12345678910System.out.println(0.05 + 0.01);System.out.println(1.0 - 0.42);System.out.println(4.015 * 100);System.out.println(123.3 / 100);输出：0.0600000000000000050.5800000000000001401.499999999999941.2329999999999999\n\n可以看到在Java中进行浮点数运算的时候，会出现丢失精度的问题。那么我们如果在进行商品价格计算的时候，就会出现问题。很有可能造成我们手中有0.06元，却无法购买一个0.05元和一个0.01元的商品。因为如上所示，他们两个的总和为0.060000000000000005。这无疑是一个很严重的问题，尤其是当电商网站的并发量上去的时候，出现的问题将是巨大的。可能会导致无法下单，或者对账出现问题。\n而 Decimal 是精确计算 , 所以一般牵扯到金钱的计算 , 都使用 Decimal。\n123456789101112131415161718import java.math.BigDecimal;public class BigDecimalExample &#123;    public static void main(String[] args) &#123;        BigDecimal num1 = new BigDecimal(&quot;0.1&quot;);        BigDecimal num2 = new BigDecimal(&quot;0.2&quot;);        BigDecimal sum = num1.add(num2);        BigDecimal product = num1.multiply(num2);        System.out.println(&quot;Sum: &quot; + sum);        System.out.println(&quot;Product: &quot; + product);    &#125;&#125;//输出Sum: 0.3Product: 0.02\n\n在上述代码中，我们创建了两个BigDecimal对象num1和num2，分别表示0.1和0.2这两个十进制数。然后，我们使用add()方法计算它们的和，并使用multiply()方法计算它们的乘积。最后，我们通过System.out.println()打印结果。\n这样的使用BigDecimal可以确保精确的十进制数值计算，避免了使用double可能出现的舍入误差。需要注意的是，在创建BigDecimal对象时，应该使用字符串作为参数，而不是直接使用浮点数值，以避免浮点数精度丢失。\n# 装箱和拆箱是什么？装箱（Boxing）和拆箱（Unboxing）是将基本数据类型和对应的包装类之间进行转换的过程。\n12Integer i = 10;  //装箱int n = i;   //拆箱\n\n自动装箱主要发生在两种情况，一种是赋值时，另一种是在方法调用的时候。\n\n\n\n\n\n\n\n\n\n赋值时\n这是最常见的一种情况，在Java 1.5以前我们需要手动地进行转换才行，而现在所有的转换都是由编译器来完成。\n1234567//before autoboxingInteger iObject = Integer.valueOf(3);Int iPrimitive = iObject.intValue()//after java5Integer iObject = 3; //autobxing - primitive to wrapper conversionint iPrimitive = iObject; //unboxing - object to primitive conversion\n\n\n\n\n\n\n\n\n\n\n方法调用时\n当我们在方法调用时，我们可以传入原始数据值或者对象，同样编译器会帮我们进行转换。\n12345678public static Integer show(Integer iParam)&#123;   System.out.println(&quot;autoboxing example - method invocation i: &quot; + iParam);   return iParam;&#125;//autoboxing and unboxing in method invocationshow(3); //autoboxingint result = show(3); //unboxing because return type of method is Integer\n\nshow方法接受Integer对象作为参数，当调用show(3)时，会将int值转换成对应的Integer对象，这就是所谓的自动装箱，show方法返回Integer对象，而int result = show(3);中result为int类型，所以这时候发生自动拆箱操作，将show方法的返回的Integer对象转换成int值。\n\n\n\n\n\n\n\n\n\n自动装箱的弊端\n自动装箱有一个问题，那就是在一个循环中进行自动装箱操作的情况，如下面的例子就会创建多余的对象，影响程序的性能。\n1Integer sum = 0; for(int i=1000; i&lt;5000; i++)&#123;   sum+=i; &#125; \n\n上面的代码sum+=i可以看成sum = sum + i，但是+这个操作符不适用于Integer对象，首先sum进行自动拆箱操作，进行数值相加操作，最后发生自动装箱操作转换成Integer对象。其内部变化如下\n1int result = sum.intValue() + i; Integer sum = new Integer(result); \n\n由于我们这里声明的sum为Integer类型，在上面的循环中会创建将近4000个无用的Integer对象，在这样庞大的循环中，会降低程序的性能并且加重了垃圾回收的工作量。因此在我们编程时，需要注意到这一点，正确地声明变量类型，避免因为自动装箱引起的性能问题。\n# Java为什么要有Integer？Integer对应是int类型的包装类，就是把int类型包装成Object对象，对象封装有很多好处，可以把属性也就是数据跟处理这些数据的方法结合在一起，比如Integer就有parseInt()等方法来专门处理int型相关的数据。\n另一个非常重要的原因就是在Java中绝大部分方法或类都是用来处理类类型对象的，如ArrayList集合类就只能以类作为他的存储对象，而这时如果想把一个int型的数据存入list是不可能的，必须把它包装成类，也就是Integer才能被List所接受。所以Integer的存在是很必要的。\n\n\n\n\n\n\n\n\n\n泛型中的应用\n在Java中，泛型只能使用引用类型，而不能使用基本类型。因此，如果要在泛型中使用int类型，必须使用Integer包装类。例如，假设我们有一个列表，我们想要将其元素排序，并将排序结果存储在一个新的列表中。如果我们使用基本数据类型int，无法直接使用Collections.sort()方法。但是，如果我们使用Integer包装类，我们就可以轻松地使用Collections.sort()方法。\n123456List&lt;Integer&gt; list = new ArrayList&lt;&gt;();list.add(3);list.add(1);list.add(2);Collections.sort(list);System.out.println(list);\n\n\n\n\n\n\n\n\n\n\n转换中的应用\n在Java中，基本类型和引用类型不能直接进行转换，必须使用包装类来实现。例如，将一个int类型的值转换为String类型，必须首先将其转换为Integer类型，然后再转换为String类型。\n1234int i = 10;Integer integer = new Integer(i);String str = integer.toString();System.out.println(str);\n\n\n\n\n\n\n\n\n\n\n集合中的应用\nJava集合中只能存储对象，而不能存储基本数据类型。因此，如果要将int类型的数据存储在集合中，必须使用Integer包装类。例如，假设我们有一个列表，我们想要计算列表中所有元素的和。如果我们使用基本数据类型int，我们需要使用一个循环来遍历列表，并将每个元素相加。但是，如果我们使用Integer包装类，我们可以直接使用stream()方法来计算所有元素的和。\n123456List&lt;Integer&gt; list = new ArrayList&lt;&gt;();list.add(3);list.add(1);list.add(2);int sum = list.stream().mapToInt(Integer::intValue).sum();System.out.println(sum);\n\n# Integer相比int有什么优点？int是Java中的原始数据类型，而Integer是int的包装类。\nInteger和 int 的区别：\n\n基本类型和引用类型：首先，int是一种基本数据类型，而Integer是一种引用类型。基本数据类型是Java中最基本的数据类型，它们是预定义的，不需要实例化就可以使用。而引用类型则需要通过实例化对象来使用。这意味着，使用int来存储一个整数时，不需要任何额外的内存分配，而使用Integer时，必须为对象分配内存。在性能方面，基本数据类型的操作通常比相应的引用类型快。\n自动装箱和拆箱：其次，Integer作为int的包装类，它可以实现自动装箱和拆箱。自动装箱是指将基本类型转化为相应的包装类类型，而自动拆箱则是将包装类类型转化为相应的基本类型。这使得Java程序员更加方便地进行数据类型转换。例如，当我们需要将int类型的值赋给Integer变量时，Java可以自动地将int类型转换为Integer类型。同样地，当我们需要将Integer类型的值赋给int变量时，Java可以自动地将Integer类型转换为int类型。\n空指针异常：另外，int变量可以直接赋值为0，而Integer变量必须通过实例化对象来赋值。如果对一个未经初始化的Integer变量进行操作，就会出现空指针异常。这是因为它被赋予了null值，而null值是无法进行自动拆箱的。\n\n# 那为什么还要保留int类型？包装类是引用类型，对象的引用和对象本身是分开存储的，而对于基本类型数据，变量对应的内存块直接存储数据本身。\n因此，基本类型数据在读写效率方面，要比包装类高效。除此之外，在64位JVM上，在开启引用压缩的情况下，一个Integer对象占用16个字节的内存空间，而一个int类型数据只占用4字节的内存空间，前者对空间的占用是后者的4倍。\n也就是说，不管是读写效率，还是存储效率，基本类型都比包装类高效。\n# 说一下 integer的缓存Java的Integer类内部实现了一个静态缓存池，用于存储特定范围内的整数值对应的Integer对象。\n默认情况下，这个范围是-128至127。当通过Integer.valueOf(int)方法创建一个在这个范围内的整数对象时，并不会每次都生成新的对象实例，而是复用缓存中的现有对象，会直接从内存中取出，不需要新建一个对象。\n# 面向对象# 怎么理解面向对象？简单说说封装继承多态面向对象是一种编程范式，它将现实世界中的事物抽象为对象，对象具有属性（称为字段或属性）和行为（称为方法）。面向对象编程的设计思想是以对象为中心，通过对象之间的交互来完成程序的功能，具有灵活性和可扩展性，通过封装和继承可以更好地应对需求变化。\nJava面向对象的三大特性包括：封装、继承、多态：\n\n封装：封装是指将对象的属性（数据）和行为（方法）结合在一起，对外隐藏对象的内部细节，仅通过对象提供的接口与外界交互。封装的目的是增强安全性和简化编程，使得对象更加独立。\n继承：继承是一种可以使得子类自动共享父类数据结构和方法的机制。它是代码复用的重要手段，通过继承可以建立类与类之间的层次关系，使得结构更加清晰。\n多态：多态是指允许不同类的对象对同一消息作出响应。即同一个接口，使用不同的实例而执行不同操作。多态性可以分为编译时多态（重载）和运行时多态（重写）。它使得程序具有良好的灵活性和扩展性。\n\n# 多态体现在哪几个方面？多态在面向对象编程中可以体现在以下几个方面：\n\n方法重载：\n方法重载是指同一类中可以有多个同名方法，它们具有不同的参数列表（参数类型、数量或顺序不同）。虽然方法名相同，但根据传入的参数不同，编译器会在编译时确定调用哪个方法。\n示例：对于一个 add 方法，可以定义为 add(int a, int b) 和 add(double a, double b)。\n\n\n方法重写：\n方法重写是指子类能够提供对父类中同名方法的具体实现。在运行时，JVM会根据对象的实际类型确定调用哪个版本的方法。这是实现多态的主要方式。\n示例：在一个动物类中，定义一个 sound 方法，子类 Dog 可以重写该方法以实现 bark，而 Cat 可以实现 meow。\n\n\n接口与实现：\n多态也体现在接口的使用上，多个类可以实现同一个接口，并且用接口类型的引用来调用这些类的方法。这使得程序在面对不同具体实现时保持一贯的调用方式。\n示例：多个类（如 Dog, Cat）都实现了一个 Animal 接口，当用 Animal 类型的引用来调用 makeSound 方法时，会触发对应的实现。\n\n\n向上转型和向下转型：\n在Java中，可以使用父类类型的引用指向子类对象，这是向上转型。通过这种方式，可以在运行时期采用不同的子类实现。\n向下转型是将父类引用转回其子类类型，但在执行前需要确认引用实际指向的对象类型以避免 ClassCastException。\n\n\n\n# 多态解决了什么问题？多态是指子类可以替换父类，在实际的代码运行过程中，调用子类的方法实现。多态这种特性也需要编程语言提供特殊的语法机制来实现，比如继承、接口类。\n多态可以提高代码的扩展性和复用性，是很多设计模式、设计原则、编程技巧的代码实现基础。比如策略模式、基于接口而非实现编程、依赖倒置原则、里式替换原则、利用多态去掉冗长的 if-else 语句等等\n# 面向对象的设计原则你知道有哪些吗面向对象编程中的六大原则：\n\n单一职责原则（SRP）：一个类应该只有一个引起它变化的原因，即一个类应该只负责一项职责。例子：考虑一个员工类，它应该只负责管理员工信息，而不应负责其他无关工作。\n开放封闭原则（OCP）：软件实体应该对扩展开放，对修改封闭。例子：通过制定接口来实现这一原则，比如定义一个图形类，然后让不同类型的图形继承这个类，而不需要修改图形类本身。\n里氏替换原则（LSP）：子类对象应该能够替换掉所有父类对象。例子：一个正方形是一个矩形，但如果修改一个矩形的高度和宽度时，正方形的行为应该如何改变就是一个违反里氏替换原则的例子。\n接口隔离原则（ISP）：客户端不应该依赖那些它不需要的接口，即接口应该小而专。例子：通过接口抽象层来实现底层和高层模块之间的解耦，比如使用依赖注入。\n依赖倒置原则（DIP）：高层模块不应该依赖低层模块，二者都应该依赖于抽象；抽象不应该依赖于细节，细节应该依赖于抽象。例子：如果一个公司类包含部门类，应该考虑使用合成&#x2F;聚合关系，而不是将公司类继承自部门类。\n**最少知识原则 (Law of Demeter)**：一个对象应当对其他对象有最少的了解，只与其直接的朋友交互。\n\n# 重载与重写有什么区别？\n重载（Overloading）指的是在同一个类中，可以有多个同名方法，它们具有不同的参数列表（参数类型、参数个数或参数顺序不同），编译器根据调用时的参数类型来决定调用哪个方法。\n重写（Overriding）指的是子类可以重新定义父类中的方法，方法名、参数列表和返回类型必须与父类中的方法一致，通过@override注解来明确表示这是对父类方法的重写。\n\n重载是指在同一个类中定义多个同名方法，而重写是指子类重新定义父类中的方法。\n# 抽象类和普通类区别？\n实例化：普通类可以直接实例化对象，而抽象类不能被实例化，只能被继承。\n方法实现：普通类中的方法可以有具体的实现，而抽象类中的方法可以有实现也可以没有实现。\n继承：一个类可以继承一个普通类，而且可以继承多个接口；而一个类只能继承一个抽象类，但可以同时实现多个接口。\n实现限制：普通类可以被其他类继承和使用，而抽象类一般用于作为基类，被其他类继承和扩展使用。\n\n# Java抽象类和接口的区别是什么？两者的特点：\n\n抽象类用于描述类的共同特性和行为，可以有成员变量、构造方法和具体方法。适用于有明显继承关系的场景。\n接口用于定义行为规范，可以多实现，只能有常量和抽象方法（Java 8 以后可以有默认方法和静态方法）。适用于定义类的能力或功能。\n\n两者的区别：\n\n实现方式：实现接口的关键字为implements，继承抽象类的关键字为extends。一个类可以实现多个接口，但一个类只能继承一个抽象类。所以，使用接口可以间接地实现多重继承。\n方法方式：接口只有定义，不能有方法的实现，java 1.8中可以定义default方法体，而抽象类可以有定义与实现，方法可在抽象类中实现。\n访问修饰符：接口成员变量默认为public static final，必须赋初值，不能被修改；其所有的成员方法都是public、abstract的。抽象类中成员变量默认default，可在子类中被重新定义，也可被重新赋值；抽象方法被abstract修饰，不能被private、static、synchronized和native等修饰，必须以分号结尾，不带花括号。\n变量：抽象类可以包含实例变量和静态变量，而接口只能包含常量（即静态常量）。\n\n# 抽象类能加final修饰吗？不能，Java中的抽象类是用来被继承的，而final修饰符用于禁止类被继承或方法被重写，因此，抽象类和final修饰符是互斥的，不能同时使用。\n# 接口里面可以定义哪些方法？\n抽象方法\n\n抽象方法是接口的核心部分，所有实现接口的类都必须实现这些方法。抽象方法默认是 public 和 abstract，这些修饰符可以省略。\n123public interface Animal &#123;    void makeSound();&#125;\n\n\n默认方法\n\n默认方法是在 Java 8 中引入的，允许接口提供具体实现。实现类可以选择重写默认方法。\n1234567public interface Animal &#123;    void makeSound();        default void sleep() &#123;        System.out.println(&quot;Sleeping...&quot;);    &#125;&#125;\n\n\n静态方法\n\n静态方法也是在 Java 8 中引入的，它们属于接口本身，可以通过接口名直接调用，而不需要实现类的对象。\n1234567public interface Animal &#123;    void makeSound();        static void staticMethod() &#123;        System.out.println(&quot;Static method in interface&quot;);    &#125;&#125;\n\n\n私有方法\n\n私有方法是在 Java 9 中引入的，用于在接口中为默认方法或其他私有方法提供辅助功能。这些方法不能被实现类访问，只能在接口内部使用。\n123456789101112public interface Animal &#123;    void makeSound();        default void sleep() &#123;        System.out.println(&quot;Sleeping...&quot;);        logSleep();    &#125;        private void logSleep() &#123;        System.out.println(&quot;Logging sleep&quot;);    &#125;&#125;\n\n123public interface Animal &#123;    void makeSound();&#125;\n\n# 抽象类可以被实例化吗？在Java中，抽象类本身不能被实例化。\n这意味着不能使用new关键字直接创建一个抽象类的对象。抽象类的存在主要是为了被继承，它通常包含一个或多个抽象方法（由abstract关键字修饰且无方法体的方法），这些方法需要在子类中被实现。\n抽象类可以有构造器，这些构造器在子类实例化时会被调用，以便进行必要的初始化工作。然而，这个过程并不是直接实例化抽象类，而是创建了子类的实例，间接地使用了抽象类的构造器。\n例如：\n123456789101112131415161718192021public abstract class AbstractClass &#123;    public AbstractClass() &#123;        // 构造器代码    &#125;        public abstract void abstractMethod();&#125;public class ConcreteClass extends AbstractClass &#123;    public ConcreteClass() &#123;        super(); // 调用抽象类的构造器    &#125;        @Override    public void abstractMethod() &#123;        // 实现抽象方法    &#125;&#125;// 下面的代码可以运行ConcreteClass obj = new ConcreteClass();\n\n在这个例子中，ConcreteClass继承了AbstractClass并实现了抽象方法abstractMethod()。当我们创建ConcreteClass的实例时，AbstractClass的构造器被调用，但这并不意味着AbstractClass被实例化；实际上，我们创建的是ConcreteClass的一个对象。\n简而言之，抽象类不能直接实例化，但通过继承抽象类并实现所有抽象方法的子类是可以被实例化的。\n# 接口可以包含构造函数吗？在接口中，不可以有构造方法,在接口里写入构造方法时，编译器提示：Interfaces cannot have constructors，因为接口不会有自己的实例的，所以不需要有构造函数。\n为什么呢？构造函数就是初始化class的属性或者方法，在new的一瞬间自动调用，那么问题来了Java的接口，都不能new 那么要构造函数干嘛呢？根本就没法调用\n# 解释Java中的静态变量和静态方法在Java中，静态变量和静态方法是与类本身关联的，而不是与类的实例（对象）关联。它们在内存中只存在一份，可以被类的所有实例共享。\n\n\n\n\n\n\n\n\n\n静态变量\n静态变量（也称为类变量）是在类中使用static关键字声明的变量。它们属于类而不是任何具体的对象。主要的特点：\n\n共享性：所有该类的实例共享同一个静态变量。如果一个实例修改了静态变量的值，其他实例也会看到这个更改。\n初始化：静态变量在类被加载时初始化，只会对其进行一次分配内存。\n访问方式：静态变量可以直接通过类名访问，也可以通过实例访问，但推荐使用类名。\n\n示例：\n12345678910111213141516public class MyClass &#123;    static int staticVar = 0; // 静态变量    public MyClass() &#123;        staticVar++; // 每创建一个对象，静态变量自增    &#125;        public static void printStaticVar() &#123;        System.out.println(&quot;Static Var: &quot; + staticVar);    &#125;&#125;// 使用示例MyClass obj1 = new MyClass();MyClass obj2 = new MyClass();MyClass.printStaticVar(); // 输出 Static Var: 2\n\n\n\n\n\n\n\n\n\n\n静态方法\n静态方法是在类中使用static关键字声明的方法。类似于静态变量，静态方法也属于类，而不是任何具体的对象。主要的特点：\n\n无实例依赖：静态方法可以在没有创建类实例的情况下调用。对于静态方法来说，不能直接访问非静态的成员变量或方法，因为静态方法没有上下文的实例。\n访问静态成员：静态方法可以直接调用其他静态变量和静态方法，但不能直接访问非静态成员。\n多态性：静态方法不支持重写（Override），但可以被隐藏（Hide）。\n\n12345678910111213141516public class MyClass &#123;    static int count = 0;    // 静态方法    public static void incrementCount() &#123;        count++;    &#125;    public static void displayCount() &#123;        System.out.println(&quot;Count: &quot; + count);    &#125;&#125;// 使用示例MyClass.incrementCount(); // 调用静态方法MyClass.displayCount();   // 输出 Count: 1\n\n\n\n\n\n\n\n\n\n\n使用场景\n\n静态变量：常用于需要在所有对象间共享的数据，如计数器、常量等。\n静态方法：常用于助手方法（utility methods）、获取类级别的信息或者是没有依赖于实例的数据处理。\n\n# 非静态内部类和静态内部类的区别？区别包括：\n\n非静态内部类依赖于外部类的实例，而静态内部类不依赖于外部类的实例。\n非静态内部类可以访问外部类的实例变量和方法，而静态内部类只能访问外部类的静态成员。\n非静态内部类不能定义静态成员，而静态内部类可以定义静态成员。\n非静态内部类在外部类实例化后才能实例化，而静态内部类可以独立实例化。\n非静态内部类可以访问外部类的私有成员，而静态内部类不能直接访问外部类的私有成员，需要通过实例化外部类来访问。\n\n# 非静态内部类可以直接访问外部方法，编译器是怎么做到的？非静态内部类可以直接访问外部方法是因为编译器在生成字节码时会为非静态内部类维护一个指向外部类实例的引用。\n这个引用使得非静态内部类能够访问外部类的实例变量和方法。编译器会在生成非静态内部类的构造方法时，将外部类实例作为参数传入，并在内部类的实例化过程中建立外部类实例与内部类实例之间的联系，从而实现直接访问外部方法的功能。\n# 有一个父类和子类，都有静态的成员变量、静态构造方法和静态方法，在我new一个子类对象的时候，加载顺序是怎么样的？当你实例化一个子类对象时，静态成员变量、静态构造方法和静态方法的加载顺序遵循以下步骤：\n\n在创建子类对象之前，首先会加载父类的静态成员变量和静态代码块（构造方法无法被 static 修饰，因此这里是静态代码块）。这个加载是在类首次被加载时进行的，且只会发生一次。\n接下来，加载子类的静态成员变量和静态代码块。这一过程也只发生一次，即当首次使用子类的相关代码时。\n之后，执行实例化子类对象的过程。这时会呼叫父类构造方法，然后是子类的构造方法。\n\n具体加载顺序可以简要总结为：\n\n父类静态成员变量、静态代码块（如果有）\n子类静态成员变量、静态代码块（如果有）\n父类构造方法（实例化对象时）\n子类构造方法（实例化对象时）\n\n示例代码\n123456789101112131415161718192021222324252627class Parent &#123;    static &#123;        System.out.println(&quot;Parent static block&quot;);    &#125;    static int parentStaticVar = 10;    Parent() &#123;        System.out.println(&quot;Parent constructor&quot;);    &#125;&#125;class Child extends Parent &#123;    static &#123;        System.out.println(&quot;Child static block&quot;);    &#125;    static int childStaticVar = 20;    Child() &#123;        System.out.println(&quot;Child constructor&quot;);    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        Child c = new Child();    &#125;&#125;\n\n输出结果\n1234Parent static blockChild static blockParent constructorChild constructor\n\n从输出可以看出，在创建 Child 类型对象时，首先执行父类的静态块，然后是子类的静态块，最后才是父类和子类的构造函数。这清晰地展示了加载的顺序。\n# 深拷贝和浅拷贝# 深拷贝和浅拷贝的区别？\n\n浅拷贝是指只复制对象本身和其内部的值类型字段，但不会复制对象内部的引用类型字段。换句话说，浅拷贝只是创建一个新的对象，然后将原对象的字段值复制到新对象中，但如果原对象内部有引用类型的字段，只是将引用复制到新对象中，两个对象指向的是同一个引用对象。\n深拷贝是指在复制对象的同时，将对象内部的所有引用类型字段的内容也复制一份，而不是共享引用。换句话说，深拷贝会递归复制对象内部所有引用类型的字段，生成一个全新的对象以及其内部的所有对象。\n\n# 实现深拷贝的三种方法是什么？在 Java 中，实现对象深拷贝的方法有以下几种主要方式：\n\n\n\n\n\n\n\n\n\n实现 Cloneable 接口并重写 clone() 方法\n这种方法要求对象及其所有引用类型字段都实现 Cloneable 接口，并且重写 clone() 方法。在 clone() 方法中，通过递归克隆引用类型字段来实现深拷贝。\n1234567891011121314151617181920class MyClass implements Cloneable &#123;    private String field1;    private NestedClass nestedObject;    @Override    protected Object clone() throws CloneNotSupportedException &#123;        MyClass cloned = (MyClass) super.clone();        cloned.nestedObject = (NestedClass) nestedObject.clone(); // 深拷贝内部的引用对象        return cloned;    &#125;&#125;class NestedClass implements Cloneable &#123;    private int nestedField;    @Override    protected Object clone() throws CloneNotSupportedException &#123;        return super.clone();    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n使用序列化和反序列化\n通过将对象序列化为字节流，再从字节流反序列化为对象来实现深拷贝。要求对象及其所有引用类型字段都实现 Serializable 接口。\n123456789101112131415161718192021222324252627import java.io.*;class MyClass implements Serializable &#123;    private String field1;    private NestedClass nestedObject;    public MyClass deepCopy() &#123;        try &#123;            ByteArrayOutputStream bos = new ByteArrayOutputStream();            ObjectOutputStream oos = new ObjectOutputStream(bos);            oos.writeObject(this);            oos.flush();            oos.close();            ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray());            ObjectInputStream ois = new ObjectInputStream(bis);            return (MyClass) ois.readObject();        &#125; catch (IOException | ClassNotFoundException e) &#123;            e.printStackTrace();            return null;        &#125;    &#125;&#125;class NestedClass implements Serializable &#123;    private int nestedField;&#125;\n\n\n\n\n\n\n\n\n\n\n手动递归复制\n针对特定对象结构，手动递归复制对象及其引用类型字段。适用于对象结构复杂度不高的情况。\n123456789101112131415161718192021class MyClass &#123;    private String field1;    private NestedClass nestedObject;    public MyClass deepCopy() &#123;        MyClass copy = new MyClass();        copy.setField1(this.field1);        copy.setNestedObject(this.nestedObject.deepCopy());        return copy;    &#125;&#125;class NestedClass &#123;    private int nestedField;    public NestedClass deepCopy() &#123;        NestedClass copy = new NestedClass();        copy.setNestedField(this.nestedField);        return copy;    &#125;&#125;\n\n# 泛型# 什么是泛型？泛型是 Java 编程语言中的一个重要特性，它允许类、接口和方法在定义时使用一个或多个类型参数，这些类型参数在使用时可以被指定为具体的类型。\n泛型的主要目的是在编译时提供更强的类型检查，并且在编译后能够保留类型信息，避免了在运行时出现类型转换异常。\n\n\n\n\n\n\n\n\n\n为什么需要泛型？\n\n适用于多种数据类型执行相同的代码\n\n1234567891011121314private static int add(int a, int b) &#123;    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));    return a + b;&#125;private static float add(float a, float b) &#123;    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));    return a + b;&#125;private static double add(double a, double b) &#123;    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));    return a + b;&#125;\n\n如果没有泛型，要实现不同类型的加法，每种类型都需要重载一个add方法；通过泛型，我们可以复用为一个方法：\n1234private static &lt;T extends Number&gt; double add(T a, T b) &#123;    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a.doubleValue() + b.doubleValue()));    return a.doubleValue() + b.doubleValue();&#125;\n\n\n泛型中的类型在使用时指定，不需要强制类型转换（类型安全，编译器会检查类型）\n\n看下这个例子：\n1234List list = new ArrayList();list.add(&quot;xxString&quot;);list.add(100d);list.add(new Person());\n\n我们在使用上述list中，list中的元素都是Object类型（无法约束其中的类型），所以在取出集合元素时需要人为的强制类型转化到具体的目标类型，且很容易出现java.lang.ClassCastException异常。\n引入泛型，它将提供类型的约束，提供编译前的检查：\n123List&lt;String&gt; list = new ArrayList&lt;String&gt;();// list中只能放String, 不能放其它类型的元素\n\n# 对象# java创建对象有哪些方式？在Java中，创建对象的方式有多种，常见的包括：\n使用new关键字：通过new关键字直接调用类的构造方法来创建对象。\n1MyClass obj = new MyClass();\n\n使用Class类的newInstance()方法：通过反射机制，可以使用Class类的newInstance()方法创建对象。\n1MyClass obj = (MyClass) Class.forName(&quot;com.example.MyClass&quot;).newInstance();\n\n使用Constructor类的newInstance()方法：同样是通过反射机制，可以使用Constructor类的newInstance()方法创建对象。\n12Constructor&lt;MyClass&gt; constructor = MyClass.class.getConstructor();MyClass obj = constructor.newInstance();\n\n使用clone()方法：如果类实现了Cloneable接口，可以使用clone()方法复制对象。\n12MyClass obj1 = new MyClass();MyClass obj2 = (MyClass) obj1.clone();\n\n使用反序列化：通过将对象序列化到文件或流中，然后再进行反序列化来创建对象。\n123456789// SerializedObject.javaObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(&quot;object.ser&quot;));out.writeObject(obj);out.close();// DeserializedObject.javaObjectInputStream in = new ObjectInputStream(new FileInputStream(&quot;object.ser&quot;));MyClass obj = (MyClass) in.readObject();in.close();\n\n# Java创建对象除了new还有别的什么方式?\n通过反射创建对象：通过 Java 的反射机制可以在运行时动态地创建对象。可以使用 Class 类的 newInstance() 方法或者通过 Constructor 类来创建对象。\n\n123456789101112public class MyClass &#123;    public MyClass() &#123;        // Constructor    &#125;&#125;public class Main &#123;    public static void main(String[] args) throws Exception &#123;        Class&lt;?&gt; clazz = MyClass.class;        MyClass obj = (MyClass) clazz.newInstance();    &#125;&#125;\n\n\n通过反序列化创建对象：通过将对象序列化（保存到文件或网络传输）然后再反序列化（从文件或网络传输中读取对象）的方式来创建对象，对象能被序列化和反序列化的前提是类实现Serializable接口。\n\n1234567891011121314151617181920import java.io.*;public class MyClass implements Serializable &#123;    // Class definition&#125;public class Main &#123;    public static void main(String[] args) throws Exception &#123;        // Serialize object        MyClass obj = new MyClass();        ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(&quot;object.ser&quot;));        out.writeObject(obj);        out.close();                // Deserialize object        ObjectInputStream in = new ObjectInputStream(new FileInputStream(&quot;object.ser&quot;));        MyClass newObj = (MyClass) in.readObject();        in.close();    &#125;&#125;\n\n\n通过clone创建对象：所有 Java 对象都继承自 Object 类，Object 类中有一个 clone() 方法，可以用来创建对象的副本，要使用 clone 方法，我们必须先实现 Cloneable 接口并实现其定义的 clone 方法。\n\n12345678910111213public class MyClass implements Cloneable &#123;    @Override    public Object clone() throws CloneNotSupportedException &#123;        return super.clone();    &#125;&#125;public class Main &#123;    public static void main(String[] args) throws CloneNotSupportedException &#123;        MyClass obj1 = new MyClass();        MyClass obj2 = (MyClass) obj1.clone();    &#125;&#125;\n\n# New出的对象什么时候回收？通过过关键字new创建的对象，由Java的垃圾回收器（Garbage Collector）负责回收。垃圾回收器的工作是在程序运行过程中自动进行的，它会周期性地检测不再被引用的对象，并将其回收释放内存。\n具体来说，Java对象的回收时机是由垃圾回收器根据一些算法来决定的，主要有以下几种情况：\n\n引用计数法：某个对象的引用计数为0时，表示该对象不再被引用，可以被回收。\n可达性分析算法：从根对象（如方法区中的类静态属性、方法中的局部变量等）出发，通过对象之间的引用链进行遍历，如果存在一条引用链到达某个对象，则说明该对象是可达的，反之不可达，不可达的对象将被回收。\n终结器（Finalizer）：如果对象重写了finalize()方法，垃圾回收器会在回收该对象之前调用finalize()方法，对象可以在finalize()方法中进行一些清理操作。然而，终结器机制的使用不被推荐，因为它的执行时间是不确定的，可能会导致不可预测的性能问题。\n\n# 反射# 什么是反射？Java 反射机制是在运行状态中，对于任意一个类，都能够知道这个类中的所有属性和方法，对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 Java 语言的反射机制。\n反射具有以下特性：\n\n运行时类信息访问：反射机制允许程序在运行时获取类的完整结构信息，包括类名、包名、父类、实现的接口、构造函数、方法和字段等。\n动态对象创建：可以使用反射API动态地创建对象实例，即使在编译时不知道具体的类名。这是通过Class类的newInstance()方法或Constructor对象的newInstance()方法实现的。\n动态方法调用：可以在运行时动态地调用对象的方法，包括私有方法。这通过Method类的invoke()方法实现，允许你传入对象实例和参数值来执行方法。\n访问和修改字段值：反射还允许程序在运行时访问和修改对象的字段值，即使是私有的。这是通过Field类的get()和set()方法完成的。\n\n\n# 反射在你平时写代码或者框架中的应用场景有哪些?\n\n\n\n\n\n\n\n\n加载数据库驱动\n我们的项目底层数据库有时是用mysql，有时用oracle，需要动态地根据实际情况加载驱动类，这个时候反射就有用了，假设 com.mikechen.java.myqlConnection，com.mikechen.java.oracleConnection这两个类我们要用。\n这时候我们在使用 JDBC 连接数据库时使用 Class.forName()通过反射加载数据库的驱动程序，如果是mysql则传入mysql的驱动类，而如果是oracle则传入的参数就变成另一个了。\n12//  DriverManager.registerDriver(new com.mysql.cj.jdbc.Driver());Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;);\n\n\n\n\n\n\n\n\n\n\n配置文件加载\nSpring 框架的 IOC（动态加载管理 Bean），Spring通过配置文件配置各种各样的bean，你需要用到哪些bean就配哪些，spring容器就会根据你的需求去动态加载，你的程序就能健壮地运行。\nSpring通过XML配置模式装载Bean的过程：\n\n将程序中所有XML或properties配置文件加载入内存\nJava类里面解析xml或者properties里面的内容，得到对应实体类的字节码字符串以及相关的属性信息\n使用反射机制，根据这个字符串获得某个类的Class实例\n动态配置实例的属性\n\n配置文件\n12className=com.example.reflectdemo.TestInvokemethodName=printlnState\n\n实体类\n12345public class TestInvoke &#123;    private void printlnState()&#123;        System.out.println(&quot;I am fine&quot;);    &#125;&#125;\n\n解析配置文件内容\n12345678// 解析xml或properties里面的内容，得到对应实体类的字节码字符串以及属性信息public static String getName(String key) throws IOException &#123;    Properties properties = new Properties();    FileInputStream in = new FileInputStream(&quot;D:\\IdeaProjects\\AllDemos\\language-specification\\src\\main\\resources\\application.properties&quot;);    properties.load(in);    in.close();    return properties.getProperty(key);&#125;\n\n利用反射获取实体类的Class实例，创建实体类的实例对象，调用方法\n1234567891011121314public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException, IOException, ClassNotFoundException, InstantiationException &#123;    // 使用反射机制，根据这个字符串获得Class对象    Class&lt;?&gt; c = Class.forName(getName(&quot;className&quot;));    System.out.println(c.getSimpleName());    // 获取方法    Method method = c.getDeclaredMethod(getName(&quot;methodName&quot;));    // 绕过安全检查    method.setAccessible(true);    // 创建实例对象    TestInvoke testInvoke = (TestInvoke)c.newInstance();    // 调用方法    method.invoke(testInvoke);&#125;\n\n运行结果：\n\n# 注解# 能讲一讲Java注解的原理吗？注解本质是一个继承了Annotation的特殊接口，其具体实现类是Java运行时生成的动态代理类。\n我们通过反射获取注解时，返回的是Java运行时生成的动态代理对象。通过代理对象调用自定义注解的方法，会最终调用AnnotationInvocationHandler的invoke方法。该方法会从memberValues这个Map中索引出对应的值。而memberValues的来源是Java常量池。\n# Java注解的作用域呢？注解的作用域（Scope）指的是注解可以应用在哪些程序元素上，例如类、方法、字段等。Java注解的作用域可以分为三种：\n\n类级别作用域：用于描述类的注解，通常放置在类定义的上面，可以用来指定类的一些属性，如类的访问级别、继承关系、注释等。\n方法级别作用域：用于描述方法的注解，通常放置在方法定义的上面，可以用来指定方法的一些属性，如方法的访问级别、返回值类型、异常类型、注释等。\n字段级别作用域：用于描述字段的注解，通常放置在字段定义的上面，可以用来指定字段的一些属性，如字段的访问级别、默认值、注释等。\n\n除了这三种作用域，Java还提供了其他一些注解作用域，例如构造函数作用域和局部变量作用域。这些注解作用域可以用来对构造函数和局部变量进行描述和注释。\n# 异常# 介绍一下Java异常Java异常类层次结构图：Java的异常体系主要基于两大类：Throwable类及其子类。Throwable有两个重要的子类：Error和Exception，它们分别代表了不同类型的异常情况。\n\nError（错误）：表示运行时环境的错误。错误是程序无法处理的严重问题，如系统崩溃、虚拟机错误、动态链接失败等。通常，程序不应该尝试捕获这类错误。例如，OutOfMemoryError、StackOverflowError等。\n\nException（异常）：表示程序本身可以处理的异常条件。异常分为两大类：\n\n非运行时异常：这类异常在编译时期就必须被捕获或者声明抛出。它们通常是外部错误，如文件不存在（FileNotFoundException）、类未找到（ClassNotFoundException）等。非运行时异常强制程序员处理这些可能出现的问题，增强了程序的健壮性。\n\n运行时异常：这类异常包括运行时异常（RuntimeException）和错误（Error）。运行时异常由程序错误导致，如空指针访问（NullPointerException）、数组越界（ArrayIndexOutOfBoundsException）等。运行时异常是不需要在编译时强制捕获或声明的。\n\n\n\n\n# Java异常处理有哪些？异常处理是通过使用try-catch语句块来捕获和处理异常。以下是Java中常用的异常处理方式：\n\ntry-catch语句块：用于捕获并处理可能抛出的异常。try块中包含可能抛出异常的代码，catch块用于捕获并处理特定类型的异常。可以有多个catch块来处理不同类型的异常。\n\n1234567891011try &#123;    // 可能抛出异常的代码&#125; catch (ExceptionType1 e1) &#123;    // 处理异常类型1的逻辑&#125; catch (ExceptionType2 e2) &#123;    // 处理异常类型2的逻辑&#125; catch (ExceptionType3 e3) &#123;    // 处理异常类型3的逻辑&#125; finally &#123;    // 可选的finally块，用于定义无论是否发生异常都会执行的代码&#125;\n\n\nthrow语句：用于手动抛出异常。可以根据需要在代码中使用throw语句主动抛出特定类型的异常。\n\n1throw new ExceptionType(&quot;Exception message&quot;);\n\n\nthrows关键字：用于在方法声明中声明可能抛出的异常类型。如果一个方法可能抛出异常，但不想在方法内部进行处理，可以使用throws关键字将异常传递给调用者来处理。\n\n123public void methodName() throws ExceptionType &#123;    // 方法体&#125;\n\n\nfinally块：用于定义无论是否发生异常都会执行的代码块。通常用于释放资源，确保资源的正确关闭。\n\n1234567try &#123;    // 可能抛出异常的代码&#125; catch (ExceptionType e) &#123;    // 处理异常的逻辑&#125; finally &#123;    // 无论是否发生异常，都会执行的代码&#125;\n\n# 抛出异常为什么不用throws？如果异常是未检查异常或者在方法内部被捕获和处理了，那么就不需要使用throws。\n\nUnchecked Exceptions：未检查异常（unchecked exceptions）是继承自RuntimeException类或Error类的异常，编译器不强制要求进行异常处理。因此，对于这些异常，不需要在方法签名中使用throws来声明。示例包括NullPointerException、ArrayIndexOutOfBoundsException等。\n捕获和处理异常：另一种常见情况是，在方法内部捕获了可能抛出的异常，并在方法内部处理它们，而不是通过throws子句将它们传递到调用者。这种情况下，方法可以处理异常而无需在方法签名中使用throws。\n\n# try catch中的语句运行情况try块中的代码将按顺序执行，如果抛出异常，将在catch块中进行匹配和处理，然后程序将继续执行catch块之后的代码。如果没有匹配的catch块，异常将被传递给上一层调用的方法。\n# try{return “a”} fianlly{return “b”}这条语句返回啥finally块中的return语句会覆盖try块中的return返回，因此，该语句将返回”b”。\n# object# &#x3D;&#x3D; 与 equals 有什么区别？对于字符串变量来说，使用”&#x3D;&#x3D;”和”equals”比较字符串时，其比较方法不同。”&#x3D;&#x3D;”比较两个变量本身的值，即两个对象在内存中的首地址，”equals”比较字符串包含内容是否相同。\n对于非字符串变量来说，如果没有对equals()进行重写的话，”&#x3D;&#x3D;” 和 “equals”方法的作用是相同的，都是用来比较对象在堆内存中的首地址，即用来比较两个引用变量是否指向同一个对象。\n\n=&#x3D;：比较的是两个字符串内存地址（堆内存）的数值是否相等，属于数值比较；\nequals()：比较的是两个字符串的内容，属于内容比较。\n\n# StringBuffer和StringBuild区别是什么？区别：\n\nString 是 Java 中基础且重要的类，被声明为 final class，是不可变字符串。因为它的不可变性，所以拼接字符串时候会产生很多无用的中间对象，如果频繁的进行这样的操作对性能有所影响。\nStringBuffer 就是为了解决大量拼接字符串时产生很多中间对象问题而提供的一个类。它提供了 append 和 add 方法，可以将字符串添加到已有序列的末尾或指定位置，它的本质是一个线程安全的可修改的字符序列。在很多情况下我们的字符串拼接操作不需要线程安全，所以 StringBuilder 登场了。\nStringBuilder 是 JDK1.5 发布的，它和 StringBuffer 本质上没什么区别，就是去掉了保证线程安全的那部分，减少了开销。\n\n线程安全：\n\nStringBuffer：线程安全\nStringBuilder：线程不安全\n\n速度：\n\n一般情况下，速度从快到慢为 StringBuilder &gt; StringBuffer &gt; String，当然这是相对的，不是绝对的。\n\n使用场景：\n\n操作少量的数据使用 String。\n单线程操作大量数据使用 StringBuilder。\n多线程操作大量数据使用 StringBuffer。\n\n\n# Java 1.8 新特性# Java中stream的API介绍一下Java 8引入了Stream API，它提供了一种高效且易于使用的数据处理方式，特别适合集合对象的操作，如过滤、映射、排序等。Stream API不仅可以提高代码的可读性和简洁性，还能利用多核处理器的优势进行并行处理。让我们通过两个具体的例子来感受下Java Stream API带来的便利，对比在Stream API引入之前的传统做法。\n\n\n\n\n\n\n\n\n\n案例1：过滤并收集满足条件的元素\n问题场景：从一个列表中筛选出所有长度大于3的字符串，并收集到一个新的列表中。\n没有Stream API的做法：\n12345678List&lt;String&gt; originalList = Arrays.asList(&quot;apple&quot;, &quot;fig&quot;, &quot;banana&quot;, &quot;kiwi&quot;);List&lt;String&gt; filteredList = new ArrayList&lt;&gt;();for (String item : originalList) &#123;    if (item.length() &gt; 3) &#123;        filteredList.add(item);    &#125;&#125;\n\n这段代码需要显式地创建一个新的ArrayList，并通过循环遍历原列表，手动检查每个元素是否满足条件，然后添加到新列表中。\n使用Stream API的做法：\n1234List&lt;String&gt; originalList = Arrays.asList(&quot;apple&quot;, &quot;fig&quot;, &quot;banana&quot;, &quot;kiwi&quot;);List&lt;String&gt; filteredList = originalList.stream()                                        .filter(s -&gt; s.length() &gt; 3)                                        .collect(Collectors.toList());\n\n这里，我们直接在原始列表上调用.stream()方法创建了一个流，使用.filter()中间操作筛选出长度大于3的字符串，最后使用.collect(Collectors.toList())终端操作将结果收集到一个新的列表中。代码更加简洁明了，逻辑一目了然。\n\n\n\n\n\n\n\n\n\n案例2：计算列表中所有数字的总和\n问题场景：计算一个数字列表中所有元素的总和。\n没有Stream API的做法：\n12345List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);int sum = 0;for (Integer number : numbers) &#123;    sum += number;&#125;\n\n这个传统的for-each循环遍历列表中的每一个元素，累加它们的值来计算总和。\n使用Stream API的做法：\n1234List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);int sum = numbers.stream()                 .mapToInt(Integer::intValue)                 .sum();\n\n通过Stream API，我们可以先使用.mapToInt()将Integer流转换为IntStream（这是为了高效处理基本类型），然后直接调用.sum()方法来计算总和，极大地简化了代码。\n# Stream流的并行API是什么？是 ParallelStream。\n并行流（ParallelStream）就是将源数据分为多个子流对象进行多线程操作，然后将处理的结果再汇总为一个流对象，底层是使用通用的 fork&#x2F;join 池来实现，即将一个任务拆分成多个“小任务”并行计算，再把多个“小任务”的结果合并成总的计算结果\nStream串行流与并行流的主要区别：\n\n对CPU密集型的任务来说，并行流使用ForkJoinPool线程池，为每个CPU分配一个任务，这是非常有效率的，但是如果任务不是CPU密集的，而是I&#x2F;O密集的，并且任务数相对线程数比较大，那么直接用ParallelStream并不是很好的选择。\n# completableFuture怎么用的？CompletableFuture是由Java 8引入的，在Java8之前我们一般通过Future实现异步。\n\nFuture用于表示异步计算的结果，只能通过阻塞或者轮询的方式获取结果，而且不支持设置回调方法，Java 8之前若要设置回调一般会使用guava的ListenableFuture，回调的引入又会导致臭名昭著的回调地狱（下面的例子会通过ListenableFuture的使用来具体进行展示）。\nCompletableFuture对Future进行了扩展，可以通过设置回调的方式处理计算结果，同时也支持组合操作，支持进一步的编排，同时一定程度解决了回调地狱的问题。\n\n下面将举例来说明，我们通过ListenableFuture、CompletableFuture来实现异步的差异。假设有三个操作step1、step2、step3存在依赖关系，其中step3的执行依赖step1和step2的结果。\nFuture(ListenableFuture)的实现（回调地狱）如下：\n1234567891011121314151617181920212223242526272829303132333435ExecutorService executor = Executors.newFixedThreadPool(5);ListeningExecutorService guavaExecutor = MoreExecutors.listeningDecorator(executor);ListenableFuture&lt;String&gt; future1 = guavaExecutor.submit(() -&gt; &#123;    //step 1    System.out.println(&quot;执行step 1&quot;);    return &quot;step1 result&quot;;&#125;);ListenableFuture&lt;String&gt; future2 = guavaExecutor.submit(() -&gt; &#123;    //step 2    System.out.println(&quot;执行step 2&quot;);    return &quot;step2 result&quot;;&#125;);ListenableFuture&lt;List&lt;String&gt;&gt; future1And2 = Futures.allAsList(future1, future2);Futures.addCallback(future1And2, new FutureCallback&lt;List&lt;String&gt;&gt;() &#123;    @Override    public void onSuccess(List&lt;String&gt; result) &#123;        System.out.println(result);        ListenableFuture&lt;String&gt; future3 = guavaExecutor.submit(() -&gt; &#123;            System.out.println(&quot;执行step 3&quot;);            return &quot;step3 result&quot;;        &#125;);        Futures.addCallback(future3, new FutureCallback&lt;String&gt;() &#123;            @Override            public void onSuccess(String result) &#123;                System.out.println(result);            &#125;                    @Override            public void onFailure(Throwable t) &#123;            &#125;        &#125;, guavaExecutor);    &#125;    @Override    public void onFailure(Throwable t) &#123;    &#125;&#125;, guavaExecutor);\n\nCompletableFuture的实现如下：\n1234567891011121314ExecutorService executor = Executors.newFixedThreadPool(5);CompletableFuture&lt;String&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;    System.out.println(&quot;执行step 1&quot;);    return &quot;step1 result&quot;;&#125;, executor);CompletableFuture&lt;String&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;    System.out.println(&quot;执行step 2&quot;);    return &quot;step2 result&quot;;&#125;);cf1.thenCombine(cf2, (result1, result2) -&gt; &#123;    System.out.println(result1 + &quot; , &quot; + result2);    System.out.println(&quot;执行step 3&quot;);    return &quot;step3 result&quot;;&#125;).thenAccept(result3 -&gt; System.out.println(result3));\n\n显然，CompletableFuture的实现更为简洁，可读性更好。\n CompletableFuture实现了两个接口（如上图所示)：Future、CompletionStage。\n\nFuture表示异步计算的结果，CompletionStage用于表示异步执行过程中的一个步骤（Stage），这个步骤可能是由另外一个CompletionStage触发的，随着当前步骤的完成，也可能会触发其他一系列CompletionStage的执行。\n从而我们可以根据实际业务对这些步骤进行多样化的编排组合，CompletionStage接口正是定义了这样的能力，我们可以通过其提供的thenAppy、thenCompose等函数式编程方法来组合编排这些步骤。\n\n# 序列化# 怎么把一个对象从一个jvm转移到另一个jvm?\n使用序列化和反序列化：将对象序列化为字节流，并将其发送到另一个 JVM，然后在另一个 JVM 中反序列化字节流恢复对象。这可以通过 Java 的 ObjectOutputStream 和 ObjectInputStream 来实现。\n使用消息传递机制：利用消息传递机制，比如使用消息队列（如 RabbitMQ、Kafka）或者通过网络套接字进行通信，将对象从一个 JVM 发送到另一个。这需要自定义协议来序列化对象并在另一个 JVM 中反序列化。\n使用远程方法调用（RPC）：可以使用远程方法调用框架，如 gRPC，来实现对象在不同 JVM 之间的传输。远程方法调用可以让你在分布式系统中调用远程 JVM 上的对象的方法。\n使用共享数据库或缓存：将对象存储在共享数据库（如 MySQL、PostgreSQL）或共享缓存（如 Redis）中，让不同的 JVM 可以访问这些共享数据。这种方法适用于需要共享数据但不需要直接传输对象的场景。\n\n# 序列化和反序列化让你自己实现你会怎么做?Java 默认的序列化虽然实现方便，但却存在安全漏洞、不跨语言以及性能差等缺陷。\n\n无法跨语言： Java 序列化目前只适用基于 Java 语言实现的框架，其它语言大部分都没有使用 Java 的序列化框架，也没有实现 Java 序列化这套协议。因此，如果是两个基于不同语言编写的应用程序相互通信，则无法实现两个应用服务之间传输对象的序列化与反序列化。\n容易被攻击：Java 序列化是不安全的，我们知道对象是通过在 ObjectInputStream 上调用 readObject() 方法进行反序列化的，这个方法其实是一个神奇的构造器，它可以将类路径上几乎所有实现了 Serializable 接口的对象都实例化。这也就意味着，在反序列化字节流的过程中，该方法可以执行任意类型的代码，这是非常危险的。\n序列化后的流太大：序列化后的二进制流大小能体现序列化的性能。序列化后的二进制数组越大，占用的存储空间就越多，存储硬件的成本就越高。如果我们是进行网络传输，则占用的带宽就更多，这时就会影响到系统的吞吐量。\n\n我会考虑用主流序列化框架，比如FastJson、Protobuf来替代Java 序列化。\n如果追求性能的话，Protobuf 序列化框架会比较合适，Protobuf 的这种数据存储格式，不仅压缩存储数据的效果好， 在编码和解码的性能方面也很高效。Protobuf 的编码和解码过程结合.proto 文件格式，加上 Protocol Buffer 独特的编码格式，只需要简单的数据运算以及位移等操作就可以完成编码与解码。可以说 Protobuf 的整体性能非常优秀。\n# 将对象转为二进制字节流具体怎么实现?其实，像序列化和反序列化，无论这些可逆操作是什么机制，都会有对应的处理和解析协议，例如加密和解密，TCP的粘包和拆包，序列化机制是通过序列化协议来进行处理的，和 class 文件类似，它其实是定义了序列化后的字节流格式，然后对此格式进行操作，生成符合格式的字节流或者将字节流解析成对象。\n在Java中通过序列化对象流来完成序列化和反序列化：\n\nObjectOutputStream：通过writeObject(）方法做序列化操作。\nObjectInputStrean：通过readObject()方法做反序列化操作。\n\n只有实现了Serializable或Externalizable接口的类的对象才能被序列化，否则抛出异常！\n实现对象序列化：\n\n让类实现Serializable接口：\n\n12345import java.io.Serializable;public class MyClass implements Serializable &#123;    // class code&#125;\n\n\n创建输出流并写入对象：\n\n12345678910111213import java.io.FileOutputStream;import java.io.ObjectOutputStream;MyClass obj = new MyClass();try &#123;    FileOutputStream fileOut = new FileOutputStream(&quot;object.ser&quot;);    ObjectOutputStream out = new ObjectOutputStream(fileOut);    out.writeObject(obj);    out.close();    fileOut.close();&#125; catch (IOException e) &#123;    e.printStackTrace();&#125;\n\n实现对象反序列化：\n\n创建输入流并读取对象：\n\n12345678910111213import java.io.FileInputStream;import java.io.ObjectInputStream;MyClass newObj = null;try &#123;    FileInputStream fileIn = new FileInputStream(&quot;object.ser&quot;);    ObjectInputStream in = new ObjectInputStream(fileIn);    newObj = (MyClass) in.readObject();    in.close();    fileIn.close();&#125; catch (IOException | ClassNotFoundException e) &#123;    e.printStackTrace();&#125;\n\n通过以上步骤，对象obj会被序列化并写入到文件”object.ser”中，然后通过反序列化操作，从文件中读取字节流并恢复为对象newObj。这种方式可以方便地将对象转换为字节流用于持久化存储、网络传输等操作。需要注意的是，要确保类实现了Serializable接口，并且所有成员变量都是Serializable的才能被正确序列化。\n# 设计模式# volatile和sychronized如何实现单例模式123456789101112131415161718public class SingleTon &#123;    // volatile 关键字修饰变量 防止指令重排序    private static volatile SingleTon instance = null;    private SingleTon()&#123;&#125;         public static  SingleTon getInstance()&#123;        if(instance == null)&#123;            //同步代码块 只有在第一次获取对象的时候会执行到 ，第二次及以后访问时 instance变量均非null故不会往下执行了 直接返回啦            synchronized(SingleTon.class)&#123;                if(instance == null)&#123;                    instance = new SingleTon();                &#125;            &#125;        &#125;        return instance;    &#125;&#125;\n\n正确的双重检查锁定模式需要需要使用 volatile。volatile主要包含两个功能。\n\n保证可见性。使用 volatile 定义的变量，将会保证对所有线程的可见性。\n禁止指令重排序优化。\n\n由于 volatile 禁止对象创建时指令之间重排序，所以其他线程不会访问到一个未初始化的对象，从而保证安全性。\n# 代理模式和适配器模式有什么区别？\n目的不同：代理模式主要关注控制对对象的访问，而适配器模式则用于接口转换，使不兼容的类能够一起工作。\n结构不同：代理模式一般包含抽象主题、真实主题和代理三个角色，适配器模式包含目标接口、适配器和被适配者三个角色。\n应用场景不同：代理模式常用于添加额外功能或控制对对象的访问，适配器模式常用于让不兼容的接口协同工作。\n\n# I&#x2F;O# Java怎么实现网络IO高并发编程？可以用 Java NIO ，是一种同步非阻塞的I&#x2F;O模型，也是I&#x2F;O多路复用的基础。\n传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，函数会一直阻塞，直到收到数据，返回读到的数据， 如果使用BIO要想要并发处理多个客户端的i&#x2F;o，那么会使用多线程模式，一个线程专门处理一个客户端 io，这种模式随着客户端越来越多，所需要创建的线程也越来越多，会急剧消耗系统的性能。\n\nNIO 是基于I&#x2F;O多路复用实现的，它可以只用一个线程处理多个客户端I&#x2F;O，如果你需要同时管理成千上万的连接，但是每个连接只发送少量数据，例如一个聊天服务器，用NIO实现会更好一些。\n\n# BIO、NIO、AIO区别是什么？\nBIO（blocking IO）：就是传统的 java.io 包，它是基于流模型实现的，交互的方式是同步、阻塞方式，也就是说在读入输入流或者输出流时，在读写动作完成之前，线程会一直阻塞在那里，它们之间的调用是可靠的线性顺序。优点是代码比较简单、直观；缺点是 IO 的效率和扩展性很低，容易成为应用性能瓶颈。\nNIO（non-blocking IO） ：Java 1.4 引入的 java.nio 包，提供了 Channel、Selector、Buffer 等新的抽象，可以构建多路复用的、同步非阻塞 IO 程序，同时提供了更接近操作系统底层高性能的数据操作方式。\nAIO（Asynchronous IO） ：是 Java 1.7 之后引入的包，是 NIO 的升级版本，提供了异步非堵塞的 IO 操作方式，所以人们叫它 AIO（Asynchronous IO），异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。\n\n# NIO是怎么实现的？NIO是一种同步非阻塞的IO模型，所以也可以叫NON-BLOCKINGIO。同步是指线程不断轮询IO事件是否就绪，非阻塞是指线程在等待IO的时候，可以同时做其他任务。\n同步的核心就Selector（I&#x2F;O多路复用），Selector代替了线程本身轮询IO事件，避免了阻塞同时减少了不必要的线程消耗；非阻塞的核心就是通道和缓冲区，当IO事件就绪时，可以通过写到缓冲区，保证IO的成功，而无需线程阻塞式地等待。\nNIO由一个专门的线程处理所有IO事件，并负责分发。事件驱动机制，事件到来的时候触发操作，不需要阻塞的监视事件。线程之间通过wait,notify通信，减少线程切换。\nNIO主要有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector。传统IO基于字节流和字符流进行操作，而NIO基于Channel和Buffer(缓冲区)进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。\nSelector(选择区)用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个线程可以监听多个数据通道。\n\n# 你知道有哪个框架用到NIO了吗？Netty。\nNetty 的 I&#x2F;O 模型是基于非阻塞 I&#x2F;O 实现的，底层依赖的是 NIO 框架的多路复用器 Selector。采用 epoll 模式后，只需要一个线程负责 Selector 的轮询。当有数据处于就绪状态后，需要一个事件分发器（Event Dispather），它负责将读写事件分发给对应的读写事件处理器（Event Handler）。事件分发器有两种设计模式：Reactor 和 Proactor，Reactor 采用同步 I&#x2F;O， Proactor 采用异步 I&#x2F;O。\n\nReactor 实现相对简单，适合处理耗时短的场景，对于耗时长的 I&#x2F;O 操作容易造成阻塞。Proactor 性能更高，但是实现逻辑非常复杂，适合图片或视频流分析服务器，目前主流的事件驱动模型还是依赖 select 或 epoll 来实现。\n# 其他# 有一个学生类，想按照分数排序，再按学号排序，应该怎么做？可以使用Comparable接口来实现按照分数排序，再按照学号排序。首先在学生类中实现Comparable接口，并重写compareTo方法，然后在compareTo方法中实现按照分数排序和按照学号排序的逻辑。\n123456789101112131415public class Student implements Comparable&lt;Student&gt; &#123;    private int id;    private int score;    // 构造方法和其他属性、方法省略    @Override    public int compareTo(Student other) &#123;        if (this.score != other.score) &#123;            return Integer.compare(other.score, this.score); // 按照分数降序排序        &#125; else &#123;            return Integer.compare(this.id, other.id); // 如果分数相同，则按照学号升序排序        &#125;    &#125;&#125;\n\n然后在需要对学生列表进行排序的地方，使用Collections.sort()方法对学生列表进行排序即可：\n123List&lt;Student&gt; students = new ArrayList&lt;&gt;();// 添加学生对象到列表中Collections.sort(students);\n\n# Native方法解释一下在Java中，native方法是一种特殊类型的方法，它允许Java代码调用外部的本地代码，即用C、C++或其他语言编写的代码。native关键字是Java语言中的一种声明，用于标记一个方法的实现将在外部定义。\n在Java类中，native方法看起来与其他方法相似，只是其方法体由native关键字代替，没有实际的实现代码。例如：\n123public class NativeExample &#123;    public native void nativeMethod();&#125;\n\n要实现native方法，你需要完成以下步骤：\n\n生成JNI头文件：使用javah工具从你的Java类生成C&#x2F;C++的头文件，这个头文件包含了所有native方法的原型。\n编写本地代码：使用C&#x2F;C++编写本地方法的实现，并确保方法签名与生成的头文件中的原型匹配。\n编译本地代码：将C&#x2F;C++代码编译成动态链接库（DLL，在Windows上），共享库（SO，在Linux上）\n加载本地库：在Java程序中，使用System.loadLibrary()方法来加载你编译好的本地库，这样JVM就能找到并调用native方法的实现了。\n\n\n","slug":"java基础/八股","date":"2024-11-13T04:14:48.000Z","categories_index":"八股","tags_index":"java,java基础,精选","author_index":"Ivan"},{"id":"bc567916c4dc0d8169bd26d18e348d36","title":"test","content":"欢迎使用 Markdown 笔记这是首次使用 Markdown 笔记 自动生成的内容，包含 Markdown 语法和应用介绍\n表格 &amp; 文本样式\n\n\n样式\n语法\n示例\n\n\n\n加粗\n前后 ** 或  __\n加粗1 加粗2\n\n\n斜体\n前后 * 或  _\n斜体1 斜体2\n\n\n删除线\n前后 ~~\n删除线\n\n\n内联代码\n前后 &#96;\ncode\n\n\n下划线\n前 &lt;u&gt;  后 &lt;/u&gt;\n下划线\n\n\n高亮\n前后 ==\n&#x3D;&#x3D;高亮文本&#x3D;&#x3D;\n\n\n引用\n\n\n\n\n\n\n\n\nuTools 新一代效率工具平台\n链接鼠标右击 或 Ctrl 键 + 点击 系统默认浏览器打开链接\nuTools 官网  猿料社区\n图片拖放图片文件、粘贴截图可直接将图片源数据存储到笔记中\n\n图片可拖动为文件到任意窗口使用\n无序列表\n项目\n项目 1\n项目 A\n项目 B\n\n\n项目 2\n\n\n\n有序列表\n项目 1\n项目 A\n项目 B\n\n\n项目 2\n\n任务列表\n A 计划\n A1 计划\n A2 计划\n\n\n B 计划\n\n代码块代码块支持 168 种编程语言\n12345678910111213141516// javascript 冒泡排序function bubbleSort(array) &#123;  let swapped = true;  do &#123;    swapped = false;    for (let j = 0; j &lt; array.length; j++) &#123;      if (array[j] &gt; array[j + 1]) &#123;        let temp = array[j];        array[j] = array[j + 1];        array[j + 1] = temp;        swapped = true;      &#125;    &#125;  &#125; while (swapped);  return array;&#125;\n\nKaTeX 数学公式内联公式质能方程 $E&#x3D;mc^2$\n公式块$$\\displaystyle \\left( \\sum_{k&#x3D;1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k&#x3D;1}^n a_k^2 \\right) \\left( \\sum_{k&#x3D;1}^n b_k^2 \\right)$$\n应用介绍特性\n极佳的 Markdown 编辑体验，实时预览、存储\n与传统富文本编辑方式结合，支持通用快捷键\n导出 MD、html、PDF、图片\n可快速搜索全部笔记(内容和标题)\n笔记名称可设置为 uTools 关键字，外部快速打开笔记\n\n使用技巧\n侧边栏文件夹或笔记，拖拽调整位置，鼠标右击 显示操作菜单\n当焦点未在编辑器，键盘上下方向键、 Tab 键切换笔记\n当焦点未在编辑器，Enter 进入编辑\nCommand/Ctrl+F 焦点切换到搜索\n编辑器中列表编辑时，按 Tab 变子项，Shift + Tab 恢复\n\n","slug":"test","date":"2024-11-09T02:38:44.000Z","categories_index":"","tags_index":"test","author_index":"Ivan"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post1$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server1$ hexo server\n\nMore info: Server\nGenerate static files1$ hexo generate\n\nMore info: Generating\nDeploy to remote sites1$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2024-11-07T16:24:53.067Z","categories_index":"","tags_index":"","author_index":"Ivan"}]